{
  "emqx_audit_api": {
    "audit_get": {
      "desc": "Get audit logs with filtering parameters. This feature enables users to efficiently\naccess the desired audit trail data and facilitates auditing, compliance,\ntroubleshooting, and security analysis.",
      "label": "List audit logs"
    },
    "filter_from": {
      "desc": "Filter logs by source type. Possible values are:\n\n- `dashboard`: Dashboard request logs.\n- `rest_api`: API KEY request logs.\n- `cli`: The emqx command line logs.\n- `erlang_console`: The emqx remote_console run function logs."
    },
    "filter_gte_created_at": {
      "desc": "Filter logs by creation time, selecting logs created no earlier than the given timestamp.\nThe timestamp can be provided either in rfc3339 string format or as a millisecond epoch timestamp."
    },
    "filter_gte_duration_ms": {
      "desc": "Filter logs by age duration, selecting those created no earlier than then given duration time ago."
    },
    "filter_http_method": {
      "desc": "Filter The HTTP API logs by method, applicable for logs generated from Dashboard or REST API operations."
    },
    "filter_http_status_code": {
      "desc": "Filter The HTTP API logs by response code, applicable for logs generated from Dashboard or REST API operations."
    },
    "filter_lte_created_at": {
      "desc": "Filter logs by creation time, selecting logs created no later than the given timestamp.\nThe timestamp can be provided either in rfc3339 string format or as a millisecond epoch timestamp."
    },
    "filter_lte_duration_ms": {
      "desc": "Filter logs by age duration, selecting those created no later than then given duration time ago."
    },
    "filter_node": {
      "desc": "Filter logs by the node name where the logs were generated."
    },
    "filter_operation_id": {
      "desc": "Filter logs by swagger's operation_id, applicable for logs generated from Dashboard or REST API operations."
    },
    "filter_operation_result": {
      "desc": "Filter logs by operation result."
    },
    "filter_operation_type": {
      "desc": "Filter logs by operation type."
    },
    "filter_source": {
      "desc": "Filter logs by source. Possible values are:\n\n- The login username to filter logs generated from Dashboard for this specific user.\n- The API Key to filter logs generated from the REST API for this specific API key.\n- An empty string to filter logs generated from CLI or Erlang console."
    },
    "filter_source_ip": {
      "desc": "Filter logs by source IP when logs, applicable for logs generated from Dashboard or REST API operations."
    }
  },
  "emqx_auth_ext_schema": {
    "common_ssl_opts_schema_partial_chain": {
      "desc": "Enable or disable peer verification with partial_chain.\nWhen local verifies a peer certificate during the x509 path validation\nprocess, it constructs a certificate chain that starts with the peer\ncertificate and ends with a trust anchor.\nBy default, if it is set to `false`, the trust anchor is the\nRoot CA, and the certificate chain must be complete.\nHowever, if the setting is set to `true` or `cacert_from_cacertfile`,\nthe last certificate in `cacertfile` will be used as the trust anchor\ncertificate (intermediate CA). This creates a partial chain\nin the path validation.\nAlternatively, if it is configured with `two_cacerts_from_cacertfile`,\none of the last two certificates in `cacertfile` will be used as the\ntrust anchor certificate, forming a partial chain. This option is\nparticularly useful for intermediate CA certificate rotation.\nHowever, please note that it incurs some additional overhead, so it\nshould only be used for certificate rotation purposes.",
      "label": "Partial chain"
    },
    "common_ssl_opts_verify_peer_ext_key_usage": {
      "desc": "Verify extended key usage in peer's certificate\nFor additional peer certificate validation, the value defined here must present in the\n'Extended Key Usage' of peer certificate defined in\n[rfc5280](https://www.rfc-editor.org/rfc/rfc5280#section-4.2.1.12).\n\nAllowed values are\n- `clientAuth`\n- `serverAuth`\n- `codeSigning`\n- `emailProtection`\n- `timeStamping`\n- `ocspSigning`\n- raw OID, for example: \"OID:1.3.6.1.5.5.7.3.2\" means `id-pk 2` which is equivalent to `clientAuth`\n\nComma-separated string is also supported for validating more than one key usages.\n\nFor example, `\"serverAuth,OID:1.3.6.1.5.5.7.3.2\"`",
      "label": "Verify KeyUsage in cert"
    }
  },
  "emqx_authn_api": {
    "authentication_get": {
      "desc": "List authenticators for global authentication.",
      "label": "List authenticators"
    },
    "authentication_id_delete": {
      "desc": "Delete authenticator from global authentication chain.",
      "label": "Delete authenticator"
    },
    "authentication_id_get": {
      "desc": "Get authenticator from global authentication chain.",
      "label": "Get authenticator"
    },
    "authentication_id_position_put": {
      "desc": "Move authenticator in global authentication chain.",
      "label": "Move authenticator"
    },
    "authentication_id_put": {
      "desc": "Update authenticator from global authentication chain.",
      "label": "Update authenticator"
    },
    "authentication_id_status_get": {
      "desc": "Get authenticator status from global authentication chain.",
      "label": "Get authenticator status"
    },
    "authentication_id_users_get": {
      "desc": "List users in authenticator in global authentication chain.",
      "label": "List users in authenticator"
    },
    "authentication_id_users_post": {
      "desc": "Create users for authenticator in global authentication chain.",
      "label": "Create users for authenticator"
    },
    "authentication_id_users_user_id_delete": {
      "desc": "Delete user in authenticator in global authentication chain.",
      "label": "Delete user in authenticator"
    },
    "authentication_id_users_user_id_get": {
      "desc": "Get user from authenticator in global authentication chain.",
      "label": "Get user from authenticator"
    },
    "authentication_id_users_user_id_put": {
      "desc": "Update user in authenticator in global authentication chain.",
      "label": "Update user in authenticator"
    },
    "authentication_order_put": {
      "desc": "Reorder all authenticators in global authentication chain.",
      "label": "Reorder Authenticators"
    },
    "authentication_post": {
      "desc": "Create authenticator for global authentication.",
      "label": "Create authenticator"
    },
    "is_superuser": {
      "desc": "Is superuser",
      "label": "Is superuser"
    },
    "like_user_id": {
      "desc": "Fuzzy search user_id (username or clientid).",
      "label": "like_user_id"
    },
    "listeners_listener_id_authentication_get": {
      "desc": "List authenticators for listener authentication.",
      "label": "List authenticators for listener"
    },
    "listeners_listener_id_authentication_id_delete": {
      "desc": "Delete authenticator from listener authentication chain.",
      "label": "Delete authenticator from listener"
    },
    "listeners_listener_id_authentication_id_get": {
      "desc": "Get authenticator from listener authentication chain.",
      "label": "Get authenticator from listener"
    },
    "listeners_listener_id_authentication_id_position_put": {
      "desc": "Move authenticator in listener authentication chain.",
      "label": "Move authenticator in listener"
    },
    "listeners_listener_id_authentication_id_put": {
      "desc": "Update authenticator from listener authentication chain.",
      "label": "Update authenticator from listener"
    },
    "listeners_listener_id_authentication_id_status_get": {
      "desc": "Get authenticator status from listener authentication chain.",
      "label": "Get authenticator status from listener"
    },
    "listeners_listener_id_authentication_id_users_get": {
      "desc": "List users in authenticator in listener authentication chain.",
      "label": "List users in authenticator in listener"
    },
    "listeners_listener_id_authentication_id_users_post": {
      "desc": "Create users for authenticator in listener authentication chain.",
      "label": "Create users for authenticator in listener"
    },
    "listeners_listener_id_authentication_id_users_user_id_delete": {
      "desc": "Delete user in authenticator in listener authentication chain.",
      "label": "Delete user in authenticator in listener"
    },
    "listeners_listener_id_authentication_id_users_user_id_get": {
      "desc": "Get user from authenticator in listener authentication chain.",
      "label": "Get user from authenticator in listener"
    },
    "listeners_listener_id_authentication_id_users_user_id_put": {
      "desc": "Update user in authenticator in listener authentication chain.",
      "label": "Update user in authenticator in listener"
    },
    "listeners_listener_id_authentication_post": {
      "desc": "Create authenticator for listener authentication.",
      "label": "Create authenticator for listener"
    },
    "param_auth_id": {
      "desc": "Authenticator ID.",
      "label": "Authenticator ID"
    },
    "param_listener_id": {
      "desc": "Listener ID.",
      "label": "Listener ID"
    },
    "param_position": {
      "desc": "Position of authenticator in chain. Possible values are 'front', 'rear', 'before:{other_authenticator}', 'after:{other_authenticator}'.",
      "label": "Position of authenticator"
    },
    "param_user_id": {
      "desc": "User ID.",
      "label": "User ID"
    }
  },
  "emqx_authn_http_schema": {
    "body": {
      "desc": "HTTP request body.",
      "label": "Request Body"
    },
    "get": {
      "desc": "Configuration of authenticator using HTTP Server as authentication service (Using GET request)."
    },
    "headers": {
      "desc": "List of HTTP Headers.",
      "label": "Headers"
    },
    "headers_no_content_type": {
      "desc": "List of HTTP headers (without <code>content-type</code>).",
      "label": "headers_no_content_type"
    },
    "method": {
      "desc": "HTTP request method.",
      "label": "Request Method"
    },
    "post": {
      "desc": "Configuration of authenticator using HTTP Server as authentication service (Using POST request)."
    },
    "request_timeout": {
      "desc": "HTTP request timeout.",
      "label": "Request Timeout"
    },
    "url": {
      "desc": "URL of the HTTP server.",
      "label": "URL"
    }
  },
  "emqx_authn_jwt_schema": {
    "acl_claim_name": {
      "desc": "The JWT claim designated for accessing ACL (Access Control List) rules can be specified,\nsuch as using the `acl` claim. A typical decoded JWT with this claim might appear as:\n`{\"username\": \"user1\", \"acl\": ...}`.\n\nSupported ACL Rule Formats:\n\n- Object Format:\n  Utilizes action types pub (publish), sub (subscribe), or all (both publish and subscribe).\n  The value is a list of topic filters.\n  Example: `{\"pub\": [\"topic1\"], \"sub\": [], \"all\": [\"${username}/#\"]}`.\n  This example signifies that the token owner can publish to topic1 and perform both publish and subscribe\n  actions on topics starting with their username.\n  Note: In this format, if no topic matches, the action is denied, and the authorization process terminates.\n\n- Array Format (resembles File-Based ACL Rules):\n  Example: `[{\"permission\": \"allow\", \"action\": \"all\", \"topic\": \"${username}/#\"}]`.\n  Additionally, the `pub` or `publish` action rules can be extended with `qos` and `retain` field,\n  and `sub` or `subscribe` action rules can be extended with a `qos` field.\n  Note: Here, if no rule matches, the action is not immediately denied.\n  The process continues to other configured authorization sources,\n  and ultimately falls back to the default permission in config `authorization.no_match`.\n\nThe ACL claim utilizes MQTT topic wildcard matching rules for publishing or subscribing.\nA special syntax for the 'subscribe' action allows the use of `eq` for an exact match.\nFor instance, `eq t/#` permits or denies subscription to `t/#`, but not to `t/1`.",
      "label": "ACL claim name"
    },
    "algorithm": {
      "desc": "JWT signing algorithm, Supports HMAC (configured as <code>hmac-based</code>) and RSA, ECDSA (configured as <code>public-key</code>).",
      "label": "JWT Signing Algorithm"
    },
    "cacertfile": {
      "desc": "Path to a file containing PEM-encoded CA certificates.",
      "label": "CA Certificate File"
    },
    "certfile": {
      "desc": "Path to a file containing the user certificate.",
      "label": "Certificate File"
    },
    "disconnect_after_expire": {
      "desc": "Disconnect the client after the token expires.",
      "label": "Disconnect After Expire"
    },
    "enable": {
      "desc": "Enable/disable SSL.",
      "label": "Enable/disable SSL"
    },
    "endpoint": {
      "desc": "JWKS endpoint, it's a read-only endpoint that returns the server's public key set in the JWKS format.",
      "label": "JWKS Endpoint"
    },
    "from": {
      "desc": "Field to take JWT from.",
      "label": "From Field"
    },
    "jwks_headers": {
      "desc": "List of HTTP headers to send with the JWKS request.",
      "label": "HTTP Headers"
    },
    "jwt_hmac": {
      "desc": "Configuration when the JWT for authentication is issued using the HMAC algorithm."
    },
    "jwt_jwks": {
      "desc": "Configuration when JWTs used for authentication need to be fetched from the JWKS endpoint."
    },
    "jwt_public_key": {
      "desc": "Configuration when the JWT for authentication is issued using RSA or ECDSA algorithm."
    },
    "keyfile": {
      "desc": "Path to a file containing the user's private PEM-encoded key.",
      "label": "Key File"
    },
    "public_key": {
      "desc": "The public key used to verify the JWT.",
      "label": "Public Key"
    },
    "refresh_interval": {
      "desc": "JWKS refresh interval.",
      "label": "JWKS Refresh Interval"
    },
    "secret": {
      "desc": "The key to verify the JWT using HMAC algorithm.",
      "label": "Secret"
    },
    "secret_base64_encoded": {
      "desc": "Whether secret is base64 encoded.",
      "label": "Whether Secret is Base64 Encoded"
    },
    "server_name_indication": {
      "desc": "Server Name Indication (SNI).",
      "label": "Server Name Indication"
    },
    "ssl": {
      "desc": "SSL options.",
      "label": "SSL Options"
    },
    "use_jwks": {
      "desc": "Whether to use JWKS.",
      "label": "Whether to Use JWKS"
    },
    "verify": {
      "desc": "Enable or disable SSL peer verification.",
      "label": "Verify"
    },
    "verify_claims": {
      "desc": "A list of custom claims to validate. The allowed formats are the following:\nA map where claim names are map keys and expected values are map values:\n <code>{ claim_name = \"${username}\", ...}</code>.\n\nA list of maps with <code>name</code> (claim name) and <code>value</code> (expected claim value) keys:\n <code>[{name = \"claim_name\", value = \"${username}\"}, ...]</code>.\n\nValues can use the following placeholders:\n- <code>${username}</code>: Will be replaced at runtime with <code>Username</code> used by the client when connecting\n- <code>${clientid}</code>: Will be replaced at runtime with <code>Client ID</code> used by the client when connecting\n\nAuthentication will verify that the value of claims in the JWT (taken from the Password field) matches what is required in <code>verify_claims</code>.",
      "label": "Verify Claims"
    }
  },
  "emqx_authn_kerberos_schema": {
    "principal": {
      "desc": "Server Kerberos principal.\nFor example <code>mqtt/emqx-cluster-1.example.com@MY_REALM.EXAMPLE.COM</code>.\nNOTE: The realm in use has to be configured in /etc/krb5.conf in EMQX nodes.",
      "label": "Kerberos Principal"
    }
  },
  "emqx_authn_ldap_schema": {
    "bind_method": {
      "desc": "Authenticate by the LDAP bind operation."
    },
    "hash_method": {
      "desc": "Authenticate by comparing the hashed password which was provided by the `password attribute`."
    },
    "is_superuser_attribute": {
      "desc": "Indicates which attribute is used to represent whether the user is a superuser.",
      "label": "IsSuperuser Attribute"
    },
    "ldap": {
      "desc": "Configuration of authenticator using LDAP as authentication data source."
    },
    "ldap_deprecated": {
      "desc": "This is a deprecated form, and you should avoid using it."
    },
    "method": {
      "desc": "Authentication method."
    },
    "method_type": {
      "desc": "Authentication method type."
    },
    "password_attribute": {
      "desc": "Indicates which attribute is used to represent the user's password.",
      "label": "Password Attribute"
    },
    "query_timeout": {
      "desc": "Timeout for the LDAP query.",
      "label": "Query Timeout"
    }
  },
  "emqx_authn_mnesia_schema": {
    "bootstrap_file": {
      "desc": "The bootstrap file imports users into the built-in database.\nIt will not import a user ID that already exists in the database.\nThe file content format is determined by `bootstrap_type`.",
      "label": "Bootstrap File Path"
    },
    "bootstrap_type": {
      "desc": "Specify which type of content the bootstrap file has.\n\n- **`plain`**:\n  - Expected data fields: `user_id`, `password`, `is_superuser`\n  - `user_id`: Can be Client ID or username, depending on built-in database authentication's `user_id_type` config.\n  - `password`: User's plaintext password.\n  - `is_superuser`: Boolean, user's administrative status.\n\n- **`hash`**:\n  - Expected data fields: `user_id`,`password_hash`,`salt`,`is_superuser`\n  - Definitions similar to `plain` type, with `password_hash` and `salt` added for security.\n\nThe content can be either in CSV, or JSON format.\n\nHere is a CSV example: `user_id,password_hash,salt,is_superuser\\nmy_user,b6c743545a7817ae8c8f624371d5f5f0373234bb0ff36b8ffbf19bce0e06ab75,de1024f462fb83910fd13151bd4bd235,true`\n\nAnd JSON content should be decoded into an array of objects, for example: `[{\"user_id\": \"my_user\",\"password\": \"s3cr3tp@ssw0rd\",\"is_superuser\": true}]`.\n\nThe hash string for `password_hash` depends on how `password_hash_algorithm` is configured for the built-in database authentication mechanism. For example, if it's configured as `password_hash_algorithm {name = sha256, salt_position = suffix}`, then the salt is appended to the password before hashed. Here is the equivalent Python expression: `hashlib.sha256(password + salt).hexdigest()`."
    },
    "builtin_db": {
      "desc": "Configuration of authenticator using built-in database as data source."
    },
    "user_id_type": {
      "desc": "Specify whether to use `clientid` or `username` for authentication.",
      "label": "Authentication ID Type"
    }
  },
  "emqx_authn_mongodb_schema": {
    "collection": {
      "desc": "Collection used to store authentication data.",
      "label": "Collection"
    },
    "filter": {
      "desc": "Conditional expression that defines the filter condition in the query.\nFilter supports the following placeholders:\n- <code>${username}</code>: Will be replaced at runtime with <code>Username</code> used by the client when connecting\n- <code>${clientid}</code>: Will be replaced at runtime with <code>Client ID</code> used by the client when connecting",
      "label": "Filter"
    },
    "is_superuser_field": {
      "desc": "Document field that defines if the user has superuser privileges.",
      "label": "Is Superuser Field"
    },
    "password_hash_field": {
      "desc": "Document field that contains password hash.",
      "label": "Password Hash Field"
    },
    "replica-set": {
      "desc": "Configuration of authenticator using MongoDB (Replica Set) as authentication data source."
    },
    "salt_field": {
      "desc": "Document field that contains the password salt.",
      "label": "Salt Field"
    },
    "sharded-cluster": {
      "desc": "Configuration of authenticator using MongoDB (Sharded Cluster) as authentication data source."
    },
    "single": {
      "desc": "Configuration of authenticator using MongoDB (Standalone) as authentication data source."
    }
  },
  "emqx_authn_mysql_schema": {
    "mysql": {
      "desc": "Configuration of authenticator using MySQL as authentication data source."
    },
    "query": {
      "desc": "SQL used to query data for authentication, such as password hash.",
      "label": "Query"
    },
    "query_timeout": {
      "desc": "Timeout for the SQL query.",
      "label": "Query Timeout"
    }
  },
  "emqx_authn_postgresql_schema": {
    "postgresql": {
      "desc": "Configuration of authenticator using PostgreSQL as authentication data source."
    },
    "query": {
      "desc": "SQL used to query data for authentication, such as password hash.",
      "label": "Query"
    }
  },
  "emqx_authn_redis_schema": {
    "cluster": {
      "desc": "Configuration of authenticator using Redis (Cluster) as authentication data source."
    },
    "cmd": {
      "desc": "The Redis Command used to query data for authentication such as password hash, currently only supports <code>HGET</code> and <code>HMGET</code>.",
      "label": "Command"
    },
    "sentinel": {
      "desc": "Configuration of authenticator using Redis (Sentinel) as authentication data source."
    },
    "single": {
      "desc": "Configuration of authenticator using Redis (Standalone) as authentication data source."
    }
  },
  "emqx_authn_schema": {
    "backend": {
      "desc": "Backend type.",
      "label": "Backend Type"
    },
    "enable": {
      "desc": "Set to <code>true</code> or <code>false</code> to disable this auth provider.",
      "label": "Enable"
    },
    "failed": {
      "desc": "Count of query failed.",
      "label": "Failed"
    },
    "global_authentication": {
      "desc": "Default authentication configs for all MQTT listeners.\n\nFor per-listener overrides see <code>authentication</code> in listener configs\n\nThis option can be configured with:\n<ul>\n  <li><code>[]</code>: The default value, it allows *ALL* logins</li>\n  <li>one: For example <code>{enable:true,backend:\"built_in_database\",mechanism=\"password_based\"}</code></li>\n  <li>chain: An array of structs.</li>\n</ul>\n\nWhen a chain is configured, the login credentials are checked against the backends per the configured order, until an 'allow' or 'deny' decision can be made.\n\nIf there is no decision after a full chain exhaustion, the login is rejected.",
      "label": "Global authentication"
    },
    "listener_authentication": {
      "desc": "Per-listener authentication override.\nAuthentication can be one single authenticator instance or a chain of authenticators as an array.\nWhen authenticating a login (username, client ID, etc.) the authenticators are checked in the configured order.",
      "label": "Per-listener authentication override"
    },
    "matched": {
      "desc": "Count of this resource is queried.",
      "label": "Matched"
    },
    "mechanism": {
      "desc": "Authentication mechanism.",
      "label": "Authentication Mechanism"
    },
    "metrics": {
      "desc": "The metrics of the resource.",
      "label": "Metrics"
    },
    "metrics_failed": {
      "desc": "The required authentication information is found in the current instance, and the instance returns authentication failure.",
      "label": "Authentication Failed Times"
    },
    "metrics_nomatch": {
      "desc": "The number of times the instance was ignored when the required authentication information was not found in the current instance.",
      "label": "Nomatch Times"
    },
    "metrics_rate": {
      "desc": "The total rate at which instances are triggered, times/second.",
      "label": "Total Triggered Rate"
    },
    "metrics_rate_last5m": {
      "desc": "The average trigger rate of the instance within 5 minutes, times/second.",
      "label": "Average Triggered Rate in Last 5min"
    },
    "metrics_rate_max": {
      "desc": "The highest trigger rate the instance has ever reached, times/second.",
      "label": "Highest Triggered Rate"
    },
    "metrics_success": {
      "desc": "The required authentication information is found in the current instance, and the instance returns authentication success.",
      "label": "Authentication Success Times"
    },
    "metrics_total": {
      "desc": "The total number of times the current instance was triggered.",
      "label": "Total Triggered Times"
    },
    "node": {
      "desc": "Node name.",
      "label": "Node Name."
    },
    "node_error": {
      "desc": "The error of node.",
      "label": "Error in Node"
    },
    "node_metrics": {
      "desc": "The metrics of the resource for each node.",
      "label": "Resource Metrics in Node"
    },
    "node_status": {
      "desc": "The status of the resource for each node.",
      "label": "Resource Status in Node"
    },
    "rate": {
      "desc": "The rate of matched, times/second.",
      "label": "Rate"
    },
    "rate_last5m": {
      "desc": "The average rate of matched in the last 5 minutes, times/second.",
      "label": "Rate in Last 5min"
    },
    "rate_max": {
      "desc": "The max rate of matched, times/second.",
      "label": "Max Rate"
    },
    "status": {
      "desc": "The status of the resource.",
      "label": "Status"
    },
    "success": {
      "desc": "Count of query success.",
      "label": "Success"
    }
  },
  "emqx_authn_user_import_api": {
    "authentication_id_import_users_post": {
      "desc": "Import users into authenticator in global authentication chain.",
      "label": "Global import users into authenticator"
    },
    "listeners_listener_id_authentication_id_import_users_post": {
      "desc": "Import users into authenticator in listener authentication chain.",
      "label": "Import users into authenticator in listener"
    }
  },
  "emqx_authz_api_cache": {
    "authorization_cache_delete": {
      "desc": "Clean all authorization cache in the cluster.",
      "label": "Clean authorization cache in cluster"
    }
  },
  "emqx_authz_api_mnesia": {
    "action": {
      "desc": "Authorized action (publish/subscribe/all)",
      "label": "action"
    },
    "clientid": {
      "desc": "ClientID",
      "label": "clientid"
    },
    "fuzzy_clientid": {
      "desc": "Fuzzy search `clientid` as substring",
      "label": "fuzzy_clientid"
    },
    "fuzzy_username": {
      "desc": "Fuzzy search `username` as substring",
      "label": "fuzzy_username"
    },
    "permission": {
      "desc": "Permission",
      "label": "permission"
    },
    "qos": {
      "desc": "QoS of authorized action",
      "label": "QoS"
    },
    "retain": {
      "desc": "Retain flag of authorized action",
      "label": "retain"
    },
    "rules_all_delete": {
      "desc": "Delete rules for 'all'",
      "label": "Delete rules for 'all'"
    },
    "rules_all_get": {
      "desc": "Show the list of rules for 'all'",
      "label": "Show rules for 'all'"
    },
    "rules_all_post": {
      "desc": "Create/Update the list of rules for 'all'.",
      "label": "Update rules for 'all'"
    },
    "rules_delete": {
      "desc": "Delete all rules for all 'users', 'clients' and 'all'",
      "label": "Delete all rules"
    },
    "topic": {
      "desc": "Rule on specific topic",
      "label": "topic"
    },
    "user_clientid_delete": {
      "desc": "Delete rule for 'clientid'",
      "label": "Delete rule for 'clientid'"
    },
    "user_clientid_get": {
      "desc": "Get rule for 'clientid'",
      "label": "Get rule for 'clientid'"
    },
    "user_clientid_put": {
      "desc": "Set rule for 'clientid'",
      "label": "Set rule for 'clientid'"
    },
    "user_username_delete": {
      "desc": "Delete rule for 'username'",
      "label": "Delete rule for 'username'"
    },
    "user_username_get": {
      "desc": "Get rule for 'username'",
      "label": "Get rule for 'username'"
    },
    "user_username_put": {
      "desc": "Set rule for 'username'",
      "label": "Set rule for 'username'"
    },
    "username": {
      "desc": "Username",
      "label": "username"
    },
    "users_clientid_get": {
      "desc": "Show the list of rules for clients",
      "label": "Show rules for clients"
    },
    "users_clientid_post": {
      "desc": "Add new rule for 'clientid'",
      "label": "Add rule for 'clientid'"
    },
    "users_username_get": {
      "desc": "Show the list of rules for users",
      "label": "Show rules for users"
    },
    "users_username_post": {
      "desc": "Add new rule for 'username'",
      "label": "Add rule for 'username'"
    }
  },
  "emqx_authz_api_settings": {
    "authorization_settings_get": {
      "desc": "Get authorization settings"
    },
    "authorization_settings_put": {
      "desc": "Update authorization settings"
    }
  },
  "emqx_authz_api_sources": {
    "authorization_sources_get": {
      "desc": "List all authorization sources",
      "label": "List all authorization sources"
    },
    "authorization_sources_order_put": {
      "desc": "Reorder all authorization sources.",
      "label": "Reorder Authorization Sources"
    },
    "authorization_sources_post": {
      "desc": "Add a new source",
      "label": "Add a new source"
    },
    "authorization_sources_type_delete": {
      "desc": "Delete source",
      "label": "Delete source"
    },
    "authorization_sources_type_get": {
      "desc": "Get a authorization source",
      "label": "Get a authorization source"
    },
    "authorization_sources_type_move_post": {
      "desc": "Change the exection order of sources",
      "label": "Change order of sources"
    },
    "authorization_sources_type_put": {
      "desc": "Update source",
      "label": "Update source"
    },
    "authorization_sources_type_status_get": {
      "desc": "Get a authorization source",
      "label": "Get a authorization source"
    },
    "source": {
      "desc": "Authorization source",
      "label": "source"
    },
    "source_config": {
      "desc": "Source config",
      "label": "source_config"
    },
    "source_type": {
      "desc": "Authorization type",
      "label": "source_type"
    },
    "sources": {
      "desc": "Authorization sources",
      "label": "sources"
    }
  },
  "emqx_authz_file_schema": {
    "file": {
      "desc": "Authorization using a static file.",
      "label": "file"
    },
    "path": {
      "desc": "Path to the file which contains the ACL rules.\nIf the file provisioned before starting EMQX node,\nit can be placed anywhere as long as EMQX has read access to it.\nThat is, EMQX will treat it as read only.\n\nIn case the rule-set is created or updated from EMQX Dashboard or HTTP API,\na new file will be created and placed in `authz` subdirectory inside EMQX's `data_dir`,\nand the old file will not be used anymore.",
      "label": "path"
    }
  },
  "emqx_authz_http_schema": {
    "body": {
      "desc": "HTTP request body.",
      "label": "Request Body"
    },
    "headers": {
      "desc": "List of HTTP Headers.",
      "label": "Headers"
    },
    "headers_no_content_type": {
      "desc": "List of HTTP headers (without <code>content-type</code>).",
      "label": "headers_no_content_type"
    },
    "http_get": {
      "desc": "Authorization using an external HTTP server (via GET requests).",
      "label": "http_get"
    },
    "http_post": {
      "desc": "Authorization using an external HTTP server (via POST requests).",
      "label": "http_post"
    },
    "method": {
      "desc": "HTTP method.",
      "label": "method"
    },
    "request_timeout": {
      "desc": "HTTP request timeout.",
      "label": "Request Timeout"
    },
    "url": {
      "desc": "URL of the auth server.",
      "label": "URL"
    }
  },
  "emqx_authz_ldap_schema": {
    "all_attribute": {
      "desc": "Indicates which attribute is used to represent the both allowed topics list of  `publish` and `subscribe`.",
      "label": "All Attribute"
    },
    "publish_attribute": {
      "desc": "Indicates which attribute is used to represent the allowed topics list of the `publish`.",
      "label": "Publish Attribute"
    },
    "query_timeout": {
      "desc": "Timeout for the LDAP query.",
      "label": "Query Timeout"
    },
    "subscribe_attribute": {
      "desc": "Indicates which attribute is used to represent the allowed topics list of the `subscribe`.",
      "label": "Subscribe Attribute"
    }
  },
  "emqx_authz_mnesia_schema": {
    "builtin_db": {
      "desc": "Authorization using a built-in database (mnesia).",
      "label": "Builtin Database"
    },
    "max_rules": {
      "desc": "Maximum number of rules per client/user. Note that performance may decrease as number of rules increases."
    }
  },
  "emqx_authz_mongodb_schema": {
    "collection": {
      "desc": "`MongoDB` collection containing the authorization data.",
      "label": "collection"
    },
    "filter": {
      "desc": "Conditional expression that defines the filter condition in the query.\nFilter supports the following placeholders<br/>\n - <code>${username}</code>: Will be replaced at runtime with <code>Username</code> used by the client when connecting<br/>\n - <code>${clientid}</code>: Will be replaced at runtime with <code>Client ID</code> used by the client when connecting",
      "label": "Filter"
    },
    "mongo_rs": {
      "desc": "Authorization using a MongoDB replica set.",
      "label": "mongo_rs"
    },
    "mongo_sharded": {
      "desc": "Authorization using a sharded MongoDB cluster.",
      "label": "mongo_sharded"
    },
    "mongo_single": {
      "desc": "Authorization using a single MongoDB instance.",
      "label": "mongo_single"
    }
  },
  "emqx_authz_mysql_schema": {
    "mysql": {
      "desc": "Authorization using a MySQL database.",
      "label": "mysql"
    },
    "query": {
      "desc": "Database query used to retrieve authorization data.",
      "label": "query"
    }
  },
  "emqx_authz_postgresql_schema": {
    "postgresql": {
      "desc": "Authorization using a PostgreSQL database.",
      "label": "postgresql"
    },
    "query": {
      "desc": "Database query used to retrieve authorization data.",
      "label": "query"
    }
  },
  "emqx_authz_redis_schema": {
    "cmd": {
      "desc": "Database query used to retrieve authorization data.",
      "label": "cmd"
    },
    "redis_cluster": {
      "desc": "Authorization using a Redis cluster.",
      "label": "redis_cluster"
    },
    "redis_sentinel": {
      "desc": "Authorization using a Redis Sentinel.",
      "label": "redis_sentinel"
    },
    "redis_single": {
      "desc": "Authorization using a single Redis instance.",
      "label": "redis_single"
    }
  },
  "emqx_authz_schema": {
    "allow": {
      "desc": "The number of times the authentication was successful.",
      "label": "The Number of Times the Authentication was Successful"
    },
    "authorization": {
      "desc": "Configuration related to the client authorization.",
      "label": "authorization"
    },
    "deny": {
      "desc": "The number of authentication failures.",
      "label": "The Number of Authentication Failures"
    },
    "enable": {
      "desc": "Set to <code>true</code> or <code>false</code> to disable this ACL provider",
      "label": "enable"
    },
    "failed": {
      "desc": "Count of query failed.",
      "label": "Failed"
    },
    "ignore": {
      "desc": "Count of query ignored.  This counter is increased whenever the authorization source attempts to authorize a request, but either it's not applicable, or an error was encountered and the result is undecidable",
      "label": "Ignored"
    },
    "matched": {
      "desc": "Count of this resource is queried.",
      "label": "Matched"
    },
    "metrics": {
      "desc": "The metrics of the resource.",
      "label": "Metrics"
    },
    "metrics_total": {
      "desc": "The total number of times the authorization rule was triggered.",
      "label": "The Total Number of Times the Authorization Rule was Triggered"
    },
    "node": {
      "desc": "Node name.",
      "label": "Node Name."
    },
    "node_error": {
      "desc": "The error of node.",
      "label": "Error in Node"
    },
    "node_metrics": {
      "desc": "The metrics of the resource for each node.",
      "label": "Resource Metrics in Node"
    },
    "node_status": {
      "desc": "The status of the resource for each node.",
      "label": "Resource Status in Node"
    },
    "nomatch": {
      "desc": "The number of times that no authorization rules were matched.",
      "label": "The Number of Times that no Authorization Rules were Matched"
    },
    "rate": {
      "desc": "The rate of matched, times/second.",
      "label": "Rate"
    },
    "rate_last5m": {
      "desc": "The average rate of matched in the last 5 minutes, times/second.",
      "label": "Rate in Last 5min"
    },
    "rate_max": {
      "desc": "The max rate of matched, times/second.",
      "label": "Max Rate"
    },
    "sources": {
      "desc": "Authorization data sources.<br/>\nAn array of authorization (ACL) data providers.\nIt is designed as an array, not a hash-map, so the sources can be\nordered to form a chain of access controls.<br/>\n\nWhen authorizing a 'publish' or 'subscribe' action, the configured\nsources are checked in order. When checking an ACL source,\nin case the client (identified by username or client ID) is not found,\nit moves on to the next source. And it stops immediately\nonce an 'allow' or 'deny' decision is returned.<br/>\n\nIf the client is not found in any of the sources,\nthe default action configured in 'authorization.no_match' is applied.<br/>\n\nNOTE:\nThe source elements are identified by their 'type'.\nIt is NOT allowed to configure two or more sources of the same type.",
      "label": "sources"
    },
    "status": {
      "desc": "The status of the resource.",
      "label": "Status"
    },
    "success": {
      "desc": "Count of query success.",
      "label": "Success"
    },
    "type": {
      "desc": "Backend type.",
      "label": "type"
    }
  },
  "emqx_auto_subscribe_api": {
    "list_auto_subscribe_api": {
      "desc": "Get auto subscribe topic list",
      "label": "Get auto subscribe topics"
    },
    "update_auto_subscribe_api": {
      "desc": "Update auto subscribe topic list",
      "label": "Update auto subscribe topics"
    },
    "update_auto_subscribe_api_response409": {
      "desc": "Auto Subscribe topics max limit",
      "label": "Auto Subscribe topics max limit"
    }
  },
  "emqx_auto_subscribe_schema": {
    "auto_subscribe": {
      "desc": "After the device logs in successfully, the subscription is automatically completed for the device through the pre-defined subscription representation. Supports the use of placeholders.",
      "label": "Auto Subscribe"
    },
    "nl": {
      "desc": "Default value 0.\nMQTT v3.1.1: if you subscribe to the topic published by yourself, you will receive all messages that you published.\nMQTT v5: if you set this option as 1 when subscribing, the server will not forward the message you published to you.",
      "label": "No Local"
    },
    "qos": {
      "desc": "Default value 0. Quality of service.\nAt most once (0)\nAt least once (1)\nExactly once (2)",
      "label": "Quality of Service"
    },
    "rap": {
      "desc": "Default value 0. This option is used to specify whether the server retains the RETAIN mark when forwarding messages to the client, and this option does not affect the RETAIN mark in the retained message. Therefore, when the option Retain As Publish is set to 0, the client will directly distinguish whether this is a normal forwarded message or a retained message according to the RETAIN mark in the message, instead of judging whether this message is the first received after subscribing(the forwarded message may be sent before the retained message, which depends on the specific implementation of different brokers).",
      "label": "Retain As Publish"
    },
    "rh": {
      "desc": "Default value 0. This option is used to specify whether the server forwards the retained message to the client when establishing a subscription.\nRetain Handling is equal to 0, as long as the client successfully subscribes, the server will send the retained message.\nRetain Handling is equal to 1, if the client successfully subscribes and this subscription does not exist previously, the server sends the retained message. After all, sometimes the client re-initiate the subscription just to change the QoS, but it does not mean that it wants to receive the reserved messages again.\nRetain Handling is equal to 2, even if the client successfully subscribes, the server does not send the retained message.",
      "label": "Retain Handling"
    },
    "topic": {
      "desc": "Topic name, placeholders are supported. For example: client/${clientid}/username/${username}/host/${host}/port/${port}\nRequired field, and cannot be empty string",
      "label": "Topic"
    }
  },
  "emqx_bridge_api": {
    "desc_api1": {
      "desc": "List all created bridges",
      "label": "List All Bridges"
    },
    "desc_api2": {
      "desc": "Create a new bridge by type and name",
      "label": "Create Bridge"
    },
    "desc_api3": {
      "desc": "Get a bridge by Id",
      "label": "Get Bridge"
    },
    "desc_api4": {
      "desc": "Update a bridge by Id",
      "label": "Update Bridge"
    },
    "desc_api5": {
      "desc": "Delete a bridge by Id",
      "label": "Delete Bridge"
    },
    "desc_api6": {
      "desc": "Reset a bridge metrics by Id",
      "label": "Reset Bridge Metrics"
    },
    "desc_api7": {
      "desc": "Stop/Restart bridges on all nodes in the cluster.",
      "label": "Cluster Bridge Operate"
    },
    "desc_api8": {
      "desc": "Stop/Restart bridges on a specific node.",
      "label": "Node Bridge Operate"
    },
    "desc_api9": {
      "desc": "Test creating a new bridge by given ID <br/>\nThe ID must be of format '{type}:{name}'",
      "label": "Test Bridge Creation"
    },
    "desc_bridge_metrics": {
      "desc": "Get bridge metrics by Id",
      "label": "Get Bridge Metrics"
    },
    "desc_enable_bridge": {
      "desc": "Enable or Disable bridges on all nodes in the cluster.",
      "label": "Cluster Bridge Enable"
    },
    "desc_param_path_enable": {
      "desc": "Whether to enable this bridge",
      "label": "Enable bridge"
    },
    "desc_param_path_id": {
      "desc": "The bridge Id. Must be of format {type}:{name}",
      "label": "Bridge ID"
    },
    "desc_param_path_node": {
      "desc": "The node name, e.g. emqx@127.0.0.1",
      "label": "The node name"
    },
    "desc_param_path_operation_cluster": {
      "desc": "Operations can be one of: stop, restart",
      "label": "Cluster Operation"
    },
    "desc_param_path_operation_on_node": {
      "desc": "Operations can be one of: stop, restart",
      "label": "Node Operation"
    }
  },
  "emqx_bridge_azure_blob_storage_action_schema": {
    "aggreg_parameters": {
      "desc": "Set of parameters for the action in aggregated mode.",
      "label": "Azure Blob Storage Aggregated Mode action parameters"
    },
    "aggregated_blob_template": {
      "desc": "Template for the Azure Blob Storage blob name of an aggregated upload.<br/>\n  Template may contain placeholders for the following variables:\n  <ul>\n  <li><code>${action}</code>: name of the action (required).</li>\n  <li><code>${node}</code>: name of the EMQX node conducting the upload (required).</li>\n  <li><code>${datetime.{format}}</code>: date and time when aggregation started, formatted according to the <code>{format}</code> string (required):\n      <ul>\n      <li><code>${datetime.rfc3339utc}</code>: RFC3339-formatted date and time in UTC,</li>\n      <li><code>${datetime.rfc3339}</code>: RFC3339-formatted date and time in local timezone,</li>\n      <li><code>${datetime.unix}</code>: Unix timestamp.</li>\n      </ul>\n  </li>\n  <li><code>${datetime_until.{format}}</code>: date and time when aggregation ended, with the same formatting options.</li>\n  <li><code>${sequence}</code>: sequence number of the aggregated upload within the same time interval (required).</li>\n  </ul>\n  All other placeholders are considered invalid. Note that placeholders marked as required will be added as a path suffix to the Azure Blob Storage blob name if they are missing from the template.",
      "label": "Azure Blob Storage blob name template"
    },
    "aggregated_container_name": {
      "desc": "The Azure Blob Storage container name. Does not support templates.",
      "label": "Azure Blob Storage Container name"
    },
    "aggregated_mode": {
      "desc": "Enables time-based aggregation of incoming events and uploading them to the Azure Blob Storage service as a single object.",
      "label": "Aggregated Azure Blob Storage Upload"
    },
    "aggregation": {
      "desc": "Set of parameters governing the aggregation process.",
      "label": "Aggregation parameters"
    },
    "aggregation_interval": {
      "desc": "Amount of time events will be aggregated in a single object before uploading.",
      "label": "Time interval"
    },
    "aggregation_max_records": {
      "desc": "Number of records (events) allowed per each aggregated object. Each aggregated upload will contain no more than that number of events, but may contain less.<br/>\n  If event rate is high enough, there obviously may be more than one aggregated upload during the same time interval. These uploads will have different, but consecutive sequence numbers, which will be a part of Azure Blob Storage blob name.",
      "label": "Maximum number of records"
    },
    "azure_blob_storage": {
      "desc": "Action that takes incoming events and uploads them to the Azure Blob Storage service.",
      "label": "Upload to Azure Blob Storage"
    },
    "direct_blob_template": {
      "desc": "The name of the Azure Blob Storage blob name.",
      "label": "Blob Name"
    },
    "direct_container_template": {
      "desc": "The name of the Azure Blob Storage container name.",
      "label": "Container Name"
    },
    "direct_content_template": {
      "desc": "Content of the Azure Blob Storage blob being uploaded. Supports templates.",
      "label": "Azure Blob Storage Blob Content"
    },
    "direct_mode": {
      "desc": "Enables uploading of events to the Azure Blob Storage service as separate objects.",
      "label": "Direct Azure Blob Storage Upload"
    },
    "direct_parameters": {
      "desc": "Set of parameters for the upload action. Action supports templates in Azure Blob Storage container name, blob name and blob content.",
      "label": "Direct Azure Blob Storage Upload action parameters"
    },
    "parameters": {
      "desc": "Set of parameters for the action.",
      "label": "Azure Blob Storage action parameters"
    }
  },
  "emqx_bridge_azure_blob_storage_connector_schema": {
    "account_key": {
      "desc": "Account key for Azure Blob Storage service.",
      "label": "Account Key"
    },
    "account_name": {
      "desc": "Account name for Azure Blob Storage service.",
      "label": "Account Name"
    },
    "config_connector": {
      "desc": "Configuration for a connector to Azure Blob Storage service.",
      "label": "Azure Blob Storage Connector Configuration"
    }
  },
  "emqx_bridge_azure_event_hub": {
    "actions": {
      "desc": "The configuration for an action.",
      "label": "Action Config"
    },
    "auth_sasl_mechanism": {
      "desc": "SASL authentication mechanism.",
      "label": "Mechanism"
    },
    "auth_sasl_password": {
      "desc": "The Connection String for connecting to Azure Event Hubs.  Should be the \"connection string-primary key\" of a Namespace shared access policy.",
      "label": "Connection String"
    },
    "auth_username_password": {
      "desc": "Username/password based authentication.",
      "label": "Username/password Auth"
    },
    "authentication": {
      "desc": "Authentication configs.",
      "label": "Authentication"
    },
    "bootstrap_hosts": {
      "desc": "A comma separated list of Azure Event Hubs Kafka <code>host[:port]</code> namespace endpoints to bootstrap the client.  Default port number is 9093.",
      "label": "Bootstrap Hosts"
    },
    "bridge_v2_type": {
      "desc": "The type of the bridge.",
      "label": "Bridge Type"
    },
    "buffer_memory_overload_protection": {
      "desc": "Applicable when buffer mode is set to <code>memory</code>\nEMQX will drop old buffered messages under high memory pressure. The high memory threshold is defined in config <code>sysmon.os.sysmem_high_watermark</code>. NOTE: This config only works on Linux.",
      "label": "Memory Overload Protection"
    },
    "buffer_mode": {
      "desc": "Message buffer mode.\n\n<code>memory</code>: Buffer all messages in memory. The messages will be lost in case of EMQX node restart\n<code>disk</code>: Buffer all messages on disk. The messages on disk are able to survive EMQX node restart.\n<code>hybrid</code>: Buffer message in memory first, when up to certain limit (see <code>segment_bytes</code> config for more information), then start offloading messages to disk, Like <code>memory</code> mode, the messages will be lost in case of EMQX node restart.",
      "label": "Buffer Mode"
    },
    "buffer_per_partition_limit": {
      "desc": "Number of bytes allowed to buffer for each partition. When this limit is exceeded, older messages will be discarded to make room for new messages to be buffered.",
      "label": "Per-partition Buffer Limit"
    },
    "buffer_segment_bytes": {
      "desc": "Applicable when buffer mode is set to <code>disk</code> or <code>hybrid</code>.\nThis setting specifies the size of each buffer segment file stored on disk.",
      "label": "Segment File Bytes"
    },
    "compression": {
      "desc": "Specify the method of compression.",
      "label": "Compression"
    },
    "config_enable": {
      "desc": "Enable (true) or disable (false) this config.",
      "label": "Enable or Disable"
    },
    "connect_timeout": {
      "desc": "Maximum wait time for TCP connection establishment (including authentication time if enabled).",
      "label": "Connect Timeout"
    },
    "connector_type": {
      "desc": "The type of the connector.",
      "label": "Connector Type"
    },
    "desc_config": {
      "desc": "Configuration for an Azure Event Hubs bridge.",
      "label": "Azure Event Hubs Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name, used as a human-readable description of the bridge.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The action type.",
      "label": "Action Type"
    },
    "kafka_header_value_encode_mode": {
      "desc": "The encoding mode for headers.\n\n - `none`: Add only strings are added as header values\n - `json`: Encode header values as JSON string",
      "label": "Headers value encode mode"
    },
    "kafka_headers": {
      "desc": "Provide a placeholder for message headers<br/>\ne.g. <code>${pub_props}</code><br/>\nNote that the value of the placeholder must be either an object:\n<code>{\"foo\": \"bar\"}</code>\nor an array of key-value pairs:\n<code>[{\"key\": \"foo\", \"value\": \"bar\"}]</code>",
      "label": "Message Headers"
    },
    "kafka_message": {
      "desc": "Template for rendering a message.",
      "label": "Azure Event Hubs Message Template"
    },
    "kafka_message_key": {
      "desc": "Template for rendering message key. If the template is rendered into a NULL value (i.e. there is no such data field in Rule Engine context) then <code>NULL</code> (but not empty string) is used.",
      "label": "Message Key"
    },
    "kafka_message_timestamp": {
      "desc": "Which timestamp to use. The timestamp is expected to be a millisecond precision Unix epoch which can be in string format, e.g. <code>1661326462115</code> or <code>'1661326462115'</code>. When the desired data field for this template is not found, or if the found data is not a valid integer, the current system timestamp will be used.",
      "label": "Message Timestamp"
    },
    "kafka_message_value": {
      "desc": "Template to render Azure Event Hubs message value. If the template is rendered into a NULL value (i.e. there is no such data field in Rule Engine context) then Azure Event Hubs' <code>NULL</code> (but not empty string) is used.",
      "label": "Message Value"
    },
    "kafka_producer": {
      "desc": "Azure Event Hubs Producer configuration.",
      "label": "Azure Event Hubs Producer"
    },
    "kafka_topic": {
      "desc": "Event Hubs name.  Supports templates (e.g.: `t-${payload.t}`).",
      "label": "Event Hubs Name"
    },
    "max_batch_bytes": {
      "desc": "Maximum bytes to collect in an Azure Event Hubs message batch.",
      "label": "Max Batch Bytes"
    },
    "max_inflight": {
      "desc": "The maximum number of message batches that the producer can send to each partition before it must wait for an acknowledgement.\nSetting a higher number can enhance throughput. However, value above 1 may lead to potential message reordering risks.",
      "label": "Max Inflight"
    },
    "metadata_request_timeout": {
      "desc": "Maximum wait time when fetching metadata from Azure Event Hubs.",
      "label": "Metadata Request Timeout"
    },
    "min_metadata_refresh_interval": {
      "desc": "Minimum time interval the client has to wait before refreshing Azure Event Hubs Kafka broker and topic metadata. Setting too small value may add extra load on Azure Event Hubs.",
      "label": "Min Metadata Refresh Interval"
    },
    "mqtt_topic": {
      "desc": "MQTT topic or topic filter as data source (action input).  If rule action is used as data source, this config should be left empty, otherwise messages will be duplicated in Azure Event Hubs.",
      "label": "Source MQTT Topic"
    },
    "partition_count_refresh_interval": {
      "desc": "The time interval for Azure Event Hubs producer to discover increased number of partitions.\nAfter the number of partitions is increased in Azure Event Hubs, EMQX will start taking the\ndiscovered partitions into account when dispatching messages per <code>partition_strategy</code>.",
      "label": "Partition Count Refresh Interval"
    },
    "partition_strategy": {
      "desc": "Partition strategy is to tell the producer how to dispatch messages to partitions.\n\n<code>random</code>: Randomly pick a partition for each message.\n<code>key_dispatch</code>: Assigns messages to partitions based on a hash of the message key,\nensuring consistent partition for messages with the same key.",
      "label": "Partition Strategy"
    },
    "partitions_limit": {
      "desc": "Limit the number of partitions to produce data for the given topic.\nThe special value `all_partitions` is to utilize all partitions for the topic.\nSetting this to a value which is greater than the total number of partitions in has no effect.",
      "label": "Max Partitions"
    },
    "producer_buffer": {
      "desc": "Configure producer message buffer.\n\nTell Azure Event Hubs producer how to buffer messages when EMQX has more messages to send than Azure Event Hubs can keep up, or when Azure Event Hubs is down.",
      "label": "Message Buffer"
    },
    "producer_health_check_topic": {
      "desc": "Topic name used exclusively for more accurate connector health checks.",
      "label": "Connector health check topic"
    },
    "producer_kafka_ext_header_key": {
      "desc": "Key of the Azure Event Hubs header. Placeholders in format of ${var} are supported.",
      "label": "Azure Event Hubs extra header key."
    },
    "producer_kafka_ext_header_value": {
      "desc": "Value of the header. Placeholders in format of ${var} are supported.",
      "label": "Extra Headers Value"
    },
    "producer_kafka_ext_headers": {
      "desc": "Please provide more key-value pairs for Azure Event Hubs headers<br/>\nThe key-value pairs here will be combined with the\nvalue of <code>kafka_headers</code> field before sending to Azure Event Hubs.",
      "label": "Extra Azure Event Hubs headers"
    },
    "producer_kafka_opts": {
      "desc": "Azure Event Hubs producer configs.",
      "label": "Azure Event Hubs Producer"
    },
    "producer_opts": {
      "desc": "Local MQTT data source and Azure Event Hubs bridge configs.",
      "label": "MQTT to Azure Event Hubs"
    },
    "query_mode": {
      "desc": "Query mode. Optional 'sync/async', default 'async'.",
      "label": "Query mode"
    },
    "required_acks": {
      "desc": "The acknowledgement criteria for the partition leader. It determines the level of confirmation required from partition replicas before sending an acknowledgement back to the producer.\n\n<code>all_isr</code>: Require all in-sync replicas to acknowledge.\n<code>leader_only</code>: Require only the partition-leader's acknowledgement.\n<code>none</code>: No need for Kafka to acknowledge at all.",
      "label": "Required Acks"
    },
    "server_name_indication": {
      "desc": "Server Name Indication (SNI) setting for TLS handshake.<br/>\n- <code>auto</code>: The client will use <code>\"servicebus.windows.net\"</code> as SNI.<br/>\n- <code>disable</code>: If you wish to prevent the client from sending the SNI.<br/>\n- Other string values it will be sent as-is.",
      "label": "SNI"
    },
    "socket_nodelay": {
      "desc": "When set to 'true', TCP buffer is sent as soon as possible. Otherwise, the OS kernel may buffer small TCP packets for a while (40 ms by default).",
      "label": "No Delay"
    },
    "socket_opts": {
      "desc": "Extra socket options.",
      "label": "Socket Options"
    },
    "socket_receive_buffer": {
      "desc": "Fine tune the socket receive buffer. The default value is tuned for high throughput.",
      "label": "Socket Receive Buffer Size"
    },
    "socket_send_buffer": {
      "desc": "Fine tune the socket send buffer. The default value is tuned for high throughput.",
      "label": "Socket Send Buffer Size"
    },
    "socket_tcp_keepalive": {
      "desc": "Enable TCP keepalive.\nThe value is three comma separated numbers in the format of 'Idle,Interval,Probes'\n - Idle: The number of seconds a connection needs to be idle before the server begins to send out keep-alive probes (Linux default 7200).\n - Interval: The number of seconds between TCP keep-alive probes (Linux default 75).\n - Probes: The maximum number of TCP keep-alive probes to send before giving up and killing the connection if no response is obtained from the other end (Linux default 9).\nFor example \"240,30,5\" means: TCP keepalive probes are sent after the connection is idle for 240 seconds, and the probes are sent every 30 seconds until a response is received, if it misses 5 consecutive responses, the connection should be closed.\nDefault: 'none'",
      "label": "TCP keepalive options"
    },
    "ssl_client_opts": {
      "desc": "TLS/SSL options for Azure Event Hubs client.",
      "label": "TLS/SSL options"
    },
    "sync_query_timeout": {
      "desc": "This parameter defines the timeout limit for synchronous queries. It applies only when the bridge query mode is configured to 'sync'.",
      "label": "Synchronous Query Timeout"
    }
  },
  "emqx_bridge_cassandra": {
    "action_parameters": {
      "desc": "Action specific configs.",
      "label": "Action"
    },
    "cassandra_action": {
      "desc": "Action configs.",
      "label": "Action"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "cql_template": {
      "desc": "CQL Template",
      "label": "CQL Template"
    },
    "desc_config": {
      "desc": "Configuration for a Cassandra bridge.",
      "label": "Cassandra Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to Cassandra. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.<br/>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    }
  },
  "emqx_bridge_cassandra_connector": {
    "config": {
      "desc": "Cassandra connection config",
      "label": "Connection config"
    },
    "keyspace": {
      "desc": "Keyspace name to connect to.",
      "label": "Keyspace"
    },
    "servers": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port][,Host2:Port]`.<br/>\nThe Cassandra default port 9042 is used if `[:Port]` is not specified.",
      "label": "Servers"
    }
  },
  "emqx_bridge_clickhouse": {
    "action_parameters": {
      "desc": "Action specific configs.",
      "label": "Action"
    },
    "batch_value_separator": {
      "desc": "The default value ',' works for the VALUES format. You can also use other separator if other format is specified. See [INSERT INTO Statement](https://clickhouse.com/docs/en/sql-reference/statements/insert-into).",
      "label": "Batch Value Separator"
    },
    "clickhouse_action": {
      "desc": "Action configs.",
      "label": "Action"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for a Clickhouse bridge.",
      "label": "Clickhouse Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to Clickhouse. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.<br/>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "sql_template": {
      "desc": "The template string can contain ${field} placeholders for message metadata and payload field. Make sure that the inserted values are formatted and escaped correctly. [Prepared Statement](https://docs.emqx.com/en/enterprise/v5.0/data-integration/data-bridges.html#Prepared-Statement) is not supported.",
      "label": "SQL Template"
    }
  },
  "emqx_bridge_clickhouse_connector": {
    "base_url": {
      "desc": "The HTTP URL to the Clickhouse server that you want to connect to (for example http://myhostname:8123)",
      "label": "Server URL"
    },
    "connect_timeout": {
      "desc": "The timeout when connecting to the Clickhouse server.",
      "label": "Clickhouse Timeout"
    }
  },
  "emqx_bridge_confluent_producer": {
    "actions": {
      "desc": "The configuration for an action.",
      "label": "Action Config"
    },
    "auth_sasl_mechanism": {
      "desc": "SASL authentication mechanism.",
      "label": "Mechanism"
    },
    "auth_sasl_password": {
      "desc": "Confluent Secret.",
      "label": "Secret"
    },
    "auth_sasl_username": {
      "desc": "Confluent Key.",
      "label": "Key"
    },
    "auth_username_password": {
      "desc": "Username/password based authentication.",
      "label": "Username/password Auth"
    },
    "authentication": {
      "desc": "Authentication configs.",
      "label": "Authentication"
    },
    "bootstrap_hosts": {
      "desc": "A comma separated list of Confluent Kafka <code>host[:port]</code> namespace endpoints to bootstrap the client.  Default port number is 9092.",
      "label": "Bootstrap Server"
    },
    "bridge_v2_type": {
      "desc": "The type of the action.",
      "label": "Action Type"
    },
    "buffer_memory_overload_protection": {
      "desc": "Applicable when buffer mode is set to <code>memory</code>\nEMQX will drop old buffered messages under high memory pressure. The high memory threshold is defined in config <code>sysmon.os.sysmem_high_watermark</code>. NOTE: This config only works on Linux.",
      "label": "Memory Overload Protection"
    },
    "buffer_mode": {
      "desc": "Message buffer mode.\n\n<code>memory</code>: Buffer all messages in memory. The messages will be lost in case of EMQX node restart\n<code>disk</code>: Buffer all messages on disk. The messages on disk are able to survive EMQX node restart.\n<code>hybrid</code>: Buffer message in memory first, when up to certain limit (see <code>segment_bytes</code> config for more information), then start offloading messages to disk, Like <code>memory</code> mode, the messages will be lost in case of EMQX node restart.",
      "label": "Buffer Mode"
    },
    "buffer_per_partition_limit": {
      "desc": "Number of bytes allowed to buffer for each partition. When this limit is exceeded, older messages will be discarded to make room for new messages to be buffered.",
      "label": "Per-partition Buffer Limit"
    },
    "buffer_segment_bytes": {
      "desc": "Applicable when buffer mode is set to <code>disk</code> or <code>hybrid</code>.\nThis setting specifies the size of each buffer file stored on disk.",
      "label": "Segment File Bytes"
    },
    "compression": {
      "desc": "Specify the method of compression.",
      "label": "Compression"
    },
    "config_enable": {
      "desc": "Enable (true) or disable (false) this config.",
      "label": "Enable or Disable"
    },
    "connect_timeout": {
      "desc": "Maximum wait time for TCP connection establishment (including authentication time if enabled).",
      "label": "Connect Timeout"
    },
    "connector_type": {
      "desc": "The type of the connector.",
      "label": "Connector Type"
    },
    "desc_config": {
      "desc": "Configuration for a Confluent action.",
      "label": "Confluent Action Configuration"
    },
    "desc_name": {
      "desc": "Action name, used as a human-readable description of the action.",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The action type.",
      "label": "Action Type"
    },
    "kafka_header_value_encode_mode": {
      "desc": "The encoding mode for headers.\n\n - `none`: Add only strings are added as header values\n - `json`: Encode header values as JSON string",
      "label": "Headers value encode mode"
    },
    "kafka_headers": {
      "desc": "Provide a placeholder for message headers<br/>\ne.g. <code>${pub_props}</code><br/>\nNote that the value of the placeholder must be either an object:\n<code>{\"foo\": \"bar\"}</code>\nor an array of key-value pairs:\n<code>[{\"key\": \"foo\", \"value\": \"bar\"}]</code>",
      "label": "Message Headers"
    },
    "kafka_message": {
      "desc": "Template for rendering a message.",
      "label": "Confluent Message Template"
    },
    "kafka_message_key": {
      "desc": "Template for rendering message key. If the template is rendered into a NULL value (i.e. there is no such data field in Rule Engine context) then <code>NULL</code> (but not empty string) is used.",
      "label": "Message Key"
    },
    "kafka_message_timestamp": {
      "desc": "Which timestamp to use. The timestamp is expected to be a millisecond precision Unix epoch which can be in string format, e.g. <code>1661326462115</code> or <code>'1661326462115'</code>. When the desired data field for this template is not found, or if the found data is not a valid integer, the current system timestamp will be used.",
      "label": "Message Timestamp"
    },
    "kafka_message_value": {
      "desc": "Template to render Confluent message value. If the template is rendered into a NULL value (i.e. there is no such data field in Rule Engine context) then Confluent's <code>NULL</code> (but not empty string) is used.",
      "label": "Message Value"
    },
    "kafka_producer": {
      "desc": "Confluent Producer configuration.",
      "label": "Confluent Producer"
    },
    "kafka_topic": {
      "desc": "Kafka topic name.  Supports templates (e.g.: `t-${payload.t}`).",
      "label": "Kafka Topic Name"
    },
    "max_batch_bytes": {
      "desc": "Maximum bytes to collect in a Confluent message batch. Most of the Kafka brokers default to a limit of 1 MB batch size. EMQX's default value is less than 1 MB in order to compensate Kafka message encoding overheads (especially when each individual message is very small). When a single message is over the limit, it is still sent (as a single element batch).",
      "label": "Max Batch Bytes"
    },
    "max_inflight": {
      "desc": "The maximum number of message batches that the producer can send to each partition before it must wait for an acknowledgement.\nSetting a higher number can enhance throughput. However, value above 1 may lead to potential message reordering risks.",
      "label": "Max Inflight"
    },
    "metadata_request_timeout": {
      "desc": "Maximum wait time when fetching metadata from Confluent.",
      "label": "Metadata Request Timeout"
    },
    "min_metadata_refresh_interval": {
      "desc": "Minimum time interval the client has to wait before refreshing Confluent Kafka broker and topic metadata. Setting too small value may add extra load on Confluent.",
      "label": "Min Metadata Refresh Interval"
    },
    "mqtt_topic": {
      "desc": "MQTT topic or topic filter as data source (action input).  If rule action is used as data source, this config should be left empty, otherwise messages will be duplicated in Confluent.",
      "label": "Source MQTT Topic"
    },
    "partition_count_refresh_interval": {
      "desc": "The time interval for Confluent producer to discover increased number of partitions.\nAfter the number of partitions is increased in Confluent, EMQX will start taking the\ndiscovered partitions into account when dispatching messages per <code>partition_strategy</code>.",
      "label": "Partition Count Refresh Interval"
    },
    "partition_strategy": {
      "desc": "Partition strategy is to tell the producer how to dispatch messages to partitions.\n\n<code>random</code>: Randomly pick a partition for each message.\n<code>key_dispatch</code>: Assigns messages to partitions based on a hash of the message key,\nensuring consistent partition for messages with the same key.",
      "label": "Partition Strategy"
    },
    "partitions_limit": {
      "desc": "Limit the number of partitions to produce data for the given topic.\nThe special value `all_partitions` is to utilize all partitions for the topic.\nSetting this to a value which is greater than the total number of partitions in has no effect.",
      "label": "Max Partitions"
    },
    "producer_buffer": {
      "desc": "Configure producer message buffer.\n\nTell Confluent producer how to buffer messages when EMQX has more messages to send than Confluent can keep up, or when Confluent is down.",
      "label": "Message Buffer"
    },
    "producer_health_check_topic": {
      "desc": "Topic name used exclusively for more accurate connector health checks.",
      "label": "Connector health check topic"
    },
    "producer_kafka_ext_header_key": {
      "desc": "Key of the Confluent header. Placeholders in format of ${var} are supported.",
      "label": "Confluent extra header key."
    },
    "producer_kafka_ext_header_value": {
      "desc": "Value of the header. Placeholders in format of ${var} are supported.",
      "label": "Extra Headers Value"
    },
    "producer_kafka_ext_headers": {
      "desc": "Please provide more key-value pairs for Confluent headers<br/>\nThe key-value pairs here will be combined with the\nvalue of <code>kafka_headers</code> field before sending to Confluent.",
      "label": "Extra Confluent headers"
    },
    "producer_kafka_opts": {
      "desc": "Confluent producer configs.",
      "label": "Confluent Producer"
    },
    "producer_opts": {
      "desc": "Local MQTT data source and Confluent bridge configs.",
      "label": "MQTT to Confluent"
    },
    "query_mode": {
      "desc": "Query mode. Optional 'sync/async', default 'async'.",
      "label": "Query mode"
    },
    "required_acks": {
      "desc": "The acknowledgement criteria for the partition leader. It determines the level of confirmation required from partition replicas before sending an acknowledgement back to the producer.\n\n<code>all_isr</code>: Require all in-sync replicas to acknowledge.\n<code>leader_only</code>: Require only the partition-leader's acknowledgement.\n<code>none</code>: No need for Kafka to acknowledge at all.",
      "label": "Required Acks"
    },
    "server_name_indication": {
      "desc": "Server Name Indication (SNI) setting for TLS handshake.<br/>\n- <code>auto</code>: The client will use <code>\"servicebus.windows.net\"</code> as SNI.<br/>\n- <code>disable</code>: If you wish to prevent the client from sending the SNI.<br/>\n- Other string values it will be sent as-is.",
      "label": "SNI"
    },
    "socket_nodelay": {
      "desc": "When set to 'true', TCP buffer is sent as soon as possible. Otherwise, the OS kernel may buffer small TCP packets for a while (40 ms by default).",
      "label": "No Delay"
    },
    "socket_opts": {
      "desc": "Extra socket options.",
      "label": "Socket Options"
    },
    "socket_receive_buffer": {
      "desc": "Fine tune the socket receive buffer. The default value is tuned for high throughput.",
      "label": "Socket Receive Buffer Size"
    },
    "socket_send_buffer": {
      "desc": "Fine tune the socket send buffer. The default value is tuned for high throughput.",
      "label": "Socket Send Buffer Size"
    },
    "socket_tcp_keepalive": {
      "desc": "Enable TCP keepalive.\nThe value is three comma separated numbers in the format of 'Idle,Interval,Probes'\n - Idle: The number of seconds a connection needs to be idle before the server begins to send out keep-alive probes (Linux default 7200).\n - Interval: The number of seconds between TCP keep-alive probes (Linux default 75).\n - Probes: The maximum number of TCP keep-alive probes to send before giving up and killing the connection if no response is obtained from the other end (Linux default 9).\nFor example \"240,30,5\" means: TCP keepalive probes are sent after the connection is idle for 240 seconds, and the probes are sent every 30 seconds until a response is received, if it misses 5 consecutive responses, the connection should be closed.\nDefault: 'none'",
      "label": "TCP keepalive options"
    },
    "ssl_client_opts": {
      "desc": "TLS/SSL options for Confluent client.",
      "label": "TLS/SSL options"
    },
    "sync_query_timeout": {
      "desc": "This parameter defines the timeout limit for synchronous queries. It applies only when the action query mode is configured to 'sync'.",
      "label": "Synchronous Query Timeout"
    }
  },
  "emqx_bridge_couchbase_action_schema": {
    "couchbase": {
      "desc": "Action that takes incoming events and uploads them to the Couchbase service.",
      "label": "Upload to Couchbase"
    },
    "max_retries": {
      "desc": "Max retry times if error on sending request.",
      "label": "Max Retries"
    },
    "parameters": {
      "desc": "Set of parameters for the action.",
      "label": "Couchbase action parameters"
    },
    "sql": {
      "desc": "SQL Template",
      "label": "SQL Template"
    }
  },
  "emqx_bridge_couchbase_connector_schema": {
    "config_connector": {
      "desc": "Configuration for a connector to Couchbase service.",
      "label": "Couchbase Connector Configuration"
    },
    "connect_timeout": {
      "desc": "The timeout when connecting to the HTTP server.",
      "label": "Connect Timeout"
    },
    "password": {
      "desc": "Password for Couchbase service.",
      "label": "Password"
    },
    "pipelining": {
      "desc": "A positive integer. Whether to send HTTP requests continuously, when set to 1, it means that after each HTTP request is sent, you need to wait for the server to return and then continue to send the next request.",
      "label": "HTTP Pipelining"
    },
    "pool_size": {
      "desc": "The pool size.",
      "label": "Pool Size"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\n  A host entry has the following form: `Host[:Port]`.<br/>\n  The Couchbase default query service port 8093 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "username": {
      "desc": "Username for Couchbase service.",
      "label": "Username"
    }
  },
  "emqx_bridge_datalayers": {
    "action_parameters": {
      "desc": "Additional parameters specific to this action type",
      "label": "Action Parameters"
    },
    "connector": {
      "desc": "Datalayers Connector Configs",
      "label": "Datalayers Connector"
    },
    "datalayers_action": {
      "desc": "Action to interact with a Datalayers connector",
      "label": "Datalayers Action"
    },
    "desc_config": {
      "desc": "Configuration for a Datalayers bridge.",
      "label": "Datalayers Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type.",
      "label": "Bridge Type"
    },
    "write_syntax": {
      "desc": "Conf of InfluxDB line protocol to write data points. It is a text-based format that provides the measurement, tag set, field set, and timestamp of a data point, and placeholder supported.\nSee also [InfluxDB 1.8 Line Protocol](https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/) <br/>\nTLDR:<br/>\n```\n<measurement>[,<tag_key>=<tag_value>[,<tag_key>=<tag_value>]] <field_key>=<field_value>[,<field_key>=<field_value>] [<timestamp>]\n```\nPlease note that a placeholder for an integer value must be annotated with a suffix `i`. For example `${payload.int_value}i`.",
      "label": "Write Syntax"
    }
  },
  "emqx_bridge_datalayers_connector": {
    "database": {
      "desc": "Datalayers database.",
      "label": "Database"
    },
    "datalayers_api": {
      "desc": "Datalayers protocol.",
      "label": "HTTP API Protocol"
    },
    "datalayers_parameters": {
      "desc": "Set of parameters specific for the given type of this Datalayers connector.",
      "label": "Datalayers Specific Parameters"
    },
    "password": {
      "desc": "Datalayers password.",
      "label": "Password"
    },
    "precision": {
      "desc": "Datalayers time precision.",
      "label": "Time Precision"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe Datalayers default port 8361 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "username": {
      "desc": "Datalayers username.",
      "label": "Username"
    }
  },
  "emqx_bridge_dynamo": {
    "action_parameters": {
      "desc": "Action specific configuration.",
      "label": "Action"
    },
    "config_connector": {
      "desc": "Configuration for an DynamoDB connector.",
      "label": "DynamoDB Connector Configuration"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for a DynamoDB bridge.",
      "label": "DynamoDB Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "dynamo_action": {
      "desc": "Configuration for DynamoDB action.",
      "label": "DynamoDB Action Configuration"
    },
    "hash_key": {
      "desc": "DynamoDB Hash Key"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to DynamoDB. All MQTT `PUBLISH` messages with the topic\nmatching the `local_topic` will be forwarded.<br/>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also `local_topic` is\nconfigured, then both the data got from the rule and the MQTT messages that match `local_topic`\nwill be forwarded.",
      "label": "Local Topic"
    },
    "range_key": {
      "desc": "DynamoDB Range Key"
    },
    "template": {
      "desc": "Template, the default value is empty. When this value is empty the whole message will be stored in the database.<br>\nThe template can be any valid JSON with placeholders and make sure all keys for table are here, example:<br>\n  <code>{\"id\" : \"${id}\", \"clientid\" : \"${clientid}\", \"data\" : \"${payload.data}\"}</code>",
      "label": "Template"
    }
  },
  "emqx_bridge_dynamo_connector": {
    "aws_access_key_id": {
      "desc": "Access Key ID for connecting to DynamoDB.",
      "label": "AWS Access Key ID"
    },
    "aws_secret_access_key": {
      "desc": "AWS Secret Access Key for connecting to DynamoDB.",
      "label": "AWS Secret Access Key"
    },
    "region": {
      "desc": "Region of AWS Dynamo"
    },
    "table": {
      "desc": "DynamoDB Table.",
      "label": "Table "
    },
    "url": {
      "desc": "The url of DynamoDB endpoint.",
      "label": "DynamoDB Endpoint"
    }
  },
  "emqx_bridge_es": {
    "action_config": {
      "desc": "ElasticSearch Action Configuration",
      "label": "ElasticSearch Action Config"
    },
    "action_create": {
      "desc": "Adds a JSON document to the specified index and makes it searchable.\nIf the target is an index and the document already exists,\nthe request updates the document and increments its version.",
      "label": "Create Doc"
    },
    "action_delete": {
      "desc": "Removes a JSON document from the specified index.",
      "label": "Delete Doc"
    },
    "action_parameters": {
      "desc": "ElasticSearch action parameters",
      "label": "Parameters"
    },
    "action_resource_opts": {
      "desc": "Resource options.",
      "label": "Resource Options"
    },
    "action_update": {
      "desc": "Updates a document using the specified doc.",
      "label": "Update Doc"
    },
    "auth_basic": {
      "desc": "Parameters for basic authentication.",
      "label": "Basic auth params"
    },
    "config_auth_basic_password": {
      "desc": "The password to authenticate against Elastic Search.",
      "label": "HTTP Basic Auth Password"
    },
    "config_auth_basic_username": {
      "desc": "The username to authenticate against Elastic Search.",
      "label": "HTTP Basic Auth Username"
    },
    "config_authentication": {
      "desc": "Authentication configuration",
      "label": "Authentication"
    },
    "config_doc_as_upsert": {
      "desc": "Instead of sending a partial doc plus an upsert doc,\nyou can set doc_as_upsert to true to use the contents of doc as the upsert value.",
      "label": "doc_as_upsert"
    },
    "config_enable": {
      "desc": "Enable or disable this action.",
      "label": "Enable Or Disable Action"
    },
    "config_max_retries": {
      "desc": "HTTP request max retry times if failed.",
      "label": "HTTP Request Max Retries"
    },
    "config_overwrite": {
      "desc": "Set to false If a document with the specified _id already exists(conflict), the operation will fail.",
      "label": "overwrite"
    },
    "config_parameters_doc": {
      "desc": "JSON document. If undefined, rule engine will use JSON format to serialize all visible inputs, such as clientid, topic, payload etc.",
      "label": "doc"
    },
    "config_parameters_id": {
      "desc": "The document ID. If no ID is specified, a document ID is automatically generated.",
      "label": "_id"
    },
    "config_parameters_index": {
      "desc": "Name of index, or index alias to perform the action on.\nThis parameter is required.",
      "label": "_index"
    },
    "config_parameters_require_alias": {
      "desc": "If true, the action must target an index alias. Defaults to false.",
      "label": "_require_alias"
    },
    "config_require_alias": {
      "desc": "If true, the requests actions must target an index alias. Defaults to false",
      "label": "Require Alias"
    },
    "config_routing": {
      "desc": "Custom value used to route operations to a specific shard.",
      "label": "Routing"
    },
    "config_target": {
      "desc": "Name of the data stream, index, or index alias to perform bulk actions on",
      "label": "Target"
    },
    "config_wait_for_active_shards": {
      "desc": "The number of shard copies that must be active before proceeding with the operation.\nSet to all or any positive integer up to the total number of shards in the index (number_of_replicas+1).\nDefault: 1, the primary shard"
    },
    "desc_config": {
      "desc": "Configuration for Elastic Search.",
      "label": "Elastic Search Action Configuration"
    },
    "desc_name": {
      "desc": "A human-readable identifier.",
      "label": "Action Name"
    },
    "elasticsearch": {
      "desc": "Elasticsearch Bridge",
      "label": "ElasticSearch"
    }
  },
  "emqx_bridge_es_connector": {
    "auth_basic": {
      "desc": "Parameters for basic authentication.",
      "label": "Basic auth params"
    },
    "config_auth_basic_password": {
      "desc": "The password as configured at the ElasticSearch REST interface",
      "label": "HTTP Basic Auth Password"
    },
    "config_auth_basic_username": {
      "desc": "The username as configured at the ElasticSearch REST interface",
      "label": "HTTP Basic Auth Username"
    },
    "config_authentication": {
      "desc": "Authentication configuration",
      "label": "Authentication"
    },
    "config_max_retries": {
      "desc": "HTTP request max retry times if failed.",
      "label": "HTTP Request Max Retries"
    },
    "desc_config": {
      "desc": "Configuration for ElasticSearch bridge.",
      "label": "ElasticSearch Bridge Configuration"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.\nA host entry has the following form: `Host[:Port]`.\nThe Elasticsearch default port 9200 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    }
  },
  "emqx_bridge_gcp_pubsub": {
    "attributes_template": {
      "desc": "The template for formatting the outgoing message attributes.  Undefined values will be rendered as empty string values.  Empty keys are removed from the attribute map.",
      "label": "Attributes template"
    },
    "connect_timeout": {
      "desc": "The timeout when connecting to the HTTP server.",
      "label": "Connect Timeout"
    },
    "consumer": {
      "desc": "GCP PubSub Consumer configuration.",
      "label": "GCP PubSub Consumer"
    },
    "consumer_mqtt_payload": {
      "desc": "The template for transforming the incoming GCP PubSub message.  By default, it will use JSON format to serialize inputs from the GCP PubSub message.  Available fields are:\n<code>message_id</code>: the message ID assigned by GCP PubSub.\n<code>publish_time</code>: message timestamp assigned by GCP PubSub.\n<code>topic</code>: GCP PubSub topic.\n<code>value</code>: the payload of the GCP PubSub message.  Omitted if there's no payload.\n<code>attributes</code>: an object containing string key-value pairs.  Omitted if there are no attributes.\n<code>ordering_key</code>: GCP PubSub message ordering key.  Omitted if there's none.",
      "label": "Payload Template"
    },
    "consumer_mqtt_qos": {
      "desc": "MQTT QoS level applied when publishing messages that are consumed from GCP PubSub.",
      "label": "QoS"
    },
    "consumer_mqtt_topic": {
      "desc": "Local topic to which consumed GCP PubSub messages should be published to.",
      "label": "MQTT Topic"
    },
    "consumer_opts": {
      "desc": "Local MQTT publish and GCP PubSub consumer configs.",
      "label": "GCP PubSub to MQTT"
    },
    "consumer_pubsub_topic": {
      "desc": "GCP PubSub topic to consume from.",
      "label": "GCP PubSub"
    },
    "consumer_pull_max_messages": {
      "desc": "The maximum number of messages to retrieve from GCP PubSub in a single pull request. The actual number may be less than the specified value.",
      "label": "Maximum Messages to Pull"
    },
    "consumer_topic_mapping": {
      "desc": "Defines the mapping between GCP PubSub topics and MQTT topics. Must contain at least one item.",
      "label": "Topic Mapping"
    },
    "desc_config": {
      "desc": "Configuration for a GCP PubSub bridge.",
      "label": "GCP PubSub Configuration"
    },
    "desc_name": {
      "desc": "Action name, used as a human-readable identifier.",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The action type.",
      "label": "Action Type"
    },
    "kv_pair_desc": {
      "desc": "Key-value pair.",
      "label": "Key-value pair"
    },
    "kv_pair_key": {
      "desc": "Key",
      "label": "Key"
    },
    "kv_pair_value": {
      "desc": "Value",
      "label": "Value"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to GCP PubSub. All MQTT 'PUBLISH' messages with the topic\nmatching `local_topic` will be forwarded.<br/>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "max_retries": {
      "desc": "Max retry times if an error occurs when sending a request.",
      "label": "Max Retries"
    },
    "ordering_key_template": {
      "desc": "The template for formatting the outgoing message ordering key.  Undefined values will be rendered as empty string values.  This value will not be added to the message if it's empty.",
      "label": "Ordering Key template"
    },
    "payload_template": {
      "desc": "The template for formatting the outgoing messages.  If undefined, will send all the available context in JSON format.",
      "label": "Payload template"
    },
    "pipelining": {
      "desc": "A positive integer. Whether to send HTTP requests continuously, when set to 1, it means that after each HTTP request is sent, you need to wait for the server to return and then continue to send the next request.",
      "label": "HTTP Pipelining"
    },
    "pool_size": {
      "desc": "The pool size.",
      "label": "Pool Size"
    },
    "producer_attributes": {
      "desc": "List of key-value pairs representing templates to construct the attributes for a given GCP PubSub message.  Both keys and values support the placeholder `${var_name}` notation.  Keys that are undefined or resolve to an empty string are omitted from the attribute map.",
      "label": "Attributes Template"
    },
    "producer_ordering_key": {
      "desc": "Template for the Ordering Key of a given GCP PubSub message.  If the resolved value is undefined or an empty string, the ordering key property is omitted from the message.",
      "label": "Ordering Key Template"
    },
    "pubsub_topic": {
      "desc": "The GCP PubSub topic to publish messages to.",
      "label": "GCP PubSub Topic"
    },
    "service_account_json": {
      "desc": "JSON containing the GCP Service Account credentials to be used with PubSub.\nWhen a GCP Service Account is created (as described in https://developers.google.com/identity/protocols/oauth2/service-account#creatinganaccount), you have the option of downloading the credentials in JSON form.  That's the file needed.",
      "label": "GCP Service Account Credentials"
    }
  },
  "emqx_bridge_gcp_pubsub_consumer_schema": {
    "config_connector": {
      "desc": "Configuration for a GCP PubSub Consumer Client.",
      "label": "GCP PubSub Consumer Client Configuration"
    },
    "consumer_source": {
      "desc": "Source configs.",
      "label": "Source"
    },
    "source_parameters": {
      "desc": "Source specific configs.",
      "label": "Source Specific Configs"
    }
  },
  "emqx_bridge_gcp_pubsub_producer_schema": {
    "action_parameters": {
      "desc": "Action specific configs.",
      "label": "Action"
    },
    "config_connector": {
      "desc": "Configuration for a GCP PubSub Producer Client.",
      "label": "GCP PubSub Producer Client Configuration"
    },
    "producer_action": {
      "desc": "Action configs.",
      "label": "Action"
    }
  },
  "emqx_bridge_greptimedb": {
    "action_parameters": {
      "desc": "Additional parameters specific to this action type",
      "label": "Action Parameters"
    },
    "config_enable": {
      "desc": "Enable or disable this action.",
      "label": "Enable Or Disable Action"
    },
    "connector": {
      "desc": "GreptimeDB Connector Configs",
      "label": "GreptimeDB Connector"
    },
    "desc_config": {
      "desc": "Configuration for an GreptimeDB action.",
      "label": "GreptimeDB Action Configuration"
    },
    "desc_name": {
      "desc": "The name of the action.",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The type of the action.",
      "label": "Action Type"
    },
    "greptimedb_action": {
      "desc": "Action to interact with a GreptimeDB connector",
      "label": "GreptimeDB Action"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to the GreptimeDB. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.<br/>\nNOTE: If this Sink is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "write_syntax": {
      "desc": "Conf of GreptimeDB gRPC protocol to write data points. Write syntax is a text-based format that provides the measurement, tag set, field set, and timestamp of a data point, and placeholder supported, which is the same as InfluxDB line protocol.\nSee also [InfluxDB 2.3 Line Protocol](https://docs.influxdata.com/influxdb/v2.3/reference/syntax/line-protocol/) and\n[GreptimeDB 1.8 Line Protocol](https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/) <br/>\nTLDR:<br/>\n```\n<measurement>[,<tag_key>=<tag_value>[,<tag_key>=<tag_value>]] <field_key>=<field_value>[,<field_key>=<field_value>] [<timestamp>]\n```\nPlease note that a placeholder for an integer value must be annotated with a suffix `i`. For example `${payload.int_value}i`.",
      "label": "Write Syntax"
    }
  },
  "emqx_bridge_greptimedb_connector": {
    "dbname": {
      "desc": "GreptimeDB database.",
      "label": "Database"
    },
    "greptimedb": {
      "desc": "GreptimeDB's protocol. Support GreptimeDB v1.8 and before.",
      "label": "HTTP API Protocol"
    },
    "password": {
      "desc": "GreptimeDB password.",
      "label": "Password"
    },
    "precision": {
      "desc": "GreptimeDB time precision.",
      "label": "Time Precision"
    },
    "protocol": {
      "desc": "GreptimeDB's protocol. gRPC API.",
      "label": "Protocol"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe GreptimeDB default port 8086 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "username": {
      "desc": "GreptimeDB username.",
      "label": "Username"
    }
  },
  "emqx_bridge_hstreamdb": {
    "action_parameters": {
      "desc": "Action specific configuration.",
      "label": "Action"
    },
    "aggregation_pool_size": {
      "desc": "The size of the record aggregation pool. A larger aggregation pool size can lead to enhanced parallelization but may also result in reduced efficiency due to smaller batch sizes.",
      "label": "Aggregation Pool Size"
    },
    "batch_interval": {
      "desc": "Maximum interval that is allowed between two successive (batch) request.",
      "label": "Max Batch Interval"
    },
    "batch_size": {
      "desc": "Maximum number of insert data clauses that can be sent in a single request.",
      "label": "Max Batch Append Count"
    },
    "config_connector": {
      "desc": "Configuration for an HStreamDB connector.",
      "label": "HStreamDB Connector Configuration"
    },
    "config_direction": {
      "desc": "The direction of this bridge, MUST be 'egress'",
      "label": "Bridge Direction"
    },
    "desc_config": {
      "desc": "Configuration for an HStreamDB action.",
      "label": "HStreamDB Action Configuration"
    },
    "desc_connector": {
      "desc": "Generic configuration for the connector.",
      "label": "Connector Generic Configuration"
    },
    "desc_name": {
      "desc": "Action name, a human-readable identifier.",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The type of the action.",
      "label": "Action Type"
    },
    "grpc_flush_timeout": {
      "desc": "Time interval for flushing gRPC calls to the HStreamDB server.",
      "label": "gRPC Flush Interval"
    },
    "hstreamdb_action": {
      "desc": "Configuration for HStreamDB action.",
      "label": "HStreamDB Action Configuration"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to the HStreamDB. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.<br/>\nNOTE: If this action is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "max_batches": {
      "desc": "Maximum number of unconfirmed batches in the flush queue.",
      "label": "Max Batches"
    },
    "record_template": {
      "desc": "The HStream Record template to be forwarded to the HStreamDB. Placeholders supported.<br>\nNOTE: When you use `raw record` template (which means the data is not a valid JSON), you should use `read` or `subscription` in HStream to get the data.",
      "label": "HStream Record"
    },
    "writer_pool_size": {
      "desc": "The size of the writer pool. A larger pool may increase parallelization and concurrent write operations, potentially boosting throughput. Trade-offs include greater memory consumption and possible resource contention.",
      "label": "Writer Pool Size"
    }
  },
  "emqx_bridge_hstreamdb_connector": {
    "config": {
      "desc": "HStreamDB connection config",
      "label": "Connection config"
    },
    "grpc_timeout": {
      "desc": "The timeout for HStreamDB gRPC requests.",
      "label": "HStreamDB gRPC Timeout"
    },
    "name": {
      "desc": "A human-readable identifier for the connector.",
      "label": "Connector Name"
    },
    "partition_key": {
      "desc": "HStreamDB Partition Key. Placeholders supported.",
      "label": "HStreamDB Partition Key"
    },
    "pool_size": {
      "desc": "The size of the aggregation pool and the writer pool (see the description of the HStreamDB action for more information about these pools). Larger pool sizes can enhance parallelization but may also reduce efficiency due to smaller batch sizes.",
      "label": "HStreamDB Pool Size"
    },
    "stream_name": {
      "desc": "HStreamDB Stream Name.",
      "label": "HStreamDB Stream Name"
    },
    "type": {
      "desc": "The Connector Type.",
      "label": "Connector Type"
    },
    "url": {
      "desc": "HStreamDB Server URL. This URL will be used as the gRPC HTTP server address.",
      "label": "HStreamDB Server URL"
    }
  },
  "emqx_bridge_http_connector": {
    "body": {
      "desc": "HTTP request body.",
      "label": "HTTP Body"
    },
    "connect_timeout": {
      "desc": "The timeout when connecting to the HTTP server.",
      "label": "Connect Timeout"
    },
    "enable_pipelining": {
      "desc": "The maximum number of HTTP requests that can be sent before an HTTP response is received.\n\nSetting this to 1 is equivalent to turning off HTTP pipelining, and the EMQX must receive a response to the previous HTTP request before sending the next HTTP request.",
      "label": "HTTP Pipelining"
    },
    "headers": {
      "desc": "List of HTTP headers.",
      "label": "HTTP Headers"
    },
    "max_retries": {
      "desc": "Max retry times if error on sending request.",
      "label": "Max Retries"
    },
    "method": {
      "desc": "HTTP method.",
      "label": "HTTP Method"
    },
    "path": {
      "desc": "URL path.",
      "label": "URL Path"
    },
    "pool_size": {
      "desc": "The pool size.",
      "label": "Pool Size"
    },
    "pool_type": {
      "desc": "The type of the pool. Can be one of `random`, `hash`.",
      "label": "Pool Type"
    },
    "request": {
      "desc": "Configure HTTP request parameters.",
      "label": "Request"
    },
    "request_timeout": {
      "desc": "HTTP request timeout.",
      "label": "Request Timeout"
    }
  },
  "emqx_bridge_http_schema": {
    "config_body": {
      "desc": "The body of the HTTP request.<br/>\nIf not provided, the body will be a JSON object of all the available fields.<br/>\nThere, 'all the available fields' means the context of a MQTT message when\nthis webhook is triggered by receiving a MQTT message (the `local_topic` is set),\nor the context of the event when this webhook is triggered by a rule (i.e. this\nwebhook is used as an action of a rule).<br/>\nTemplate with variables is allowed.",
      "label": "HTTP Body"
    },
    "config_enable_bridge": {
      "desc": "Enable or disable this action.",
      "label": "Enable Or Disable Bridge"
    },
    "config_headers": {
      "desc": "The headers of the HTTP request.<br/>\nTemplate with variables is allowed.",
      "label": "HTTP Header"
    },
    "config_local_topic": {
      "desc": "The MQTT topic filter to be forwarded to the HTTP server. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.<br/>\nNOTE: If this action is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "config_max_retries": {
      "desc": "HTTP request max retry times if failed.",
      "label": "HTTP Request Max Retries"
    },
    "config_method": {
      "desc": "The method of the HTTP request. All the available methods are: post, put, get, delete.<br/>\nTemplate with variables is allowed.",
      "label": "HTTP Method"
    },
    "config_parameters_opts": {
      "desc": "The parameters for HTTP action.",
      "label": "Parameters"
    },
    "config_path": {
      "desc": "The URL path for this Action.<br/>\nThis path will be appended to the Connector's <code>url</code> configuration to form the full\nURL address.\nTemplate with variables is allowed in this option. For example, <code>/room/{$room_no}</code>",
      "label": "URL Path"
    },
    "config_request_timeout": {
      "desc": "HTTP request timeout.",
      "label": "HTTP Request Timeout"
    },
    "config_url": {
      "desc": "The URL of the HTTP action.<br/>\nTemplate with variables is allowed in the path, but variables cannot be used in the scheme, host,\nor port part.<br/>\nFor example, <code> http://localhost:9901/${topic} </code> is allowed, but\n<code> http://${host}:9901/message </code> or <code> http://localhost:${port}/message </code>\nis not allowed.",
      "label": "URL"
    },
    "desc_config": {
      "desc": "Configuration for an HTTP action.",
      "label": "HTTP Action Configuration"
    },
    "desc_name": {
      "desc": "Action name, used as a human-readable identifier.",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The action type.",
      "label": "Action Type"
    }
  },
  "emqx_bridge_influxdb": {
    "action_parameters": {
      "desc": "Additional parameters specific to this action type",
      "label": "Action Parameters"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge.",
      "label": "Enable Or Disable Bridge"
    },
    "connector": {
      "desc": "InfluxDB Connector Configs",
      "label": "InfluxDB Connector"
    },
    "desc_config": {
      "desc": "Configuration for an InfluxDB bridge.",
      "label": "InfluxDB Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type.",
      "label": "Bridge Type"
    },
    "influxdb_action": {
      "desc": "Action to interact with a InfluxDB connector",
      "label": "InfluxDB Action"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to the InfluxDB. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.<br/>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "write_syntax": {
      "desc": "Conf of InfluxDB line protocol to write data points. It is a text-based format that provides the measurement, tag set, field set, and timestamp of a data point, and placeholder supported.\nSee also [InfluxDB 2.3 Line Protocol](https://docs.influxdata.com/influxdb/v2.3/reference/syntax/line-protocol/) and\n[InfluxDB 1.8 Line Protocol](https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/) <br/>\nTLDR:<br/>\n```\n<measurement>[,<tag_key>=<tag_value>[,<tag_key>=<tag_value>]] <field_key>=<field_value>[,<field_key>=<field_value>] [<timestamp>]\n```\nPlease note that a placeholder for an integer value must be annotated with a suffix `i`. For example `${payload.int_value}i`.",
      "label": "Write Syntax"
    }
  },
  "emqx_bridge_influxdb_connector": {
    "bucket": {
      "desc": "InfluxDB bucket name.",
      "label": "Bucket"
    },
    "database": {
      "desc": "InfluxDB database.",
      "label": "Database"
    },
    "influxdb_api_v1": {
      "desc": "InfluxDB's protocol. Support InfluxDB v1.8 and before.",
      "label": "HTTP API Protocol"
    },
    "influxdb_api_v2": {
      "desc": "InfluxDB's protocol. Support InfluxDB v2.0 and after.",
      "label": "HTTP API V2 Protocol"
    },
    "influxdb_parameters": {
      "desc": "Set of parameters specific for the given type of this InfluxDB connector, `influxdb_type` can be one of `influxdb_api_v1`, `influxdb_api_v1`.",
      "label": "InfluxDB Type Specific Parameters"
    },
    "org": {
      "desc": "Organization name of InfluxDB.",
      "label": "Organization"
    },
    "password": {
      "desc": "InfluxDB password.",
      "label": "Password"
    },
    "precision": {
      "desc": "InfluxDB time precision.",
      "label": "Time Precision"
    },
    "protocol": {
      "desc": "InfluxDB's protocol. HTTP API or HTTP API V2.",
      "label": "Protocol"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe InfluxDB default port 8086 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "token": {
      "desc": "InfluxDB token.",
      "label": "Token"
    },
    "username": {
      "desc": "InfluxDB username.",
      "label": "Username"
    }
  },
  "emqx_bridge_iotdb": {
    "action_parameters": {
      "desc": "IoTDB action parameters",
      "label": "Parameters"
    },
    "action_parameters_data": {
      "desc": "IoTDB action parameter data",
      "label": "Parameter Data"
    },
    "auth_basic": {
      "desc": "Parameters for basic authentication.",
      "label": "Basic auth params"
    },
    "config_auth_basic_password": {
      "desc": "The password as configured at the IoTDB REST interface",
      "label": "HTTP Basic Auth Password"
    },
    "config_auth_basic_username": {
      "desc": "The username as configured at the IoTDB REST interface",
      "label": "HTTP Basic Auth Username"
    },
    "config_authentication": {
      "desc": "Authentication configuration",
      "label": "Authentication"
    },
    "config_base_url": {
      "desc": "The base URL of the external IoTDB service's REST interface.",
      "label": "IoTDB REST Service Base URL"
    },
    "config_device_id": {
      "desc": "The IoTDB device ID this data should be inserted for.\nIf left empty, the MQTT message payload must contain a `device_id` field,\nor EMQX's rule-engine SQL must produce a `device_id` field.",
      "label": "Device ID"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "config_iotdb_version": {
      "desc": "The version of the IoTDB system to connect to.",
      "label": "IoTDB Version"
    },
    "config_is_aligned": {
      "desc": "Whether to align the timeseries",
      "label": "Align Timeseries"
    },
    "config_max_retries": {
      "desc": "HTTP request max retry times if failed.",
      "label": "HTTP Request Max Retries"
    },
    "config_parameters_data_type": {
      "desc": "Data Type, an enumerated or a string.\nFor string placeholders in format of ${var} is supported, the final value can be:\n\n- TEXT\n- BOOLEAN\n- INT32\n- INT64\n- FLOAT\n- DOUBLE",
      "label": "Data type"
    },
    "config_parameters_measurement": {
      "desc": "Measurement. Placeholders in format of ${var} is supported",
      "label": "Measurement"
    },
    "config_parameters_timestamp": {
      "desc": "Timestamp. Placeholders in format of ${var} is supported, the final value can be:\n\n- now: use the `now_ms` which is contained in the payload as timestamp\n- now_ms: same as above\n- now_us: use the `now_us` which is contained in the payload as timestamp\n- now_ns: use the `now_ns` which is contained in the payload as timestamp\n- any other: use the value directly as the timestamp",
      "label": "Timestamp"
    },
    "config_parameters_value": {
      "desc": "Value. Placeholders in format of ${var} is supported",
      "label": "Value"
    },
    "desc_config": {
      "desc": "Configuration for Apache IoTDB bridge.",
      "label": "IoTDB Bridge Configuration"
    },
    "desc_name": {
      "desc": "Action name, a human-readable identifier.",
      "label": "Action Name"
    }
  },
  "emqx_bridge_iotdb_connector": {
    "auth_basic": {
      "desc": "Parameters for basic authentication.",
      "label": "Basic auth params"
    },
    "config_auth_basic_password": {
      "desc": "The password as configured at the IoTDB REST interface",
      "label": "HTTP Basic Auth Password"
    },
    "config_auth_basic_username": {
      "desc": "The username as configured at the IoTDB REST interface",
      "label": "HTTP Basic Auth Username"
    },
    "config_authentication": {
      "desc": "Authentication configuration",
      "label": "Authentication"
    },
    "config_base_url": {
      "desc": "The base URL of the external IoTDB service's REST interface.",
      "label": "IoTDB REST Service Base URL"
    },
    "config_max_retries": {
      "desc": "HTTP request max retry times if failed.",
      "label": "HTTP Request Max Retries"
    },
    "desc_config": {
      "desc": "Configuration for Apache IoTDB bridge.",
      "label": "IoTDB Bridge Configuration"
    }
  },
  "emqx_bridge_kafka": {
    "auth_gssapi_kerberos": {
      "desc": "Use GSSAPI/Kerberos authentication.",
      "label": "GSSAPI/Kerberos"
    },
    "auth_kerberos_keytab_file": {
      "desc": "SASL GSSAPI authentication Kerberos keytab file path. NOTE: This file has to be placed in EMQX nodes, and the EMQX service runner user requires read permission.",
      "label": "Kerberos keytab file"
    },
    "auth_kerberos_principal": {
      "desc": "SASL GSSAPI authentication Kerberos principal. For example <code>kafka/node1.example.com@EXAMPLE.COM</code>, NOTE: The realm in use has to be configured in /etc/krb5.conf in EMQX nodes.",
      "label": "Kerberos Principal"
    },
    "auth_sasl_mechanism": {
      "desc": "SASL authentication mechanism.",
      "label": "Mechanism"
    },
    "auth_sasl_password": {
      "desc": "SASL authentication password.",
      "label": "Password"
    },
    "auth_sasl_username": {
      "desc": "SASL authentication username.",
      "label": "Username"
    },
    "auth_username_password": {
      "desc": "Username/password based authentication.",
      "label": "Username/password Auth"
    },
    "authentication": {
      "desc": "Authentication configs.",
      "label": "Authentication"
    },
    "bootstrap_hosts": {
      "desc": "A comma separated list of Kafka <code>host:port</code> endpoints to bootstrap the client.",
      "label": "Bootstrap Hosts"
    },
    "buffer_memory_overload_protection": {
      "desc": "Applicable when buffer mode is set to <code>memory</code>\nEMQX will drop old buffered messages under high memory pressure. The high memory threshold is defined in config <code>sysmon.os.sysmem_high_watermark</code>. NOTE: This config only works on Linux.",
      "label": "Memory Overload Protection"
    },
    "buffer_mode": {
      "desc": "Message buffer mode.\n\n<code>memory</code>: Buffer all messages in memory. The messages will be lost in case of EMQX node restart\n<code>disk</code>: Buffer all messages on disk. The messages on disk are able to survive EMQX node restart.\n<code>hybrid</code>: Buffer message in memory first, when up to certain limit (see <code>segment_bytes</code> config for more information), then start offloading messages to disk, Like <code>memory</code> mode, the messages will be lost in case of EMQX node restart.",
      "label": "Buffer Mode"
    },
    "buffer_per_partition_limit": {
      "desc": "Number of bytes allowed to buffer for each partition. When this limit is exceeded, older messages will be discarded to make room for new messages to be buffered.",
      "label": "Per-partition Buffer Limit"
    },
    "buffer_segment_bytes": {
      "desc": "Applicable when buffer mode is set to <code>disk</code> or <code>hybrid</code>.\nThis setting specifies the size of each buffer file stored on disk.",
      "label": "Segment File Bytes"
    },
    "compression": {
      "desc": "Specify the method of compression.",
      "label": "Compression"
    },
    "config_enable": {
      "desc": "Enable (true) or disable (false) config.",
      "label": "Enable or Disable"
    },
    "connect_timeout": {
      "desc": "Maximum wait time for TCP connection establishment (including authentication time if enabled).",
      "label": "Connect Timeout"
    },
    "consumer_kafka_opts": {
      "desc": "Kafka consumer configs.",
      "label": "Kafka Consumer"
    },
    "consumer_kafka_topic": {
      "desc": "Kafka topic to consume from.",
      "label": "Kafka Topic"
    },
    "consumer_key_encoding_mode": {
      "desc": "Defines how the key from the Kafka message is encoded before being forwarded via MQTT.\n<code>none</code> Uses the key from the Kafka message unchanged.  Note: in this case, the key must be a valid UTF-8 string.\n<code>base64</code> Uses base-64 encoding on the received key.",
      "label": "Key Encoding Mode"
    },
    "consumer_max_batch_bytes": {
      "desc": "Set how many bytes to pull from Kafka in each fetch request. Please note that if the configured value is smaller than the message size in Kafka, it may negatively impact the fetch performance.",
      "label": "Fetch Bytes"
    },
    "consumer_max_rejoin_attempts": {
      "desc": "Maximum number of times allowed for a member to re-join the group. If the consumer group can not reach balance after this configured number of attempts, the consumer group member will restart after a delay.",
      "label": "Max Rejoin Attempts"
    },
    "consumer_mqtt_opts": {
      "desc": "Local MQTT message publish.",
      "label": "MQTT publish"
    },
    "consumer_mqtt_payload": {
      "desc": "The template for transforming the incoming Kafka message.  By default, it will use JSON format to serialize inputs from the Kafka message.  Such fields are:\n<code>headers</code>: an object containing string key-value pairs.\n<code>key</code>: Kafka message key (uses the chosen key encoding).\n<code>offset</code>: offset for the message.\n<code>topic</code>: Kafka topic.\n<code>ts</code>: message timestamp.\n<code>ts_type</code>: message timestamp type, which is one of <code>create</code>, <code>append</code> or <code>undefined</code>.\n<code>value</code>: Kafka message value (uses the chosen value encoding).",
      "label": "MQTT Payload Template"
    },
    "consumer_mqtt_qos": {
      "desc": "MQTT QoS used to publish messages consumed from Kafka.",
      "label": "QoS"
    },
    "consumer_mqtt_topic": {
      "desc": "Local topic to which consumed Kafka messages should be published to.",
      "label": "MQTT Topic"
    },
    "consumer_offset_commit_interval_seconds": {
      "desc": "Defines the time interval between two offset commit requests sent for each consumer group.",
      "label": "Offset Commit Interval"
    },
    "consumer_offset_reset_policy": {
      "desc": "Defines from which offset a consumer should start fetching when there is no commit history or when the commit history becomes invalid.",
      "label": "Offset Reset Policy"
    },
    "consumer_opts": {
      "desc": "Local MQTT publish and Kafka consumer configs.",
      "label": "MQTT to Kafka"
    },
    "consumer_topic_mapping": {
      "desc": "Defines the mapping between Kafka topics and MQTT topics. Must contain at least one item.",
      "label": "Topic Mapping"
    },
    "consumer_value_encoding_mode": {
      "desc": "Defines how the value from the Kafka message is encoded before being forwarded via MQTT.\n<code>none</code> Uses the value from the Kafka message unchanged.  Note: in this case, the value must be a valid UTF-8 string.\n<code>base64</code> Uses base-64 encoding on the received value.",
      "label": "Value Encoding Mode"
    },
    "desc_config": {
      "desc": "Configuration for a Kafka Producer Client.",
      "label": "Kafka Producer Client Configuration"
    },
    "desc_name": {
      "desc": "Action name, used as a human-readable identifier.",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The Action Type",
      "label": "Action Type"
    },
    "kafka_consumer": {
      "desc": "Kafka Consumer configuration.",
      "label": "Kafka Consumer"
    },
    "kafka_header_value_encode_mode": {
      "desc": "The encoding mode for headers.\n\n - `none`: Add only strings are added as header values\n - `json`: Encode header values as JSON string",
      "label": "Headers value encode mode"
    },
    "kafka_headers": {
      "desc": "Provide a placeholder for message headers<br/>\ne.g. <code>${pub_props}</code><br/>\nNote that the value of the placeholder must be either an object:\n<code>{\"foo\": \"bar\"}</code>\nor an array of key-value pairs:\n<code>[{\"key\": \"foo\", \"value\": \"bar\"}]</code>",
      "label": "Message Headers"
    },
    "kafka_message": {
      "desc": "Template for rendering a message.",
      "label": "Message Template"
    },
    "kafka_message_key": {
      "desc": "Template for rendering message key. If the template is rendered into a NULL value (i.e. there is no such data field in Rule Engine context) then <code>NULL</code> (but not empty string) is used.",
      "label": "Message Key"
    },
    "kafka_message_timestamp": {
      "desc": "Which timestamp to use. The timestamp is expected to be a millisecond precision Unix epoch which can be in string format, e.g. <code>1661326462115</code> or <code>'1661326462115'</code>. When the desired data field for this template is not found, or if the found data is not a valid integer, the current system timestamp will be used.",
      "label": "Message Timestamp"
    },
    "kafka_message_value": {
      "desc": "Template for rendering Kafka message value. If the template is rendered into a NULL value (i.e. there is no such data field in Rule Engine context) then Kafka's <code>NULL</code> (but not empty string) is used.",
      "label": "Message Value"
    },
    "kafka_producer": {
      "desc": "Kafka Producer configuration.",
      "label": "Kafka Producer"
    },
    "kafka_producer_action": {
      "desc": "Producer Action",
      "label": "Producer Action"
    },
    "kafka_topic": {
      "desc": "Kafka topic name.  Supports templates (e.g.: `t-${payload.t}`).",
      "label": "Kafka Topic Name"
    },
    "max_batch_bytes": {
      "desc": "Maximum bytes to collect in a Kafka message batch. Most of the Kafka brokers default to a limit of 1 MB batch size. EMQX's default value is less than 1 MB in order to compensate Kafka message encoding overheads (especially when each individual message is very small). When a single message is over the limit, it is still sent (as a single element batch).",
      "label": "Max Batch Bytes"
    },
    "max_inflight": {
      "desc": "The maximum number of message batches that the producer can send to each partition before it must wait for an acknowledgement.\nSetting a higher number can enhance throughput. However, value above 1 may lead to potential message reordering risks.",
      "label": "Max Inflight"
    },
    "metadata_request_timeout": {
      "desc": "Maximum wait time when fetching topic metadata.",
      "label": "Metadata Request Timeout"
    },
    "min_metadata_refresh_interval": {
      "desc": "Minimum time interval the client has to wait before refreshing Kafka broker and topic metadata. Setting too small value may add extra load on Kafka.",
      "label": "Min Metadata Refresh Interval"
    },
    "mqtt_topic": {
      "desc": "MQTT topic or topic filter as data source (action input).  If rule action is used as data source, this config should be left empty, otherwise messages will be duplicated in Kafka.",
      "label": "Source MQTT Topic"
    },
    "partition_count_refresh_interval": {
      "desc": "The time interval for Kafka producer to discover increased number of partitions.\nAfter the number of partitions is increased in Kafka, EMQX will start taking the\ndiscovered partitions into account when dispatching messages per <code>partition_strategy</code>.",
      "label": "Partition Count Refresh Interval"
    },
    "partition_strategy": {
      "desc": "Partition strategy is to tell the producer how to dispatch messages to partitions.\n\n<code>random</code>: Randomly pick a partition for each message.\n<code>key_dispatch</code>: Assigns messages to partitions based on a hash of the message key,\nensuring consistent partition for messages with the same key.",
      "label": "Partition Strategy"
    },
    "partitions_limit": {
      "desc": "Limit the number of partitions to produce data for the given topic.\nThe special value `all_partitions` is to utilize all partitions for the topic.\nSetting this to a value which is greater than the total number of partitions in has no effect.",
      "label": "Max Partitions"
    },
    "producer_buffer": {
      "desc": "Configure producer message buffer.\n\nTell Kafka producer how to buffer messages when EMQX has more messages to send than Kafka can keep up, or when Kafka is down.",
      "label": "Message Buffer"
    },
    "producer_health_check_topic": {
      "desc": "Topic name used exclusively for more accurate connector health checks.",
      "label": "Connector health check topic"
    },
    "producer_kafka_ext_header_key": {
      "desc": "Key of the header. Placeholders in format of ${var} are supported.",
      "label": "Extra Headers Key"
    },
    "producer_kafka_ext_header_value": {
      "desc": "Value of the header. Placeholders in format of ${var} are supported.",
      "label": "Extra Headers Value"
    },
    "producer_kafka_ext_headers": {
      "desc": "Provide more key-value pairs for message headers<br/>\nThe key-value pairs here will be combined with the\nvalue of <code>kafka_headers</code> field before sending producing.",
      "label": "Extra Headers"
    },
    "producer_kafka_opts": {
      "desc": "Kafka producer configs.",
      "label": "Kafka Producer"
    },
    "query_mode": {
      "desc": "Query mode. Optional 'sync/async', default 'async'.",
      "label": "Query mode"
    },
    "required_acks": {
      "desc": "The acknowledgement criteria for the partition leader. It determines the level of confirmation required from partition replicas before sending an acknowledgement back to the producer.\n\n<code>all_isr</code>: Require all in-sync replicas to acknowledge.\n<code>leader_only</code>: Require only the partition-leader's acknowledgement.\n<code>none</code>: No need for Kafka to acknowledge at all.",
      "label": "Required Acks"
    },
    "server_name_indication": {
      "desc": "Server Name Indication (SNI) setting for TLS handshake.<br/>\n- <code>auto</code>: Allow the client to automatically determine the appropriate SNI.<br/>\n- <code>disable</code>: If you wish to prevent the client from sending the SNI.<br/>\n- Other string values will be sent as-is.",
      "label": "SNI"
    },
    "socket_nodelay": {
      "desc": "When set to 'true', TCP buffer is sent as soon as possible. Otherwise, the OS kernel may buffer small TCP packets for a while (40 ms by default).",
      "label": "No Delay"
    },
    "socket_opts": {
      "desc": "Extra socket options.",
      "label": "Socket Options"
    },
    "socket_receive_buffer": {
      "desc": "Fine tune the socket receive buffer. The default value is tuned for high throughput.",
      "label": "Socket Receive Buffer Size"
    },
    "socket_send_buffer": {
      "desc": "Fine tune the socket send buffer. The default value is tuned for high throughput.",
      "label": "Socket Send Buffer Size"
    },
    "socket_tcp_keepalive": {
      "desc": "Enable TCP keepalive.\nThe value is three comma separated numbers in the format of 'Idle,Interval,Probes'\n - Idle: The number of seconds a connection needs to be idle before the server begins to send out keep-alive probes (Linux default 7200).\n - Interval: The number of seconds between TCP keep-alive probes (Linux default 75).\n - Probes: The maximum number of TCP keep-alive probes to send before giving up and killing the connection if no response is obtained from the other end (Linux default 9).\nFor example \"240,30,5\" means: TCP keepalive probes are sent after the connection is idle for 240 seconds, and the probes are sent every 30 seconds until a response is received, if it misses 5 consecutive responses, the connection should be closed.\nDefault: 'none'",
      "label": "TCP keepalive options"
    },
    "ssl_client_opts": {
      "desc": "TLS/SSL options for client.",
      "label": "TLS/SSL options"
    },
    "sync_query_timeout": {
      "desc": "This parameter defines the timeout limit for synchronous queries. It applies only when the query mode is configured to 'sync'.",
      "label": "Synchronous Query Timeout"
    }
  },
  "emqx_bridge_kafka_consumer_schema": {
    "config_connector": {
      "desc": "Configuration for a Kafka Consumer Client.",
      "label": "Kafka Consumer Client Configuration"
    },
    "consumer_source": {
      "desc": "Source configs.",
      "label": "Source"
    },
    "group_id": {
      "desc": "Consumer group identifier to be used for this source.  If omitted, one based off the source name will be automatically generated.",
      "label": "Custom Consumer Group Id"
    },
    "source_parameters": {
      "desc": "Source specific configs.",
      "label": "Source Specific Configs"
    }
  },
  "emqx_bridge_kinesis": {
    "action_parameters": {
      "desc": "Action specific configuration.",
      "label": "Action"
    },
    "aws_access_key_id": {
      "desc": "Access Key ID for connecting to Amazon Kinesis.",
      "label": "AWS Access Key ID"
    },
    "aws_secret_access_key": {
      "desc": "AWS Secret Access Key for connecting to Amazon Kinesis.",
      "label": "AWS Secret Access Key"
    },
    "config_connector": {
      "desc": "Configuration for a Kinesis Client.",
      "label": "Kinesis Client Configuration"
    },
    "config_enable": {
      "desc": "Enable or disable this action",
      "label": "Enable Or Disable Action"
    },
    "desc_config": {
      "desc": "Configuration for an Amazon Kinesis action.",
      "label": "Amazon Kinesis Action Configuration"
    },
    "desc_name": {
      "desc": "Action name.",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The action type.",
      "label": "Action Type"
    },
    "endpoint": {
      "desc": "The url of Amazon Kinesis endpoint.",
      "label": "Amazon Kinesis Endpoint"
    },
    "kinesis_action": {
      "desc": "Configuration for Kinesis Action",
      "label": "Kinesis Action Configuration"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to Amazon Kinesis. All MQTT `PUBLISH` messages with the topic\nmatching the `local_topic` will be forwarded.<br/>\nNOTE: If this action is used as the action of a rule (EMQX rule engine), and also `local_topic` is\nconfigured, then both the data got from the rule and the MQTT messages that match `local_topic`\nwill be forwarded.",
      "label": "Local Topic"
    },
    "max_retries": {
      "desc": "Max retry times if an error occurs when sending a request.",
      "label": "Max Retries"
    },
    "partition_key": {
      "desc": "The Amazon Kinesis Partition Key associated to published message. Placeholders in format of ${var} are supported.",
      "label": "Partition key"
    },
    "payload_template": {
      "desc": "The template for formatting the outgoing messages.  If undefined, will send all the available context in JSON format.",
      "label": "Payload template"
    },
    "pool_size": {
      "desc": "The pool size.",
      "label": "Pool Size"
    },
    "stream_name": {
      "desc": "The Amazon Kinesis Stream to publish messages to.",
      "label": "Amazon Kinesis Stream"
    }
  },
  "emqx_bridge_mongodb": {
    "action_parameters": {
      "desc": "Additional parameters specific to this action type",
      "label": "Action Parameters"
    },
    "batch_size": {
      "desc": "There is no batching support for MongoDB at the moment, so this config field has no effect. Internally the value is overridden to 1.",
      "label": "Batch Size"
    },
    "collection": {
      "desc": "The collection where data will be stored into",
      "label": "Collection to be used"
    },
    "desc_config": {
      "desc": "Configuration for MongoDB action",
      "label": "MongoDB Action Configuration"
    },
    "desc_name": {
      "desc": "Action name.",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The action type.",
      "label": "Action Type"
    },
    "enable": {
      "desc": "Enable or disable this MongoDB Action",
      "label": "Enable or disable"
    },
    "mongodb_action": {
      "desc": "Action to interact with a MongoDB connector",
      "label": "MongoDB Action"
    },
    "mongodb_parameters": {
      "desc": "Set of parameters specific for the given type of this MongoDB connector, `mongo_type` can be one of `single` (Standalone), `sharded` (Sharded) or `rs` (Replica Set).",
      "label": "MongoDB Type Specific Parameters"
    },
    "mongodb_rs_conf": {
      "desc": "MongoDB (Replica Set) configuration",
      "label": "MongoDB (Replica Set) Configuration"
    },
    "mongodb_sharded_conf": {
      "desc": "MongoDB (Sharded) configuration",
      "label": "MongoDB (Sharded) Configuration"
    },
    "mongodb_single_conf": {
      "desc": "MongoDB (Standalone) configuration",
      "label": "MongoDB (Standalone) Configuration"
    },
    "mqtt_topic": {
      "desc": "MQTT topic or topic filter as data source (action input).  If rule action is used as data source, this config should be left empty, otherwise messages will be duplicated in MongoDB.",
      "label": "Source MQTT Topic"
    },
    "payload_template": {
      "desc": "The template for formatting the outgoing messages.  If undefined, rule engine will use JSON format to serialize all visible inputs, such as clientid, topic, payload etc.",
      "label": "Payload template"
    }
  },
  "emqx_bridge_mqtt_connector_schema": {
    "bridge_mode": {
      "desc": "If enable bridge mode.\nNOTE: This setting is only for MQTT protocol version older than 5.0, and the remote MQTT\nbroker MUST support this feature.\nIf bridge_mode is set to true, the bridge will indicate to the remote broker that it is a bridge not an ordinary client.\nThis means that loop detection will be more effective and that retained messages will be propagated correctly.",
      "label": "Bridge Mode"
    },
    "clean_start": {
      "desc": "Whether to start a clean session when reconnecting a remote broker for ingress bridge",
      "label": "Clean Session"
    },
    "clientid_prefix": {
      "desc": "Optional prefix to prepend to the clientid used by egress bridges.",
      "label": "Clientid Prefix"
    },
    "config_connector": {
      "desc": "Configurations for an MQTT connector.",
      "label": "MQTT connector"
    },
    "egress_desc": {
      "desc": "The egress config defines how this bridge forwards messages from the local broker to the remote broker.<br/>\nTemplate with variables is allowed in 'remote.topic', 'local.qos', 'local.retain', 'local.payload'.<br/>\nNOTE: if this bridge is used as the action of a rule, and also 'local.topic'\nis configured, then both the data got from the rule and the MQTT messages that matches\n'local.topic' will be forwarded.",
      "label": "Egress Configs"
    },
    "egress_local": {
      "desc": "The configs about receiving messages from local broker.",
      "label": "Local Configs"
    },
    "egress_local_topic": {
      "desc": "The local topic to be forwarded to the remote broker",
      "label": "Local Topic"
    },
    "egress_pool_size": {
      "desc": "Size of the pool of MQTT clients that will publish messages to the remote broker.<br/>\nEach MQTT client will be assigned 'clientid' of the form '${clientid_prefix}:${bridge_name}:egress:${node}:${n}'\nwhere 'n' is the number of a client inside the pool.",
      "label": "Pool Size"
    },
    "egress_remote": {
      "desc": "The configs about sending message to the remote broker.",
      "label": "Remote Configs"
    },
    "egress_remote_qos": {
      "desc": "The QoS of the MQTT message to be sent.<br/>\nTemplate with variables is allowed.",
      "label": "Remote QoS"
    },
    "egress_remote_topic": {
      "desc": "Forward to which topic of the remote broker.<br/>\nTemplate with variables is allowed.",
      "label": "Remote Topic"
    },
    "ingress_desc": {
      "desc": "The ingress config defines how this bridge receive messages from the remote MQTT broker, and then\n        send them to the local broker.<br/>\n        Template with variables is allowed in 'remote.qos', 'local.topic', 'local.qos', 'local.retain', 'local.payload'.<br/>\n        NOTE: if this bridge is used as the input of a rule, and also 'local.topic' is\n        configured, then messages got from the remote broker will be sent to both the 'local.topic' and\n        the rule.",
      "label": "Ingress Configs"
    },
    "ingress_local": {
      "desc": "The configs about sending message to the local broker.",
      "label": "Local Configs"
    },
    "ingress_local_qos": {
      "desc": "The QoS of the MQTT message to be sent.<br/>\nTemplate with variables is allowed.",
      "label": "Local QoS"
    },
    "ingress_local_topic": {
      "desc": "Send messages to which topic of the local broker.<br/>\nTemplate with variables is allowed.",
      "label": "Local Topic"
    },
    "ingress_pool_size": {
      "desc": "Size of the pool of MQTT clients that will ingest messages from the remote broker.<br/>\nThis value will be respected only if 'remote.topic' is a shared subscription topic or topic-filter\n(for example `$share/name1/topic1` or `$share/name2/topic2/#`), otherwise only a single MQTT client will be used.\nEach MQTT client will be assigned 'clientid' of the form '${clientid_prefix}:${bridge_name}:ingress:${node}:${n}'\nwhere 'n' is the number of a client inside the pool.\nNOTE: Non-shared subscription will not work well when EMQX is clustered.",
      "label": "Pool Size"
    },
    "ingress_remote": {
      "desc": "The configs about subscribing to the remote broker.",
      "label": "Remote Configs"
    },
    "ingress_remote_qos": {
      "desc": "The QoS level to be used when subscribing to the remote broker",
      "label": "Remote QoS"
    },
    "ingress_remote_topic": {
      "desc": "Receive messages from which topic of the remote broker",
      "label": "Remote Topic"
    },
    "max_inflight": {
      "desc": "Max inflight (sent, but un-acked) messages of the MQTT protocol",
      "label": "Max Inflight Message"
    },
    "mode": {
      "desc": "The mode of the MQTT Bridge.<br/>\n- cluster_shareload: create an MQTT connection on each node in the emqx cluster.<br/>\nIn 'cluster_shareload' mode, the incoming load from the remote broker is shared by\nusing shared subscription.<br/>\nNote that the 'clientid' is suffixed by the node name, this is to avoid\nclientid conflicts between different nodes. And we can only use shared subscription\ntopic filters for <code>remote.topic</code> of ingress connections.",
      "label": "MQTT Bridge Mode"
    },
    "password": {
      "desc": "The password of the MQTT protocol",
      "label": "Password"
    },
    "payload": {
      "desc": "The payload of the MQTT message to be sent.<br/>\nTemplate with variables is allowed.",
      "label": "Payload"
    },
    "proto_ver": {
      "desc": "The MQTT protocol version",
      "label": "Protocol Version"
    },
    "retain": {
      "desc": "The 'retain' flag of the MQTT message to be sent.<br/>\nTemplate with variables is allowed.",
      "label": "Retain Flag"
    },
    "server": {
      "desc": "The host and port of the remote MQTT broker",
      "label": "Broker IP And Port"
    },
    "server_configs": {
      "desc": "Configs related to the server.",
      "label": "Server Configs"
    },
    "username": {
      "desc": "The username of the MQTT protocol",
      "label": "Username"
    }
  },
  "emqx_bridge_mqtt_pubsub_schema": {
    "action_parameters": {
      "desc": "Action specific configs.",
      "label": "Action"
    },
    "ingress_parameters": {
      "desc": "Source specific configs.",
      "label": "Source"
    },
    "mqtt_publisher_action": {
      "desc": "Action configs.",
      "label": "Action"
    },
    "mqtt_subscriber_source": {
      "desc": "Source configs.",
      "label": "Source"
    }
  },
  "emqx_bridge_mqtt_schema": {
    "config": {
      "desc": "The config for MQTT Bridges.",
      "label": "Config"
    },
    "desc_name": {
      "desc": "Bridge name, used as a human-readable identifier.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The bridge type.",
      "label": "Bridge Type"
    }
  },
  "emqx_bridge_mysql": {
    "action_parameters": {
      "desc": "Additional parameters specific to this action type",
      "label": "Action Parameters"
    },
    "config_enable": {
      "desc": "Enable or disable this action",
      "label": "Enable Or Disable Action"
    },
    "desc_config": {
      "desc": "Configuration for a MySQL action.",
      "label": "MySQL Action Configuration"
    },
    "desc_name": {
      "desc": "Action name, used as a human-readable identifier of the action.",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The action type",
      "label": "Action Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to MySQL. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.<br/>\nNOTE: If this action is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "mysql_action": {
      "desc": "Action to interact with a MySQL connector",
      "label": "MySQL Action"
    },
    "sql_template": {
      "desc": "SQL Template",
      "label": "SQL Template"
    }
  },
  "emqx_bridge_opents": {
    "action_parameters": {
      "desc": "OpenTSDB action parameters",
      "label": "Parameters"
    },
    "action_parameters_data": {
      "desc": "OpenTSDB action parameter data",
      "label": "Parameter Data"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "config_parameters_metric": {
      "desc": "Metric. Placeholders in the format of ${var} are supported",
      "label": "Metric"
    },
    "config_parameters_tags": {
      "desc": "Tags. Only supports with placeholder to extract tags from a variable or a tags map",
      "label": "Tags"
    },
    "config_parameters_timestamp": {
      "desc": "Timestamp. Placeholders in the format of ${var} are supported",
      "label": "Timestamp"
    },
    "config_parameters_value": {
      "desc": "Value. Placeholders in the format of ${var} are supported",
      "label": "Value"
    },
    "desc_config": {
      "desc": "Configuration for an OpenTSDB bridge.",
      "label": "OpenTSDB Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    }
  },
  "emqx_bridge_opents_connector": {
    "desc_config": {
      "desc": "Configuration for OpenTSDB Connector.",
      "label": "OpenTSDB Connector Configuration"
    },
    "details": {
      "desc": "Whether to return detailed information.",
      "label": "Details"
    },
    "server": {
      "desc": "The URL of OpenTSDB endpoint.",
      "label": "URL"
    },
    "summary": {
      "desc": "Whether to return summary information.",
      "label": "Summary"
    }
  },
  "emqx_bridge_oracle": {
    "action_parameters": {
      "desc": "Action specific configuration.",
      "label": "Action"
    },
    "config_connector": {
      "desc": "Configuration for an Oracle Client.",
      "label": "Oracle Client Configuration"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for an Oracle Database bridge.",
      "label": "Oracle Database Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to Oracle Database. All MQTT 'PUBLISH' messages with the topic matching the local_topic will be forwarded.<br/>NOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is configured, then both the data got from the rule and the MQTT messages that match local_topic will be forwarded.",
      "label": "Local Topic"
    },
    "oracle_action": {
      "desc": "Configuration for Oracle Action",
      "label": "Oracle Action Configuration"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>A host entry has the following form: `Host[:Port]`.<br/>The Oracle Database default port 1521 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "service_name": {
      "desc": "Service Name for Oracle Database.",
      "label": "Oracle Database Service Name"
    },
    "sid": {
      "desc": "Sid for Oracle Database",
      "label": "Oracle Database Sid."
    },
    "sql_template": {
      "desc": "SQL Template. The template string can contain placeholders for message metadata and payload field. The placeholders are inserted without any checking and special formatting, so it is important to ensure that the inserted values are formatted and escaped correctly.",
      "label": "SQL Template"
    }
  },
  "emqx_bridge_pgsql": {
    "action_parameters": {
      "desc": "Configuration Parameters Specific to the PostgreSQL Action",
      "label": "Action Parameters"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for a PostgreSQL bridge.",
      "label": "PostgreSQL Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to PostgreSQL. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.<br/>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "pgsql_action": {
      "desc": "Configuration for PostgreSQL Action",
      "label": "PostgreSQL Action Configuration"
    },
    "sql_template": {
      "desc": "SQL Template",
      "label": "SQL Template"
    }
  },
  "emqx_bridge_pulsar": {
    "auth_basic": {
      "desc": "Parameters for basic authentication.",
      "label": "Basic auth parameters"
    },
    "auth_basic_password": {
      "desc": "Basic authentication password. The `password` part of the `username:password` authentication string.",
      "label": "Password"
    },
    "auth_basic_username": {
      "desc": "Basic authentication username. The `username` part of the `username:password` authentication string.",
      "label": "Username"
    },
    "auth_token": {
      "desc": "Parameters for token authentication.",
      "label": "Token auth params"
    },
    "auth_token_jwt": {
      "desc": "JWT authentication token.",
      "label": "JWT"
    },
    "authentication": {
      "desc": "Authentication configs.",
      "label": "Authentication"
    },
    "buffer_memory_overload_protection": {
      "desc": "Applicable when buffer mode is set to <code>memory</code>\nEMQX will drop old buffered messages under high memory pressure.\nThe high memory threshold is defined in config <code>sysmon.os.sysmem_high_watermark</code>.\n NOTE: This config only works on Linux.",
      "label": "Memory Overload Protection"
    },
    "buffer_mode": {
      "desc": "Message buffer mode.\n<code>memory</code>: Buffer all messages in memory. The messages will be lost\n in case of EMQX node restart\\n<code>disk</code>: Buffer all messages on disk.\n The messages on disk are able to survive EMQX node restart.\n<code>hybrid</code>: Buffer message in memory first, when up to certain limit\n (see <code>segment_bytes</code> config for more information), then start offloading\n messages to disk, Like <code>memory</code> mode, the messages will be lost in\n case of EMQX node restart.",
      "label": "Buffer Mode"
    },
    "buffer_per_partition_limit": {
      "desc": "Number of bytes allowed to buffer for each Pulsar partition.\n When this limit is exceeded, old messages will be dropped in a trade for credits\n for new messages to be buffered.",
      "label": "Per-partition Buffer Limit"
    },
    "buffer_segment_bytes": {
      "desc": "Applicable when buffer mode is set to <code>disk</code> or <code>hybrid</code>.\nThis value is to specify the size of each on-disk buffer file.",
      "label": "Segment File Bytes"
    },
    "config_connector": {
      "desc": "Pulsar connector config",
      "label": "Pulsar Connector"
    },
    "config_enable": {
      "desc": "Enable (true) or disable (false) this Pulsar bridge.",
      "label": "Enable or Disable"
    },
    "connect_timeout": {
      "desc": "Maximum wait time for TCP connection establishment (including authentication time if enabled).",
      "label": "Connect Timeout"
    },
    "connector_resource_opts": {
      "desc": "Pulsar connector resource options",
      "label": "Resource Options"
    },
    "desc_name": {
      "desc": "Bridge name, used as a human-readable description of the bridge.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "producer_batch_size": {
      "desc": "Maximum number of individual requests to batch in a Pulsar message.",
      "label": "Batch size"
    },
    "producer_buffer": {
      "desc": "Configure producer message buffer.\"\nTell Pulsar producer how to buffer messages when EMQX has more messages to\"\n send than Pulsar can keep up, or when Pulsar is down.",
      "label": "Message Buffer"
    },
    "producer_compression": {
      "desc": "Compression method.",
      "label": "Compression"
    },
    "producer_local_topic": {
      "desc": "MQTT topic or topic filter as data source (bridge input)\n If rule action is used as data source, this config should be left empty,\n otherwise messages will be duplicated in Pulsar.",
      "label": "Source MQTT Topic"
    },
    "producer_max_batch_bytes": {
      "desc": "Maximum bytes to collect in a Pulsar message batch. Most of the Pulsar brokers\n default to a limit of 5 MB batch size. EMQX's default value is less than 5 MB in\n order to compensate Pulsar message encoding overheads (especially when each individual\n message is very small). When a single message is over the limit, it is still\n sent (as a single element batch).",
      "label": "Max Batch Bytes"
    },
    "producer_pulsar_topic": {
      "desc": "Pulsar topic name",
      "label": "Pulsar topic name"
    },
    "producer_retention_period": {
      "desc": "The amount of time messages will be buffered while there is no connection to\n the Pulsar broker.  Longer times mean that more memory/disk will be used",
      "label": "Retention Period"
    },
    "producer_send_buffer": {
      "desc": "Fine tune the socket send buffer. The default value is tuned for high throughput.",
      "label": "Socket Send Buffer Size"
    },
    "producer_strategy": {
      "desc": "Partition strategy is to tell the producer how to dispatch messages to Pulsar partitions.\n\n<code>random</code>: Randomly pick a partition for each message.\n<code>roundrobin</code>: Pick each available producer in turn for each message.\n<code>key_dispatch</code>: Hash Pulsar message key of the first message in a batch\n to a partition number.",
      "label": "Partition Strategy"
    },
    "pulsar_producer_struct": {
      "desc": "Configuration for a Pulsar bridge.",
      "label": "Pulsar Bridge Configuration"
    },
    "servers": {
      "desc": "A comma separated list of Pulsar URLs in the form <code>scheme://host[:port]</code>\n for the client to connect to. The supported schemes are <code>pulsar://</code> (default)\n and <code>pulsar+ssl://</code>. The default port is 6650.",
      "label": "Servers"
    }
  },
  "emqx_bridge_pulsar_pubsub_schema": {
    "action_parameters": {
      "desc": "Action specific configs.",
      "label": "Action"
    },
    "producer_key_template": {
      "desc": "Template to render Pulsar message key.",
      "label": "Message Key"
    },
    "producer_message_opts": {
      "desc": "Template to render a Pulsar message.",
      "label": "Pulsar Message Template"
    },
    "producer_pulsar_message": {
      "desc": "Template to render a Pulsar message.",
      "label": "Pulsar Message Template"
    },
    "producer_sync_timeout": {
      "desc": "Maximum wait time for receiving a receipt from Pulsar when publishing synchronously.",
      "label": "Sync publish timeout"
    },
    "producer_value_template": {
      "desc": "Template to render Pulsar message value.",
      "label": "Message Value"
    },
    "publisher_action": {
      "desc": "Publish message to Pulsar topic",
      "label": "Publish Action "
    }
  },
  "emqx_bridge_rabbitmq": {
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for a RabbitMQ bridge.",
      "label": "RabbitMQ Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to RabbitMQ. All MQTT 'PUBLISH' messages with the topic matching the local_topic will be forwarded.\n    NOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is configured, then both the data got from the rule and the MQTT messages that match local_topic will be forwarded.",
      "label": "Local Topic"
    }
  },
  "emqx_bridge_rabbitmq_connector_schema": {
    "auto_reconnect": {
      "desc": "The interval for attempting to reconnect to the RabbitMQ server if the connection is lost.",
      "label": "Auto Reconnect"
    },
    "config_connector": {
      "desc": "The configuration for the RabbitMQ connector.",
      "label": "RabbitMQ Connector Configuration"
    },
    "connector_resource_opts": {
      "desc": "Connector resource options.",
      "label": "Connector Resource Options"
    },
    "delivery_mode": {
      "desc": "The delivery mode for messages published to RabbitMQ. Delivery mode non_persistent (1) is suitable for messages that don't require persistence across RabbitMQ restarts, whereas delivery mode persistent (2) is designed for messages that must survive RabbitMQ restarts.",
      "label": "Message Delivery Mode"
    },
    "exchange": {
      "desc": "The name of the RabbitMQ exchange where the messages will be sent.",
      "label": "Exchange"
    },
    "exchange_type": {
      "desc": "The type of the RabbitMQ exchange (direct, fanout, or topic).",
      "label": "Exchange Type"
    },
    "heartbeat": {
      "desc": "The interval for sending heartbeat messages to the RabbitMQ server.",
      "label": "Heartbeat"
    },
    "password": {
      "desc": "The password used to authenticate with the RabbitMQ server.",
      "label": "Password"
    },
    "payload_template": {
      "desc": "The template for formatting the payload of the message before sending it to RabbitMQ. Template placeholders, such as ${field1.sub_field}, will be substituted with the respective field's value. When left empty, the entire input message will be used as the payload, formatted as a JSON text. This behavior is equivalent to specifying ${.} as the payload template.",
      "label": "Payload Template"
    },
    "pool_size": {
      "desc": "The size of the connection pool.",
      "label": "Pool Size"
    },
    "port": {
      "desc": "The port number on which the RabbitMQ server is listening (default is 5672).",
      "label": "Port"
    },
    "publish_confirmation_timeout": {
      "desc": "The timeout for waiting for RabbitMQ to confirm message publication when using publisher confirms.",
      "label": "Publish Confirmation Timeout"
    },
    "routing_key": {
      "desc": "The routing key used to route messages to the correct queue in the RabbitMQ exchange.",
      "label": "Routing Key"
    },
    "server": {
      "desc": "The RabbitMQ server address that you want to connect to (for example, localhost).",
      "label": "Server"
    },
    "timeout": {
      "desc": "The timeout for waiting on the connection to be established.",
      "label": "Connection Timeout"
    },
    "username": {
      "desc": "The username used to authenticate with the RabbitMQ server.",
      "label": "Username"
    },
    "virtual_host": {
      "desc": "The virtual host to use when connecting to the RabbitMQ server.",
      "label": "Virtual Host"
    },
    "wait_for_publish_confirmations": {
      "desc": "A boolean value that indicates whether to wait for RabbitMQ to confirm message publication when using publisher confirms.",
      "label": "Wait for Publish Confirmations"
    }
  },
  "emqx_bridge_rabbitmq_pubsub_schema": {
    "action_parameters": {
      "desc": "The action config defines how this bridge send messages to the remote RabbitMQ broker",
      "label": "Action Parameters"
    },
    "publisher_action": {
      "desc": "Action configs.",
      "label": "Action"
    },
    "source_no_ack": {
      "desc": "Whether to use no_ack mode when consuming messages from the RabbitMQ broker.",
      "label": "Source No Ack"
    },
    "source_parameters": {
      "desc": "The source config defines how this bridge receive messages from the remote RabbitMQ broker",
      "label": "Source Parameters"
    },
    "source_queue": {
      "desc": "The queue name of the RabbitMQ broker.",
      "label": "Source Queue"
    },
    "subscriber_source": {
      "desc": "Source configs.",
      "label": "Source"
    }
  },
  "emqx_bridge_redis": {
    "command_template": {
      "desc": "Redis command template used to export messages. Each list element stands for a command name or its argument.\nFor example, to push payloads in a Redis list by key `msgs`, the elements should be the following:\n`rpush`, `msgs`, `${payload}`.",
      "label": "Redis Command Template"
    },
    "config_enable": {
      "desc": "Enable or disable this action .",
      "label": "Enable Or Disable Action"
    },
    "desc_action_parameters": {
      "desc": "The parameters of the action.",
      "label": "Action Parameters"
    },
    "desc_config": {
      "desc": "Configuration for a Redis action.",
      "label": "Redis Action Configuration"
    },
    "desc_local_topic": {
      "desc": "The MQTT topic filter to be forwarded to Redis. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.<br/>\nNOTE: If this action is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "desc_name": {
      "desc": "Action name, used as a human-readable identifier.",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The Action Type",
      "label": "Action Type"
    },
    "redis_type": {
      "desc": "Single mode. Must be set to 'single' when Redis server is running in single mode.\nSentinel mode. Must be set to 'sentinel' when Redis server is running in sentinel mode.\nCluster mode. Must be set to 'cluster' when Redis server is running in clustered mode.",
      "label": "Redis Type"
    }
  },
  "emqx_bridge_redis_schema": {
    "batch_size": {
      "desc": "This parameter defines the upper limit of the batch count.\nSetting this value to 1 effectively disables batching, as it indicates that only one item will be processed per batch.\nNote on Redis Cluster Mode:\nIn the context of Redis Cluster Mode, it is important to note that batching is not supported.\nConsequently, the batch_size is always set to 1,\nreflecting the mode inherent limitation in handling batch operations.",
      "label": "Batch Size"
    },
    "batch_time": {
      "desc": "Maximum waiting interval when accumulating a batch at a low message rates for more efficient resource usage.",
      "label": "Max batch wait time, disable when in Redis Cluster Mode."
    },
    "producer_action": {
      "desc": "The parameters of the action.",
      "label": "Action Parameters"
    },
    "redis_action": {
      "desc": "Action to interact with a Redis connector.",
      "label": "Redis Action"
    },
    "redis_parameters": {
      "desc": "Set of parameters specific for the given type of this Redis connector, `redis_type` can be one of `single`, `cluster` or `sentinel`.",
      "label": "Redis Type Specific Parameters"
    }
  },
  "emqx_bridge_rocketmq": {
    "action_parameters": {
      "desc": "Action specific configuration.",
      "label": "Action"
    },
    "config_connector": {
      "desc": "Configuration for an RocketMQ Client.",
      "label": "RocketMQ Client Configuration"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for a RocketMQ bridge.",
      "label": "RocketMQ Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to RocketMQ. All MQTT `PUBLISH` messages with the topic\nmatching the `local_topic` will be forwarded.<br/>\nNOTE: if the bridge is used as a rule action, `local_topic` should be left empty otherwise the messages will be duplicated.",
      "label": "Local Topic"
    },
    "rocketmq_action": {
      "desc": "Configuration for RocketMQ Action",
      "label": "RocketMQ Action Configuration"
    },
    "strategy": {
      "desc": "Producer key dispatch strategy, the default is `roundrobin`, also supports placeholders, such as: `clientid`, `messageid`, `username`."
    },
    "template": {
      "desc": "Template, the default value is empty. When this value is empty the whole message will be stored in the RocketMQ.<br>\n            The template can be any valid string with placeholders, example:<br>\n            - ${id}, ${username}, ${clientid}, ${timestamp}<br>\n            - {\"id\" : ${id}, \"username\" : ${username}}",
      "label": "Template"
    }
  },
  "emqx_bridge_rocketmq_connector": {
    "access_key": {
      "desc": "RocketMQ server `accessKey`.",
      "label": "AccessKey"
    },
    "namespace": {
      "desc": "The namespace field MUST be set if you are using the RocketMQ service in\naliyun cloud and also the namespace is enabled,\nor if you have configured a namespace in your RocketMQ server.\nFor RocketMQ in aliyun cloud, the namespace is the instance ID.",
      "label": "Namespace / Instance ID"
    },
    "refresh_interval": {
      "desc": "RocketMQ Topic Route Refresh Interval.",
      "label": "Topic Route Refresh Interval"
    },
    "secret_key": {
      "desc": "RocketMQ server `secretKey`.",
      "label": "SecretKey"
    },
    "security_token": {
      "desc": "RocketMQ Server Security Token",
      "label": "Security Token"
    },
    "send_buffer": {
      "desc": "The socket send buffer size of the RocketMQ driver client.",
      "label": "Send Buffer Size"
    },
    "servers": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe RocketMQ default port 9876 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "sync_timeout": {
      "desc": "Timeout of RocketMQ driver synchronous call.",
      "label": "Sync Timeout"
    },
    "topic": {
      "desc": "RocketMQ Topic",
      "label": "RocketMQ Topic"
    }
  },
  "emqx_bridge_s3": {
    "config_connector": {
      "desc": "Configuration for a connector to S3 API compatible storage service.",
      "label": "S3 Connector Configuration"
    }
  },
  "emqx_bridge_s3_upload": {
    "s3_aggregated_container": {
      "desc": "Settings governing the file format of an upload containing aggregated events.",
      "label": "Container for aggregated events"
    },
    "s3_aggregated_container_csv": {
      "desc": "Records (events) will be aggregated and uploaded as a CSV file.",
      "label": "CSV container"
    },
    "s3_aggregated_container_csv_column_order": {
      "desc": "Event fields that will be ordered first as columns in the resulting CSV file.<br/>\nRegardless of this setting, resulting CSV will contain all the fields of aggregated events, but all the columns not explicitly mentioned here will be ordered after the ones listed here in the lexicographical order.",
      "label": "CSV column order"
    },
    "s3_aggregated_upload_key": {
      "desc": "Template for the S3 object key of an aggregated upload.<br/>\nTemplate may contain placeholders for the following variables:\n<ul>\n<li><code>${action}</code>: name of the action (required).</li>\n<li><code>${node}</code>: name of the EMQX node conducting the upload (required).</li>\n<li><code>${datetime.{format}}</code>: date and time when aggregation started, formatted according to the <code>{format}</code> string (required):\n    <ul>\n    <li><code>${datetime.rfc3339utc}</code>: RFC3339-formatted date and time in UTC,</li>\n    <li><code>${datetime.rfc3339}</code>: RFC3339-formatted date and time in local timezone,</li>\n    <li><code>${datetime.unix}</code>: Unix timestamp.</li>\n    </ul>\n</li>\n<li><code>${datetime_until.{format}}</code>: date and time when aggregation ended, with the same formatting options.</li>\n<li><code>${sequence}</code>: sequence number of the aggregated upload within the same time interval (required).</li>\n</ul>\nAll other placeholders are considered invalid. Note that placeholders marked as required will be added as a path suffix to the S3 object key if they are missing from the template.",
      "label": "S3 object key template"
    },
    "s3_aggregated_upload_mode": {
      "desc": "Enables time-based aggregation of incoming events and uploading them to the S3 service as a single object.",
      "label": "Aggregated S3 Upload"
    },
    "s3_aggregated_upload_parameters": {
      "desc": "Set of parameters for the aggregated upload action.",
      "label": "Aggregated S3 Upload action parameters"
    },
    "s3_aggregation": {
      "desc": "Set of parameters governing the aggregation process.",
      "label": "Aggregation parameters"
    },
    "s3_aggregation_interval": {
      "desc": "Amount of time events will be aggregated in a single object before uploading.",
      "label": "Time interval"
    },
    "s3_aggregation_max_records": {
      "desc": "Number of records (events) allowed per each aggregated object. Each aggregated upload will contain no more than that number of events, but may contain less.<br/>\nIf event rate is high enough, there obviously may be more than one aggregated upload during the same time interval. These uploads will have different, but consecutive sequence numbers, which will be a part of S3 object key.",
      "label": "Maximum number of records"
    },
    "s3_direct_upload_mode": {
      "desc": "Enables uploading of events to the S3 service as separate objects.",
      "label": "Direct S3 Upload"
    },
    "s3_direct_upload_parameters": {
      "desc": "Set of parameters for the upload action. Action supports templates in S3 bucket name, object key and object content.",
      "label": "Direct S3 Upload action parameters"
    },
    "s3_object_content": {
      "desc": "Content of the S3 object being uploaded. Supports templates.",
      "label": "S3 Object Content"
    },
    "s3_parameters": {
      "desc": "Set of parameters for the upload action.",
      "label": "S3 Upload parameters"
    },
    "s3_upload": {
      "desc": "Action that takes incoming events and uploads them to the S3 API compatible service.",
      "label": "Upload to S3"
    }
  },
  "emqx_bridge_schema": {
    "bridges_mqtt": {
      "desc": "MQTT bridges to/from another MQTT broker",
      "label": "MQTT Bridge"
    },
    "bridges_webhook": {
      "desc": "WebHook to an HTTP server.",
      "label": "WebHook"
    },
    "desc_bridges": {
      "desc": "Configuration for MQTT bridges.",
      "label": "MQTT Bridge Configuration"
    },
    "desc_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_metrics": {
      "desc": "Bridge metrics.",
      "label": "Bridge Metrics"
    },
    "desc_node_metrics": {
      "desc": "Node metrics.",
      "label": "Node Metrics"
    },
    "desc_node_name": {
      "desc": "The node name.",
      "label": "Node Name"
    },
    "desc_node_status": {
      "desc": "Node status.",
      "label": "Node Status"
    },
    "desc_status": {
      "desc": "The status of the bridge<br/>\n- <code>connecting</code>: the initial state before any health probes were made.<br/>\n- <code>connected</code>: when the bridge passes the health probes.<br/>\n- <code>disconnected</code>: when the bridge can not pass health probes.<br/>\n- <code>stopped</code>: when the bridge resource is requested to be stopped.<br/>\n- <code>inconsistent</code>: When not all the nodes are at the same status.",
      "label": "Bridge Status"
    },
    "desc_status_reason": {
      "desc": "This is the reason given in case a bridge is failing to connect.",
      "label": "Failure reason"
    },
    "metric_dropped": {
      "desc": "Count of messages dropped.",
      "label": "Dropped"
    },
    "metric_dropped_other": {
      "desc": "Count of messages dropped due to other reasons.",
      "label": "Dropped Other"
    },
    "metric_dropped_queue_full": {
      "desc": "Count of messages dropped due to the queue is full.",
      "label": "Dropped Queue Full"
    },
    "metric_dropped_resource_not_found": {
      "desc": "Count of messages dropped due to the resource is not found.",
      "label": "Dropped Resource NotFound"
    },
    "metric_dropped_resource_stopped": {
      "desc": "Count of messages dropped due to the resource is stopped.",
      "label": "Dropped Resource Stopped"
    },
    "metric_inflight": {
      "desc": "Count of messages that were sent asynchronously but ACKs are not yet received.",
      "label": "Sent Inflight"
    },
    "metric_matched": {
      "desc": "Count of this bridge is matched and queried.",
      "label": "Matched"
    },
    "metric_queuing": {
      "desc": "Count of messages that are currently queuing.",
      "label": "Queued"
    },
    "metric_rate": {
      "desc": "The rate of matched, times/second",
      "label": "Rate"
    },
    "metric_rate_last5m": {
      "desc": "The average rate of matched in the last 5 minutes, times/second",
      "label": "Last 5 Minutes Rate"
    },
    "metric_rate_max": {
      "desc": "The max rate of matched, times/second",
      "label": "Max Rate Of Matched"
    },
    "metric_received": {
      "desc": "Count of messages that is received from the remote system.",
      "label": "Received"
    },
    "metric_retried": {
      "desc": "Times of retried.",
      "label": "Retried"
    },
    "metric_sent_failed": {
      "desc": "Count of messages that sent failed.",
      "label": "Sent Failed"
    },
    "metric_sent_success": {
      "desc": "Count of messages that sent successfully.",
      "label": "Sent Success"
    }
  },
  "emqx_bridge_sqlserver": {
    "action_parameters": {
      "desc": "Action specific configuration.",
      "label": "Action"
    },
    "config_connector": {
      "desc": "Configuration for a Microsoft SOL Server connector.",
      "label": "Microsoft SOL Server Connector Configuration"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for a Microsoft SQL Server bridge.",
      "label": "Microsoft SQL Server Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "driver": {
      "desc": "SQL Server Driver Name",
      "label": "SQL Server Driver Name"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to Microsoft SQL Server. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.<br/>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "sql_template": {
      "desc": "SQL Template",
      "label": "SQL Template"
    },
    "sqlserver_action": {
      "desc": "Configuration for Microsoft SOL Server action.",
      "label": "Microsoft SOL Server Action Configuration"
    }
  },
  "emqx_bridge_sqlserver_connector": {
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe SQL Server default port 1433 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    }
  },
  "emqx_bridge_syskeeper": {
    "config_enable": {
      "desc": "Enable or disable this action.",
      "label": "Enable Or Disable Action"
    },
    "desc_config": {
      "desc": "Configuration for a Syskeeper action.",
      "label": "Syskeeper Action Configuration"
    },
    "desc_name": {
      "desc": "Action name.",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The action type.",
      "label": "Action Type"
    },
    "mqtt_topic": {
      "desc": "MQTT topic or topic filter as data source (action input).  If rule action is used as data source, this config should be left empty, otherwise messages will be duplicated in Syskeeper.",
      "label": "Source MQTT Topic"
    },
    "parameters": {
      "desc": "Syskeeper action parameters",
      "label": "Parameters"
    },
    "target_qos": {
      "desc": "The QoS for the forwarded message. To preserve the original QoS of the forwarded message, the value can be omitted.",
      "label": "Target QoS"
    },
    "target_topic": {
      "desc": "The topic for the forwarded message",
      "label": "Target Topic"
    },
    "template": {
      "desc": "Template",
      "label": "Template"
    }
  },
  "emqx_bridge_syskeeper_connector": {
    "ack_mode": {
      "desc": "Specify whether the proxy server should reply with an acknowledgement for the message forwarding, can be:<br>- need_ack <br>- no_ack <br>",
      "label": "Acknowledgement Mode"
    },
    "ack_timeout": {
      "desc": "The maximum time to wait for an acknowledgement from the proxy server",
      "label": "Acknowledgement Timeout"
    },
    "config_enable": {
      "desc": "Enable or disable this connector",
      "label": "Enable Or Disable connector"
    },
    "desc_config": {
      "desc": "Configuration for a Syskeeper forwarder connector",
      "label": "Syskeeper Forwarder Connector Configuration"
    },
    "server": {
      "desc": "The address of the Syskeeper proxy server",
      "label": "Server"
    }
  },
  "emqx_bridge_syskeeper_proxy": {
    "acceptors": {
      "desc": "The number of the acceptors",
      "label": "Acceptors"
    },
    "config_enable": {
      "desc": "Enable or disable this connector",
      "label": "Enable Or Disable Connector"
    },
    "desc_config": {
      "desc": "Configuration for a Syskeeper proxy connector",
      "label": "Syskeeper Proxy Connector Configuration"
    },
    "desc_name": {
      "desc": "Action name",
      "label": "Action Name"
    },
    "desc_type": {
      "desc": "The action type.",
      "label": "Action Type"
    },
    "handshake_timeout": {
      "desc": "The maximum to wait for the handshake when a connection is created",
      "label": "Handshake Timeout"
    },
    "listen": {
      "desc": "The listening address for this Syskeeper proxy server",
      "label": "Listen Address"
    }
  },
  "emqx_bridge_tdengine": {
    "action_parameters": {
      "desc": "TDengine action parameters",
      "label": "Parameters"
    },
    "config_enable": {
      "desc": "Enable or disable this bridge",
      "label": "Enable Or Disable Bridge"
    },
    "desc_config": {
      "desc": "Configuration for a TDengine bridge.",
      "label": "TDengine Bridge Configuration"
    },
    "desc_name": {
      "desc": "Bridge name.",
      "label": "Bridge Name"
    },
    "desc_type": {
      "desc": "The Bridge Type",
      "label": "Bridge Type"
    },
    "local_topic": {
      "desc": "The MQTT topic filter to be forwarded to TDengine. All MQTT 'PUBLISH' messages with the topic\nmatching the local_topic will be forwarded.<br/>\nNOTE: if this bridge is used as the action of a rule (EMQX rule engine), and also local_topic is\nconfigured, then both the data got from the rule and the MQTT messages that match local_topic\nwill be forwarded.",
      "label": "Local Topic"
    },
    "sql_template": {
      "desc": "SQL Template",
      "label": "SQL Template"
    }
  },
  "emqx_bridge_tdengine_connector": {
    "desc_config": {
      "desc": "Configuration for TDengine Connector.",
      "label": "TDengine Connector Configuration"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe TDengine default port 6041 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    }
  },
  "emqx_bridge_v2_api": {
    "desc_api1": {
      "desc": "List all created bridges.",
      "label": "List All Bridges"
    },
    "desc_api10": {
      "desc": "Lists the available action types.",
      "label": "List action types"
    },
    "desc_api11": {
      "desc": "Lists the available source types.",
      "label": "List source types"
    },
    "desc_api2": {
      "desc": "Create a new bridge by type and name.",
      "label": "Create Bridge"
    },
    "desc_api3": {
      "desc": "Get a bridge by id.",
      "label": "Get Bridge"
    },
    "desc_api4": {
      "desc": "Update a bridge by id.",
      "label": "Update Bridge"
    },
    "desc_api5": {
      "desc": "Delete a bridge by id.",
      "label": "Delete Bridge"
    },
    "desc_api6": {
      "desc": "Reset a bridge metrics by id.",
      "label": "Reset Bridge Metrics"
    },
    "desc_api7": {
      "desc": "Start bridge on all nodes in the cluster.",
      "label": "Cluster Bridge Operation"
    },
    "desc_api8": {
      "desc": "Start bridge on a specific node.",
      "label": "Node Bridge Operation"
    },
    "desc_api9": {
      "desc": "Test creating a new bridge.",
      "label": "Test Bridge Creation"
    },
    "desc_bridge_metrics": {
      "desc": "Get bridge metrics by id.",
      "label": "Get Bridge Metrics"
    },
    "desc_enable_bridge": {
      "desc": "Enable or Disable bridge on all nodes in the cluster.",
      "label": "Cluster Bridge Enable"
    },
    "desc_param_path_enable": {
      "desc": "Whether to enable this bridge.",
      "label": "Enable bridge"
    },
    "desc_param_path_id": {
      "desc": "The bridge id. Must be of format {type}:{name}.",
      "label": "Bridge ID"
    },
    "desc_param_path_node": {
      "desc": "The node name, e.g. 'emqx@127.0.0.1'.",
      "label": "The node name"
    },
    "desc_param_path_operation_cluster": {
      "desc": "Operation can be one of: 'start'.",
      "label": "Cluster Operation"
    },
    "desc_param_path_operation_on_node": {
      "desc": "Operation can be one of: 'start'.",
      "label": "Node Operation"
    },
    "desc_qs_also_delete_dep_actions": {
      "desc": "Whether to cascade delete dependent actions.",
      "label": "Cascade delete dependent actions?"
    }
  },
  "emqx_bridge_v2_schema": {
    "config_enable": {
      "desc": "Enable (true) or disable (false) this action.",
      "label": "Enable or Disable"
    },
    "desc_bridges_v2": {
      "desc": "Configuration for actions.",
      "label": "Action Configuration"
    },
    "desc_sources": {
      "desc": "Configuration for sources.",
      "label": "Source Configuration"
    },
    "mqtt_topic": {
      "desc": "MQTT topic or topic filter as data source (action input).  If rule action is used as data source, this config should be left empty, otherwise messages will be duplicated in the remote system.",
      "label": "Source MQTT Topic"
    }
  },
  "emqx_cluster_link_schema": {
    "clientid": {
      "desc": "Optional Base MQTT client ID for connecting to the remote EMQX cluster. If omitted, local `cluster.name` is used. EMQX maintains several connections between linked clusters, so distinct suffixes are automatically appended to the base client ID.",
      "label": "Base Client ID"
    },
    "enable": {
      "desc": "Enable or disable a cluster link. The link is enabled by default, disabling it allows stopping the link without removing its configuration. The link must be enabled on both sides to be operational. Disabling the link should also be done on both clusters in order to free up all associated resources.",
      "label": "Enable"
    },
    "link": {
      "desc": "Cluster link configuration",
      "label": "Cluster Link"
    },
    "link_name": {
      "desc": "Linked (remote) cluster name. Must be exactly equal to the value of `cluster.name` configured at the remote cluster. Must not be equal to the local cluster.name. All configured cluster link names must be unique.",
      "label": "Linked Cluster Name"
    },
    "links": {
      "desc": "The list of the linked EMQX clusters.",
      "label": "Cluster Links"
    },
    "max_inflight": {
      "desc": "Max inflight (sent, but un-acked) messages of the MQTT protocol",
      "label": "Max Inflight Message"
    },
    "password": {
      "desc": "Optional MQTT username for connecting to the remote EMQX cluster.",
      "label": "Password"
    },
    "pool_size": {
      "desc": "Size of the pool of MQTT clients that will publish messages to the linked EMQX broker.",
      "label": "Connection Pool Size"
    },
    "server": {
      "desc": "MQTT host and port of the remote EMQX broker.",
      "label": "MQTT Server"
    },
    "ssl": {
      "desc": "SSL configuration for connecting to the remote EMQX cluster.",
      "label": "SSL Options"
    },
    "topics": {
      "desc": "MQTT topics to be forwarded by the linked remote EMQX broker to the local broker. Messages are only forwarded if the local EMQX broker has matching subscriber(s).\nWildcards are supported. Setting empty topics list on one side of the link can be used to establish unidirectional links: the side with the empty topics won't receive remote messages, but it can forward relevant messages to its linked counterpart (according to the topics configured on that side of the link).",
      "label": "Topics"
    },
    "username": {
      "desc": "Optional MQTT username for connecting to the remote EMQX cluster.",
      "label": "Username"
    }
  },
  "emqx_coap_api": {
    "content_type": {
      "desc": "Payload type"
    },
    "message_id": {
      "desc": "Message ID"
    },
    "method": {
      "desc": "Request method type"
    },
    "payload": {
      "desc": "The content of the payload"
    },
    "response_code": {
      "desc": "Response code"
    },
    "send_coap_request": {
      "desc": "Send a CoAP request message to the client"
    },
    "timeout": {
      "desc": "Timespan for response"
    },
    "token": {
      "desc": "Message token, can be empty"
    }
  },
  "emqx_coap_schema": {
    "coap": {
      "desc": "The CoAP Gateway configuration.\nThis gateway is implemented based on RFC-7252 and https://core-wg.github.io/coap-pubsub/draft-ietf-core-pubsub.html"
    },
    "coap_connection_required": {
      "desc": "Enable or disable connection mode.\nConnection mode is a feature of non-standard protocols. When connection mode is enabled, it is necessary to maintain the creation, authentication and alive of connection resources"
    },
    "coap_heartbeat": {
      "desc": "The gateway server required minimum heartbeat interval.\nWhen connection mode is enabled, this parameter is used to set the minimum heartbeat interval for the connection to be alive"
    },
    "coap_notify_type": {
      "desc": "The Notification Message will be delivered to the CoAP client if a new message received on an observed topic.\nThe type of delivered coap message can be set to:<br/>\n  - non: Non-confirmable;<br/>\n  - con: Confirmable;<br/>\n  - qos: Mapping from QoS type of received message, QoS0 -> non, QoS1,2 -> con"
    },
    "coap_publish_qos": {
      "desc": "The Default QoS Level indicator for publish request.\nThis option specifies the QoS level for the CoAP Client when publishing a message to EMQX PUB/SUB system, if the publish request is not carried `qos` option. The indicator can be set to:<br/>\n  - qos0, qos1, qos2: Fixed default QoS level<br/>\n  - coap: Dynamic QoS level by the message type of publish request<br/>\n    * qos0: If the publish request is non-confirmable<br/>\n    * qos1: If the publish request is confirmable"
    },
    "coap_subscribe_qos": {
      "desc": "The Default QoS Level indicator for subscribe request.\nThis option specifies the QoS level for the CoAP Client when establishing a subscription membership, if the subscribe request is not carried `qos` option. The indicator can be set to:<br/>\n  - qos0, qos1, qos2: Fixed default QoS level<br/>\n  - coap: Dynamic QoS level by the message type of subscribe request<br/>\n    * qos0: If the subscribe request is non-confirmable<br/>\n    * qos1: If the subscribe request is confirmable"
    }
  },
  "emqx_conf_schema": {
    "audit_file_handler_path": {
      "desc": "Name the audit log file.",
      "label": "Audit Log File Name"
    },
    "audit_handler_level": {
      "desc": "The log level for the audit log handler.<br/>\n- Requests that take longer than 3 seconds to process are logged as <code>warning</code> logs.<br/>\n- GET requests with HTTP status codes between 200-300 are logged as <code>debug</code> logs.<br/>\n- Non-GET Requests with HTTP status codes between 200-300 are logged as <code>info</code> logs.<br/>\n- Requests with HTTP status codes between 300-400 are logged as <code>warning</code> logs.<br/>\n- Requests with HTTP status codes between 400-500 are logged as <code>error</code> logs.<br/>\n- Defaults to info.",
      "label": "Log Level"
    },
    "audit_log_ignore_high_frequency_request": {
      "desc": "Ignore high frequency requests to avoid flooding the audit log,\nsuch as publish/subscribe kick out http api requests are ignored.",
      "label": "Ignore High Frequency Request"
    },
    "audit_log_max_filter_limit": {
      "desc": "Store the latest N log entries in a database for allow `/audit` HTTP API to filter and retrieval of log data.\nThe interval for purging redundant log records is maintained within a range of 10~20 seconds.",
      "label": "Max Filter Limit"
    },
    "authorization": {
      "desc": "Authorization a.k.a. ACL.<br/>\nIn EMQX, MQTT client access control is extremely flexible.<br/>\nAn out-of-the-box set of authorization data sources are supported.\nFor example,<br/>\n'file' source is to support concise and yet generic ACL rules in a file;<br/>\n'built_in_database' source can be used to store per-client customizable rule sets,\nnatively in the EMQX node;<br/>\n'http' source to make EMQX call an external HTTP API to make the decision;<br/>\n'PostgreSQL' etc. to look up clients or rules from external databases",
      "label": "Authorization"
    },
    "cluster_autoclean": {
      "desc": "Remove disconnected nodes from the cluster after this interval.",
      "label": "Cluster Auto Clean"
    },
    "cluster_autoheal": {
      "desc": "If <code>true</code>, the node will try to heal network partitions automatically.",
      "label": "Cluster Auto Heal"
    },
    "cluster_call_cleanup_interval": {
      "desc": "Time interval to clear completed but stale transactions.\nEnsure that the number of completed transactions is less than the <code>max_history</code>.",
      "label": "Clean Up Interval"
    },
    "cluster_call_max_history": {
      "desc": "Retain the maximum number of completed transactions (for queries).",
      "label": "Cluster Call Max History"
    },
    "cluster_call_retry_interval": {
      "desc": "Time interval to retry after a failed call.",
      "label": "Cluster Call Retry Interval"
    },
    "cluster_discovery_strategy": {
      "desc": "Service discovery method for the cluster nodes. Possible values are:\n- manual: Use <code>emqx ctl cluster</code> command to manage cluster.<br/>\n- static: Configure static nodes list by setting <code>seeds</code> in config file.<br/>\n- dns: Use DNS A record to discover peer nodes.<br/>\n- etcd: Use etcd to discover peer nodes.<br/>\n- k8s: Use Kubernetes API to discover peer pods.",
      "label": "Cluster Discovery Strategy"
    },
    "cluster_dns_name": {
      "desc": "The domain name from which to discover peer EMQX nodes' IP addresses.\nApplicable when <code>cluster.discovery_strategy = dns</code>",
      "label": "Cluster Dns Name"
    },
    "cluster_dns_record_type": {
      "desc": "DNS record type.",
      "label": "DNS Record Type"
    },
    "cluster_etcd_node_ttl": {
      "desc": "Expiration time of the etcd key associated with the node.\nIt is refreshed automatically, as long as the node is alive.",
      "label": "Cluster Etcd Node TTL"
    },
    "cluster_etcd_prefix": {
      "desc": "Key prefix used for EMQX service discovery.",
      "label": "Cluster Etcd Prefix"
    },
    "cluster_etcd_server": {
      "desc": "List of endpoint URLs of the etcd cluster",
      "label": "Cluster Etcd Server"
    },
    "cluster_etcd_ssl": {
      "desc": "Options for the TLS connection to the etcd cluster.",
      "label": "Cluster Etcd SSL Option"
    },
    "cluster_k8s_address_type": {
      "desc": "Address type used for connecting to the discovered nodes.\nSetting <code>cluster.k8s.address_type</code> to <code>ip</code> will\nmake EMQX to discover IP addresses of peer nodes from Kubernetes API.",
      "label": "K8s Address Type"
    },
    "cluster_k8s_apiserver": {
      "desc": "Kubernetes API endpoint URL.",
      "label": "Cluster k8s ApiServer"
    },
    "cluster_k8s_namespace": {
      "desc": "Kubernetes namespace.",
      "label": "K8s Namespace"
    },
    "cluster_k8s_service_name": {
      "desc": "EMQX broker service name.",
      "label": "K8s Service Name"
    },
    "cluster_k8s_suffix": {
      "desc": "Node name suffix.<br/>\nNote: this parameter is only relevant when <code>address_type</code> is <code>dns</code>\nor <code>hostname</code>.",
      "label": "K8s Suffix"
    },
    "cluster_name": {
      "desc": "Human-friendly name of the EMQX cluster.",
      "label": "Cluster Name"
    },
    "cluster_proto_dist": {
      "desc": "The Erlang distribution protocol for the cluster.<br/>\n- inet_tcp: IPv4 TCP <br/>\n- inet_tls: IPv4 TLS, works together with <code>etc/ssl_dist.conf</code> <br/>\n- inet6_tcp: IPv6 TCP <br/>\n- inet6_tls: IPv6 TLS, works together with <code>etc/ssl_dist.conf</code>",
      "label": "Cluster Protocol Distribution"
    },
    "cluster_quic_lb_mode": {
      "desc": "QUIC stack LB Mode\n- 0: disabled (Default)\n- 1: server_ip\n- 2: server_id_fixed",
      "label": " QUIC stack LB Mode "
    },
    "cluster_static_seeds": {
      "desc": "List EMQX node names in the static cluster. See <code>node.name</code>.",
      "label": "Cluster Static Seeds"
    },
    "common_handler_chars_limit": {
      "desc": "Set the maximum length of a single log message. If this length is exceeded, the log message will be truncated.\nWhen formatter is <code>json</code> the truncation is done on the JSON values, but not on the log message itself.",
      "label": "Single Log Max Length"
    },
    "common_handler_drop_mode_qlen": {
      "desc": "When the number of buffered log events is larger than this value, the new log events are dropped.\nWhen drop mode is activated or deactivated, a message is printed in the logs.",
      "label": "Queue Length before Entering Drop Mode"
    },
    "common_handler_enable": {
      "desc": "Enable this log handler.",
      "label": "Enable Log Handler"
    },
    "common_handler_flush_qlen": {
      "desc": "If the number of buffered log events grows larger than this threshold, a flush (delete) operation takes place.\nTo flush events, the handler discards the buffered log messages without logging.",
      "label": "Flush Threshold"
    },
    "common_handler_formatter": {
      "desc": "Choose log formatter. <code>text</code> for free text, and <code>json</code> for structured logging.",
      "label": "Log Formatter"
    },
    "common_handler_level": {
      "desc": "The log level for the current log handler.\nDefaults to warning.",
      "label": "Log Level"
    },
    "common_handler_max_depth": {
      "desc": "Maximum depth for Erlang term log formatting and Erlang process message queue inspection.",
      "label": "Max Depth"
    },
    "common_handler_single_line": {
      "desc": "Print logs in a single line if set to true. Otherwise, log messages may span multiple lines.",
      "label": "Single Line Mode"
    },
    "common_handler_supervisor_reports": {
      "desc": "Type of supervisor reports that are logged. Defaults to <code>error</code><br/>\n  - <code>error</code>: only log errors in the Erlang processes<br/>.\n  - <code>progress</code>: log process startup.",
      "label": "Report Type"
    },
    "common_handler_sync_mode_qlen": {
      "desc": "As long as the number of buffered log events is lower than this value,\nall log events are handled asynchronously. This means that the client process sending the log event,\nby calling a log function in the Logger API, does not wait for a response from the handler\nbut continues executing immediately after the event is sent.\nIt is not affected by the time it takes the handler to print the event to the log device.\nIf the message queue grows larger than this value,\nthe handler starts handling log events synchronously instead,\nmeaning that the client process sending the event must wait for a response.\nWhen the handler reduces the message queue to a level below the sync_mode_qlen threshold,\nasynchronous operation is resumed.",
      "label": "Queue Length before Entering Sync Mode"
    },
    "common_handler_time_offset": {
      "desc": "The time offset to be used when formatting the timestamp.\nCan be one of:\n  - <code>system</code>: the time offset used by the local system\n  - <code>utc</code>: the UTC time offset\n  - <code>+-[hh]:[mm]</code>: user specified time offset, such as \"-02:00\" or \"+00:00\"\nDefaults to: <code>system</code>.\nThis config has no effect for when formatter is <code>json</code> as the timestamp in JSON is milliseconds since epoch.",
      "label": "Time Offset"
    },
    "common_handler_timestamp_format": {
      "desc": "Pick a timestamp format:\n- `auto`: automatically choose the best format based on log formatter. `epoch` for JSON and `rfc3339` for text.\n- `epoch`: Unix epoch time in microseconds.\n- `rfc3339`: RFC3339 format.",
      "label": "Timestamp Format"
    },
    "db_backend": {
      "desc": "Select the backend for the embedded database.<br/>\n<code>rlog</code> is the default backend,\nthat is suitable for very large clusters.<br/>\n<code>mnesia</code> is a backend that offers decent performance in small clusters.",
      "label": "DB Backend"
    },
    "db_default_bootstrap_batch_size": {
      "desc": "The number of built-in database table records to be pushed in one chunk from a core node to a replicant node during bootstrap.\nThe bootstrapping occurs when a new replicant node is added to the cluster or an existing replicant node reconnects to a core one.\nIncreasing this value may greatly reduce a replicant node startup time, especially when EMQX cluster interconnect network latency is high\nand EMQX built-in database holds large amount of data, e.g. when the number of subscriptions is high.\nDefaults to 500.",
      "label": "Default Bootstrap Batch Size"
    },
    "db_default_shard_transport": {
      "desc": "Defines the default transport for pushing transaction logs.<br/>\nThis may be overridden on a per-shard basis in <code>db.shard_transports</code>.\n<code>gen_rpc</code> uses the <code>gen_rpc</code> library,\n<code>distr</code> uses the Erlang distribution.",
      "label": "Default Shard Transport"
    },
    "db_role": {
      "desc": "Select a node role.<br/>\n<code>core</code> nodes provide durability of the data, and take care of writes.\nIt is recommended to place core nodes in different racks or different availability zones.<br/>\n<code>replicant</code> nodes are ephemeral worker nodes. Removing them from the cluster\ndoesn't affect database redundancy<br/>\nIt is recommended to have more replicant nodes than core nodes.<br/>\nNote: this parameter only takes effect when the <code>backend</code> is set\nto <code>rlog</code>.",
      "label": "DB Role"
    },
    "db_rpc_module": {
      "desc": "Protocol used for pushing transaction logs to the replicant nodes.",
      "label": "RPC Module"
    },
    "db_shard_transports": {
      "desc": "Allows to tune the transport method used for transaction log replication, on a per-shard basis.<br/>\n<code>gen_rpc</code> uses the <code>gen_rpc</code> library,\n<code>distr</code> uses the Erlang distribution.<br/>If not specified,\nthe default is to use the value set in <code>db.default_shard_transport</code>.",
      "label": "Shard Transports"
    },
    "db_tlog_push_mode": {
      "desc": "In sync mode the core node waits for an ack from the replicant nodes before sending the next\ntransaction log entry.",
      "label": "Tlog Push Mode"
    },
    "desc_audit_log_handler": {
      "desc": "Audit log handler that prints log events to files.",
      "label": "Audit Log Handler"
    },
    "desc_authorization": {
      "desc": "Settings that control client authorization.",
      "label": "Authorization"
    },
    "desc_cluster": {
      "desc": "EMQX nodes can form a cluster to scale up the total capacity.<br/>\n      Here holds the configs to instruct how individual nodes can discover each other.",
      "label": "Cluster"
    },
    "desc_cluster_call": {
      "desc": "Options for the 'cluster call' feature that allows to execute a callback on all nodes in the cluster.",
      "label": "Cluster Call"
    },
    "desc_cluster_dns": {
      "desc": "Service discovery via DNS SRV records.",
      "label": "Cluster DNS"
    },
    "desc_cluster_etcd": {
      "desc": "Service discovery using 'etcd' service.",
      "label": "Cluster Etcd"
    },
    "desc_cluster_k8s": {
      "desc": "Service discovery via Kubernetes API server.",
      "label": "Cluster Kubernetes"
    },
    "desc_cluster_static": {
      "desc": "Service discovery via static nodes.\nThe new node joins the cluster by connecting to one of the bootstrap nodes.",
      "label": "Cluster Static"
    },
    "desc_console_handler": {
      "desc": "Log handler that prints log events to the EMQX console.",
      "label": "Console Handler"
    },
    "desc_db": {
      "desc": "Settings for the embedded database.",
      "label": "Database"
    },
    "desc_log": {
      "desc": "EMQX supports multiple log handlers, one console handler and multiple file handlers.\nEMQX by default logs to console when running in docker or in console/foreground mode,\notherwise it logs to file $EMQX_LOG_DIR/emqx.log.\nFor advanced configuration, you can find more parameters in this section.",
      "label": "Log"
    },
    "desc_log_burst_limit": {
      "desc": "Large bursts of log events produced in a short time can potentially cause problems, such as:\n - Log files grow very large\n - Log files are rotated too quickly, and useful information gets overwritten\n - Overall performance impact on the system\n\nLog burst limit feature can temporarily disable logging to avoid these issues.",
      "label": "Log Burst Limit"
    },
    "desc_log_file_handler": {
      "desc": "Log handler that prints log events to files.",
      "label": "Files Log Handler"
    },
    "desc_log_overload_kill": {
      "desc": "Log overload kill features an overload protection that activates when the log handlers use too much memory or have too many buffered log messages.<br/>\nWhen the overload is detected, the log handler is terminated and restarted after a cooldown period.",
      "label": "Log Overload Kill"
    },
    "desc_log_rotation": {
      "desc": "By default, the logs are stored in `./log` directory (for installation from zip file) or in `/var/log/emqx` (for binary installation).<br/>\nThis section of the configuration controls the number of files kept for each log handler.",
      "label": "Log Rotation"
    },
    "desc_log_throttling": {
      "desc": "Log throttling feature reduces the number of potentially flooding logged events by\ndropping all but the first event within a configured time window.\nThe throttling is automatically disabled if `console` or `file` log level is set to debug.",
      "label": "Log Throttling"
    },
    "desc_node": {
      "desc": "Node name, cookie, config & data directories and the Erlang virtual machine (BEAM) boot parameters.",
      "label": "Node"
    },
    "desc_rpc": {
      "desc": "EMQX uses a library called <code>gen_rpc</code> for inter-broker communication.<br/>\nMost of the time the default config should work,\nbut in case you need to do performance fine-tuning or experiment a bit,\nthis is where to look.",
      "label": "RPC"
    },
    "dist_buffer_size": {
      "desc": "Erlang's distribution buffer busy limit in kilobytes.",
      "label": "Erlang's dist buffer size(KB)"
    },
    "log_audit_handler": {
      "desc": "Audit file-based log handler.",
      "label": "Audit log Handler"
    },
    "log_burst_limit_enable": {
      "desc": "Enable log burst control feature.",
      "label": "Enable Burst"
    },
    "log_burst_limit_max_count": {
      "desc": "Maximum number of log events to handle within a `window_time` interval. After the limit is reached, successive events are dropped until the end of the `window_time`.",
      "label": "Events Number"
    },
    "log_burst_limit_window_time": {
      "desc": "See <code>max_count</code>.",
      "label": "Window Time"
    },
    "log_file_handler_file": {
      "desc": "Name the log file.",
      "label": "Log File Name"
    },
    "log_file_handler_max_size": {
      "desc": "This parameter controls log file rotation. The value `infinity` means the log file will grow indefinitely, otherwise the log file will be rotated once it reaches `rotation_size` in bytes.",
      "label": "Rotation Size"
    },
    "log_file_handlers": {
      "desc": "File-based log handlers.",
      "label": "File Handler"
    },
    "log_overload_kill_enable": {
      "desc": "Enable log handler overload kill feature.",
      "label": "Log Handler Overload Kill"
    },
    "log_overload_kill_mem_size": {
      "desc": "Maximum memory size that the log handler process is allowed to use.",
      "label": "Log Handler Max Memory Size"
    },
    "log_overload_kill_qlen": {
      "desc": "Maximum allowed queue length.",
      "label": "Max Queue Length"
    },
    "log_overload_kill_restart_after": {
      "desc": "The handler restarts automatically after a delay in the event of termination, unless the value `infinity` is set, which blocks any subsequent restarts.",
      "label": "Handler Restart Timer"
    },
    "log_root": {
      "desc": "EMQX provides support for two primary log handlers: `file` and `console`, with an additional `audit` handler specifically designed to always direct logs to files.\nThe system's default log handling behavior can be configured via the environment variable `EMQX_DEFAULT_LOG_HANDLER`, which accepts the following settings:\n\n- `file`: Directs log output exclusively to files.\n- `console`: Channels log output solely to the console.\n\nIt's noteworthy that `EMQX_DEFAULT_LOG_HANDLER` is set to `file` when EMQX is initiated via systemd's `emqx.service` file.\nIn scenarios outside systemd initiation, `console` serves as the default log handler.",
      "label": "log"
    },
    "log_rotation_count": {
      "desc": "Maximum number of log files.",
      "label": "Max Log Files Number"
    },
    "log_rotation_enable": {
      "desc": "Enable log rotation feature.",
      "label": "Rotation Enable"
    },
    "log_throttling_time_window": {
      "desc": "This configuration setting controls the logging behavior for throttled messages,\nincluding, but not limited to messages like 'authorization_permission_denied'.\nWithin each defined time window, only one instance of a throttled message will be logged to prevent log flooding.\nAt the conclusion of each time window, a summary log will be generated, detailing the occurrence of any throttled messages during that period.\nIt's important to note that the shortest effective time window for this setting is 1 second (`1s`).\nShould a value lower than `1s` be specified, it will automatically be adjusted to `1s`.",
      "label": "Log Throttling Time Window"
    },
    "max_ets_tables": {
      "desc": "Max number of ETS tables",
      "label": "Max number of ETS tables"
    },
    "max_ports": {
      "desc": "Maximum number of simultaneously open files and sockets for this Erlang system.\nFor more information, see: https://www.erlang.org/doc/man/erl.html",
      "label": "Erlang Port Limit"
    },
    "node_applications": {
      "desc": "List of Erlang applications that shall be rebooted when the EMQX broker joins the cluster.",
      "label": "Application"
    },
    "node_backtrace_depth": {
      "desc": "Maximum depth of the call stack printed in error messages and\n<code>process_info</code>.",
      "label": "BackTrace Depth"
    },
    "node_broker_pool_size": {
      "desc": "The number of workers in emqx_broker pool. Increasing this value may improve performance\nby enhancing parallelism, especially when EMQX cluster interconnect network latency is high.\nDefaults to the number of Erlang schedulers (CPU cores) * 2.",
      "label": "Node Broker Pool Size"
    },
    "node_channel_cleanup_batch_size": {
      "desc": "The size of the channel cleanup batch. if EMQX cluster interconnect network latency is high,\nreducing this value together with increasing node.generic_pool_size may improve performance\nduring an abrupt disconnect of a large numbers of clients.\nDefaults to 100000.",
      "label": "Node Channel Cleanup Batch Size"
    },
    "node_cookie": {
      "desc": "Secret cookie is a random string that should be the same on all nodes in\nthe given EMQX cluster, but unique per EMQX cluster. It is used to prevent EMQX nodes that\nbelong to different clusters from accidentally connecting to each other.",
      "label": "Node Cookie"
    },
    "node_crash_dump_bytes": {
      "desc": "This variable sets the maximum size of a crash dump file in bytes.\nThe crash dump will be truncated if this limit is exceeded.\nIf setting it to 0, the runtime system does not even attempt to write a crash dump file.",
      "label": "Crash Dump Bytes"
    },
    "node_crash_dump_file": {
      "desc": "Location of the crash dump file.",
      "label": "Crash Dump File"
    },
    "node_crash_dump_seconds": {
      "desc": "This variable gives the number of seconds that the emulator is allowed to spend writing a crash dump. When the given number of seconds have elapsed, the emulator is terminated.<br/>\n- If setting to 0 seconds, the runtime system does not even attempt to write the crash dump file. It only terminates.<br/>\n- If setting to a positive value S, wait for S seconds to complete the crash dump file and then terminates the runtime system with a SIGALRM signal.<br/>\n- A negative value causes the termination of the runtime system to wait indefinitely until the crash dump file has been completely written.",
      "label": "Crash Dump Seconds"
    },
    "node_data_dir": {
      "desc": "Path to the persistent data directory.<br/>\nPossible auto-created subdirectories are:<br/>\n- `mnesia/<node_name>`: EMQX's built-in database directory.<br/>\nFor example, `mnesia/emqx@127.0.0.1`.<br/>\nThere should be only one such subdirectory.<br/>\nMeaning, in case the node is to be renamed (to e.g. `emqx@10.0.1.1`),<br/>\nthe old dir should be deleted first.<br/>\n- `configs`: Generated configs at boot time, and cluster/local override configs.<br/>\n- `patches`: Hot-patch beam files are to be placed here.<br/>\n- `trace`: Trace log files.<br/>\n\n**NOTE**: One data dir cannot be shared by two or more EMQX nodes.",
      "label": "Node Data Dir"
    },
    "node_dist_net_ticktime": {
      "desc": "This is the approximate time an EMQX node may be unresponsive until it is considered down and thereby disconnected.",
      "label": "Dist Net TickTime"
    },
    "node_etc_dir": {
      "desc": "<code>etc</code> dir for the node",
      "label": "Etc Dir"
    },
    "node_generic_pool_size": {
      "desc": "The number of workers in emqx_pool. Increasing this value may improve performance\nby enhancing parallelism, especially when EMQX cluster interconnect network latency is high.\nDefaults to the number of Erlang schedulers (CPU cores).",
      "label": "Node Generic Pool Size"
    },
    "node_global_gc_interval": {
      "desc": "Periodic garbage collection interval. Set to <code>disabled</code> to have it disabled.",
      "label": "Global GC Interval"
    },
    "node_name": {
      "desc": "Unique name of the EMQX node. It must follow <code>%name%@FQDN</code> or\n<code>%name%@IPv4</code> format.",
      "label": "Node Name"
    },
    "process_limit": {
      "desc": "Maximum number of simultaneously existing processes for this Erlang system.\nFor more information, see: https://www.erlang.org/doc/man/erl.html",
      "label": "Erlang Process Limit"
    },
    "rpc_async_batch_size": {
      "desc": "The maximum number of batch messages sent in asynchronous mode.\n      Note that this configuration does not work in synchronous mode.",
      "label": "Async Batch Size"
    },
    "rpc_authentication_timeout": {
      "desc": "Timeout for the remote node authentication.",
      "label": "RPC Authentication Timeout"
    },
    "rpc_cacertfile": {
      "desc": "Path to certification authority TLS certificate file used to validate <code>rpc.certfile</code>.<br/>\nNote: certificates of all nodes in the cluster must be signed by the same CA.",
      "label": "RPC Cacertfile"
    },
    "rpc_call_receive_timeout": {
      "desc": "Timeout for the reply to a synchronous RPC.",
      "label": "RPC Call Receive Timeout"
    },
    "rpc_certfile": {
      "desc": "Path to TLS certificate file used to validate identity of the cluster nodes.\nNote that this config only takes effect when <code>rpc.driver</code> is set to <code>ssl</code>.",
      "label": "RPC Certfile"
    },
    "rpc_client_num": {
      "desc": "Set the maximum number of RPC communication channels initiated by this node to each remote node.",
      "label": "RPC TCP Client Num"
    },
    "rpc_connect_timeout": {
      "desc": "Timeout for establishing an RPC connection.",
      "label": "RPC Connect Timeout"
    },
    "rpc_driver": {
      "desc": "Transport protocol used for inter-broker communication",
      "label": "RPC dirver"
    },
    "rpc_insecure_fallback": {
      "desc": "Enable compatibility with old RPC authentication.",
      "label": "RPC insecure fallback"
    },
    "rpc_ipv6_only": {
      "desc": "This setting is effective only when <code>rpc.listen_address</code> is assigned an IPv6 address.\nIf set to <code>true</code>, the RPC client will exclusively use IPv6 for connections.\nOtherwise, the client might opt for IPv4, even if the server is on IPv6.",
      "label": "Use IPv6 Only"
    },
    "rpc_keyfile": {
      "desc": "Path to the private key file for the <code>rpc.certfile</code>.<br/>\nNote: contents of this file are secret, so it's necessary to set permissions to 600.",
      "label": "RPC Keyfile"
    },
    "rpc_listen_address": {
      "desc": "Indicates the IP address for the RPC server to listen on. For example, use <code>\"0.0.0.0\"</code> for IPv4 or <code>\"::\"</code> for IPv6.",
      "label": "RPC Listen IP Address"
    },
    "rpc_mode": {
      "desc": "In <code>sync</code> mode the sending side waits for the ack from the receiving side.",
      "label": "RPC Mode"
    },
    "rpc_port_discovery": {
      "desc": "<code>manual</code>: discover ports by <code>server_port</code>.<br/>\n<code>stateless</code>: discover ports in a stateless manner, using the following algorithm.\nIf node name is <code>emqxN@127.0.0.1</code>, where the N is an integer,\nthen the listening port will be 5370 + N.\nNOTE: when `port_discovery` is `manual`, `server_port` configuration has no effect.",
      "label": "RRC Port Discovery"
    },
    "rpc_send_timeout": {
      "desc": "Timeout for sending the RPC request.",
      "label": "RPC Send Timeout"
    },
    "rpc_server_port": {
      "desc": "Listening port used by RPC local service.<br/>\nNote that this config only takes effect when rpc.port_discovery is set to manual.",
      "label": "RPC Server Port"
    },
    "rpc_socket_buffer": {
      "desc": "TCP tuning parameters. Socket buffer size in user mode.",
      "label": "RPC Socket Buffer"
    },
    "rpc_socket_keepalive_count": {
      "desc": "Corresponds to the `TCP_KEEPCNT` socket option. The maximum number of TCP keep-alive probes to send before giving up and killing the connection if no response is obtained from the other end.",
      "label": "RPC Socket Keepalive Count"
    },
    "rpc_socket_keepalive_idle": {
      "desc": "Corresponds to the `TCP_KEEPIDLE` socket option. The time (in seconds) the connection needs to remain idle before TCP starts sending keepalive probes.",
      "label": "RPC Socket Keepalive Idle"
    },
    "rpc_socket_keepalive_interval": {
      "desc": "Corresponds to the `TCP_KEEPINTVL` socket option. The time (in seconds) between individual keepalive probes.",
      "label": "RPC Socket Keepalive Interval"
    },
    "rpc_socket_recbuf": {
      "desc": "TCP tuning parameters. TCP receiving buffer size.",
      "label": "RPC Socket Recbuf"
    },
    "rpc_socket_sndbuf": {
      "desc": "TCP tuning parameters. TCP sending buffer size.",
      "label": "RPC Socket Sndbuf"
    }
  },
  "emqx_conf_schema_types": {
    "bytesize": {
      "desc": "A string that represents a number of bytes, for example: <code>10B</code>, <code>640kb</code>, <code>4MB</code>, <code>1GB</code>. Units are binary standardized, i.e., 1MB equals 1024KB. units are not case sensitive, i.e., 1kb equals 1KB."
    },
    "duration": {
      "desc": "A string that represents a time duration, for example: <code>10s</code>, <code>2.5m</code>, <code>1h30m</code>, <code>1W2D</code>, or <code>2345ms</code>, which is the smallest unit. Each configuration item has its own minimum precision. The part of the setting value that exceeds the precision will be ignored.\n\nFor example, if a configuration item of type <code>Duration(s)</code> is set to <code>1200ms</code>, the final effective value will be <code>1s</code> instead of <code>1.2s</code>.\n\n`Duration` is equivalent to `Duration(ms)`. The unit part is case-insensitive."
    },
    "secret": {
      "desc": "A string holding some sensitive information, such as a password. When secret starts with <code>file://</code>, the rest of the string is interpreted as a path to a file containing the secret itself: whole content of the file except any trailing whitespace characters is considered a secret value. Note: when clustered, all EMQX nodes should have the same file present before using <code>file://</code> secrets."
    },
    "template": {
      "desc": "A string for `${.path.to.var}` style value interpolation,\nwhere the leading dot is optional, and `${.}` represents all values as an object."
    }
  },
  "emqx_connector_aggregator_schema": {
    "container": {
      "desc": "Settings governing the file format of an upload containing aggregated events.",
      "label": "Container for aggregated events"
    },
    "container_csv": {
      "desc": "Records (events) will be aggregated and uploaded as a CSV file.",
      "label": "CSV container"
    },
    "container_csv_column_order": {
      "desc": "Event fields that will be ordered first as columns in the resulting CSV file.<br/>\nRegardless of this setting, resulting CSV will contain all the fields of aggregated events, but all the columns not explicitly mentioned here will be ordered after the ones listed here in the lexicographical order.",
      "label": "CSV column order"
    }
  },
  "emqx_connector_api": {
    "desc_api1": {
      "desc": "List all created connectors.",
      "label": "List All Connectors"
    },
    "desc_api2": {
      "desc": "Create a new connector by type and name.",
      "label": "Create Connector"
    },
    "desc_api3": {
      "desc": "Get a connector by id.",
      "label": "Get Connector"
    },
    "desc_api4": {
      "desc": "Update a connector by id.",
      "label": "Update Connector"
    },
    "desc_api5": {
      "desc": "Delete a connector by id.",
      "label": "Delete Connector"
    },
    "desc_api6": {
      "desc": "Reset a connector metrics by id.",
      "label": "Reset Connector Metrics"
    },
    "desc_api7": {
      "desc": "Start connector on all nodes in the cluster.",
      "label": "Cluster Connector Operate"
    },
    "desc_api8": {
      "desc": "Start connector on a specific node.",
      "label": "Node Connector Operate"
    },
    "desc_api9": {
      "desc": "Test creating a new connector.",
      "label": "Test Connector Creation"
    },
    "desc_connector_metrics": {
      "desc": "Get connector metrics by id.",
      "label": "Get Connector Metrics"
    },
    "desc_enable_connector": {
      "desc": "Enable or Disable connector on all nodes in the cluster.",
      "label": "Cluster Connector Enable"
    },
    "desc_param_path_enable": {
      "desc": "Whether to enable this connector.",
      "label": "Enable connector"
    },
    "desc_param_path_id": {
      "desc": "The connector id. Must be of format {type}:{name}.",
      "label": "Connector ID"
    },
    "desc_param_path_node": {
      "desc": "The node name, e.g. 'emqx@127.0.0.1'.",
      "label": "The node name"
    },
    "desc_param_path_operation_cluster": {
      "desc": "Operation can be one of: 'start'.",
      "label": "Cluster Operation"
    },
    "desc_param_path_operation_on_node": {
      "desc": "Operation can be one of: 'start'.",
      "label": "Node Operation"
    }
  },
  "emqx_connector_schema": {
    "config_enable": {
      "desc": "Enable (true) or disable (false) this connector.",
      "label": "Enable or Disable"
    },
    "connector_actions": {
      "desc": "List of actions added to this connector.",
      "label": "Actions"
    },
    "connector_field": {
      "desc": "Name of the connector specified by the action, used for external resource selection.",
      "label": "Connector"
    },
    "desc_connectors": {
      "desc": "Connectors that are used to connect to external systems",
      "label": "Connectors"
    },
    "desc_name": {
      "desc": "The name of the connector.",
      "label": "Connector Name"
    },
    "desc_node_name": {
      "desc": "The node name.",
      "label": "Node Name"
    },
    "desc_node_status": {
      "desc": "Node status.",
      "label": "Node Status"
    },
    "desc_status": {
      "desc": "The status of the connector<br/>\n- <code>connecting</code>: the initial state before any health probes were made.<br/>\n- <code>connected</code>: when the connector passes the health probes.<br/>\n- <code>disconnected</code>: when the connector can not pass health probes.<br/>\n- <code>inconsistent</code>: When not all the nodes are at the same status.",
      "label": "Connector Status"
    },
    "desc_status_reason": {
      "desc": "This is the reason given in case a connector is failing to connect.",
      "label": "Failure reason"
    },
    "desc_type": {
      "desc": "The type of the connector.",
      "label": "Connector Type"
    }
  },
  "emqx_connector_schema_lib": {
    "auto_reconnect": {
      "desc": "Deprecated. Enable automatic reconnect to the database.",
      "label": "Deprecated. Auto Reconnect Database"
    },
    "database_desc": {
      "desc": "Database name.",
      "label": "Database Name"
    },
    "password": {
      "desc": "The password associated with the bridge, used for authentication with the external database.",
      "label": "Password"
    },
    "pool_size": {
      "desc": "Size of the connection pool towards the bridge target service.",
      "label": "Connection Pool Size"
    },
    "prepare_statement": {
      "desc": "Key-value list of SQL prepared statements.",
      "label": "SQL Prepared Statements List"
    },
    "ssl": {
      "desc": "SSL connection settings.",
      "label": "Enable SSL"
    },
    "username": {
      "desc": "The username associated with the bridge in the external database used for authentication or identification purposes.",
      "label": "Username"
    }
  },
  "emqx_dashboard_api": {
    "backend": {
      "desc": "User account source"
    },
    "backend_name": {
      "desc": "Backend name",
      "label": "Backend Name"
    },
    "backend_not_found": {
      "desc": "Operate failed. Backend not exists"
    },
    "change_pwd_api": {
      "desc": "Change dashboard user password",
      "label": "Change dashboard user password"
    },
    "create_user_api": {
      "desc": "Create dashboard user",
      "label": "Create dashboard user"
    },
    "create_user_api_success": {
      "desc": "Create dashboard user success",
      "label": "Create dashboard user success"
    },
    "delete_backend": {
      "desc": "Delete a backend",
      "label": "Delete Backend"
    },
    "delete_user_api": {
      "desc": "Delete dashboard user",
      "label": "Delete dashboard user"
    },
    "get_backend": {
      "desc": "Get details of a backend",
      "label": "Backend Details"
    },
    "get_sso": {
      "desc": "List all SSO backends",
      "label": "SSO Backends"
    },
    "last_error": {
      "desc": "Last error of this backend",
      "label": "Last Error"
    },
    "license": {
      "desc": "EMQX License. opensource or enterprise"
    },
    "list_running": {
      "desc": "List all running SSO backends",
      "label": "Running Backends"
    },
    "list_users_api": {
      "desc": "Dashboard list users",
      "label": "Dashboard list users"
    },
    "login": {
      "desc": "Get Dashboard Auth Token.",
      "label": "Get Dashboard Auth Token."
    },
    "login_api": {
      "desc": "Get Dashboard Auth Token.",
      "label": "Get Dashboard Auth Token."
    },
    "login_failed401": {
      "desc": "Login failed. Bad username or password"
    },
    "login_failed_response400": {
      "desc": "Login failed. Bad username or password"
    },
    "login_success": {
      "desc": "Dashboard Auth Success"
    },
    "logout_api": {
      "desc": "Dashboard user logout.\nThis endpoint is only for the Dashboard, not the `API Key`.\nThe token from the `/login` endpoint must be a bearer authorization in the headers.",
      "label": "Dashboard user logout"
    },
    "new_pwd": {
      "desc": "New password"
    },
    "old_pwd": {
      "desc": "Old password"
    },
    "password": {
      "desc": "Dashboard Password"
    },
    "redirect": {
      "desc": "Redirect to IDP SSO login page"
    },
    "role": {
      "desc": "User role"
    },
    "running": {
      "desc": "Is the backend running",
      "label": "Running"
    },
    "saml_sso_acs": {
      "desc": "SAML SSO ACS URL"
    },
    "sp_saml_metadata": {
      "desc": "SP SAML Metadata"
    },
    "token": {
      "desc": "Dashboard Auth Token"
    },
    "update_backend": {
      "desc": "Update a backend",
      "label": "Update Backend"
    },
    "update_user_api": {
      "desc": "Update dashboard user description",
      "label": "Update dashboard user description"
    },
    "update_user_api200": {
      "desc": "Update dashboard user success"
    },
    "user_description": {
      "desc": "Dashboard User Description"
    },
    "username": {
      "desc": "Dashboard Username"
    },
    "users_api404": {
      "desc": "Dashboard user not found"
    },
    "version": {
      "desc": "EMQX Version"
    }
  },
  "emqx_dashboard_error_code_api": {
    "error_codes": {
      "desc": "API Error Codes",
      "label": "API Error Codes"
    }
  },
  "emqx_dashboard_monitor_api": {
    "current_stats": {
      "desc": "Current monitor (statistics) data, e.g. number of connections and connection rate in the whole cluster.",
      "label": "Cluster runtime stats"
    },
    "current_stats_node": {
      "desc": "Node monitor (statistics) data, e.g. number of connections and connection rate on the specified node.",
      "label": "Node runtime stats"
    },
    "list_monitor": {
      "desc": "List monitor (statistics) data for the whole cluster.",
      "label": "List cluster stats data"
    },
    "list_monitor_node": {
      "desc": "List the monitor (statistics) data on the specified node.",
      "label": "List node's stats data"
    }
  },
  "emqx_dashboard_schema": {
    "backlog": {
      "desc": "Defines the maximum length that the queue of pending connections can grow to.",
      "label": "Backlog"
    },
    "bind": {
      "desc": "Bind the listener to a specified address and port number, for example `127.0.0.1:18083`.\nIf configured with just the port number (e.g. `18083`) it's equivalent to binding to all addresses `0.0.0.0`.\nThe listener is disabled if `bind` is `0`.",
      "label": "Bind"
    },
    "bootstrap_users_file": {
      "desc": "Deprecated, use api_key.bootstrap_file.",
      "label": "Deprecated"
    },
    "cors": {
      "desc": "Support Cross-Origin Resource Sharing (CORS).\nAllows a server to indicate any origins (domain, scheme, or port) other than\nits own from which a browser should permit loading resources.",
      "label": "CORS"
    },
    "default_password": {
      "desc": "The password used to initialize a database record for `admin` user.\nNOTE: Changing the default password after it has been initialized (boot up for the fist time) has no effect.\nOnce initialized, the default password `public` must be changed from dashboard or CLI as soon as possible.",
      "label": "Default password"
    },
    "default_username": {
      "desc": "The default username of the automatically created dashboard user.",
      "label": "Default username"
    },
    "desc_dashboard": {
      "desc": "Configuration for EMQX dashboard.",
      "label": "Dashboard"
    },
    "desc_http": {
      "desc": "Configuration for the dashboard listener (plaintext).",
      "label": "HTTP"
    },
    "desc_https": {
      "desc": "Configuration for the dashboard listener (TLS).",
      "label": "HTTPS"
    },
    "desc_listeners": {
      "desc": "Configuration for the dashboard listener.",
      "label": "Listeners"
    },
    "i18n_lang": {
      "desc": "Internationalization language support.",
      "label": "I18n language"
    },
    "inet6": {
      "desc": "Enable IPv6 support, default is false, which means IPv4 only.",
      "label": "IPv6"
    },
    "ipv6_v6only": {
      "desc": "Disable IPv4-to-IPv6 mapping for the listener.\nThe configuration is only valid when the inet6 is true.",
      "label": "IPv6 only"
    },
    "listener_enable": {
      "desc": "Ignore or enable this listener",
      "label": "Enable"
    },
    "listeners": {
      "desc": "HTTP(s) listeners are identified by their protocol type and are\nused to serve dashboard UI and restful HTTP API.\nListeners must have a unique combination of port number and IP address.\nFor example, an HTTP listener can listen on all configured IP addresses\non a given port for a machine by specifying the IP address 0.0.0.0.\nAlternatively, the HTTP listener can specify a unique IP address for each listener,\nbut use the same port.",
      "label": "Listeners"
    },
    "max_connections": {
      "desc": "The maximum number of concurrent connections allowed by the listener.",
      "label": "Maximum connections"
    },
    "num_acceptors": {
      "desc": "Socket acceptor pool size for TCP protocols. Default is the number of schedulers online",
      "label": "Number of acceptors"
    },
    "proxy_header": {
      "desc": "Enable support for `HAProxy` header. Be aware once enabled regular HTTP requests can't be handled anymore.",
      "label": "Enable support for HAProxy header"
    },
    "sample_interval": {
      "desc": "How often to update metrics displayed in the dashboard.\nNote: `sample_interval` should be a divisor of 60, default is 10s."
    },
    "send_timeout": {
      "desc": "Send timeout for the socket.",
      "label": "Send timeout"
    },
    "ssl_options": {
      "desc": "SSL/TLS options for the dashboard listener.",
      "label": "SSL options"
    },
    "swagger_support": {
      "desc": "Enable or disable support for swagger API documentation.",
      "label": "Swagger Support"
    },
    "token_expired_time": {
      "desc": "JWT token expiration time. Default is 60 minutes",
      "label": "Token expired time"
    }
  },
  "emqx_dashboard_sso_ldap": {
    "filter": {
      "desc": "The filter for matching users in LDAP is by default `(&(objectClass=person)(uid=${username}))`. For Active Directory, it should be set to `(&(objectClass=user)(sAMAccountName=${username}))` by default. Please refer to [LDAP Filters](https://ldap.com/ldap-filters/) for more details.",
      "label": "Filter"
    },
    "ldap_bind": {
      "desc": "Configuration of authenticator using the LDAP bind operation as the authentication method."
    },
    "query_timeout": {
      "desc": "Timeout for the LDAP query.",
      "label": "Query Timeout"
    }
  },
  "emqx_dashboard_sso_oidc": {
    "client_file_jwks": {
      "desc": "Set JWKS from file."
    },
    "client_file_jwks_file": {
      "desc": "The content of the JWKS."
    },
    "client_file_jwks_type": {
      "desc": "The JWKS source type."
    },
    "client_jwks": {
      "desc": "Set JWK or JWKS here to enable the `private_key_jwt` authorization or the `DPoP` extension."
    },
    "clientid": {
      "desc": "The clientId for this backend."
    },
    "dashboard_addr": {
      "desc": "The address of the EMQX Dashboard."
    },
    "fallback_methods": {
      "desc": "Some providers do not provide all the method items in the provider configuration, set this value as a fallback for those items."
    },
    "issuer": {
      "desc": "The URL of the OIDC issuer."
    },
    "name_var": {
      "desc": "A template to map OIDC user information to a Dashboard name, its default value is `${sub}`."
    },
    "preferred_auth_methods": {
      "desc": "Set the valid authentication methods and their priority."
    },
    "provider": {
      "desc": "The OIDC provider."
    },
    "require_pkce": {
      "desc": "Whether to require PKCE when getting the token."
    },
    "scopes": {
      "desc": "The scopes, its default value is `[\"openid\"]`."
    },
    "secret": {
      "desc": "The client secret."
    },
    "session_expiry": {
      "desc": "The valid time span for an OIDC `state`, the default is `30s`, if the code response returned by the authorization server exceeds this time span, it will be treated as invalid."
    }
  },
  "emqx_dashboard_sso_oidc_api": {
    "code_callback": {
      "desc": "The callback path for the OIDC authorization server.."
    }
  },
  "emqx_dashboard_sso_saml": {
    "dashboard_addr": {
      "desc": "The address of the EMQX Dashboard.",
      "label": "Dashboard Address"
    },
    "idp_metadata_url": {
      "desc": "The URL of the IdP metadata.",
      "label": "IdP Metadata URL"
    },
    "sign_request": {
      "desc": "Whether to sign the SAML request.",
      "label": "Sign SAML Request"
    },
    "sp_private_key": {
      "desc": "The private key of the SP.",
      "label": "SP Private Key"
    },
    "sp_public_key": {
      "desc": "The public key of the SP.",
      "label": "SP Public Key"
    }
  },
  "emqx_dashboard_sso_schema": {
    "backend": {
      "desc": "Backend type.",
      "label": "Backend Type"
    },
    "backend_enable": {
      "desc": "Whether to enable this backend."
    }
  },
  "emqx_delayed_api": {
    "bad_msgid_format": {
      "desc": "Bad Message ID format",
      "label": "Bad Message ID format"
    },
    "bad_topic_name": {
      "desc": "Bad Topic Name",
      "label": "Bad Topic Name"
    },
    "count": {
      "desc": "Count of delayed messages",
      "label": "Count of delayed messages"
    },
    "delayed_interval": {
      "desc": "Delayed interval(second)",
      "label": "Delayed interval"
    },
    "delayed_remaining": {
      "desc": "Delayed remaining(second)",
      "label": "Delayed remaining"
    },
    "delete_api": {
      "desc": "Delete delayed message",
      "label": "Delete delayed message"
    },
    "expected_at": {
      "desc": "Expect publish time, in RFC 3339 format",
      "label": "Expect publish time"
    },
    "from_clientid": {
      "desc": "From ClientID",
      "label": "From ClientID"
    },
    "from_username": {
      "desc": "From Username",
      "label": "From Username"
    },
    "get_message_api": {
      "desc": "View delayed message",
      "label": "View delayed message"
    },
    "illegality_limit": {
      "desc": "Max limit illegality",
      "label": "Max limit illegality"
    },
    "list_api": {
      "desc": "List delayed messages",
      "label": "List delayed messages"
    },
    "msgid": {
      "desc": "Delayed Message ID",
      "label": "Delayed Message ID"
    },
    "msgid_not_found": {
      "desc": "Message ID not found",
      "label": "Message ID not found"
    },
    "no_delayed_message": {
      "desc": "Not found delayed message for this topic",
      "label": "Not found delayed message for this topic"
    },
    "node": {
      "desc": "The node where message from",
      "label": "Node where message from"
    },
    "payload": {
      "desc": "Payload, base64 encoded. Payload will be set to 'PAYLOAD_TO_LARGE' if its length is larger than 2048 bytes",
      "label": "Payload"
    },
    "publish_at": {
      "desc": "Clinet publish message time, in RFC 3339 format",
      "label": "Client publish message time"
    },
    "qos": {
      "desc": "QoS",
      "label": "QoS"
    },
    "topic": {
      "desc": "Topic",
      "label": "Topic"
    },
    "update_api": {
      "desc": "Enable or disable delayed, set max delayed messages",
      "label": "Enable or disable delayed"
    },
    "update_success": {
      "desc": "Enable or disable delayed successfully",
      "label": "Enable or disable delayed successfully"
    },
    "view_limit": {
      "desc": "Page limit",
      "label": "Page limit"
    },
    "view_page": {
      "desc": "View page",
      "label": "View page"
    },
    "view_status_api": {
      "desc": "Get delayed status",
      "label": "Get delayed status"
    }
  },
  "emqx_ds_schema": {
    "backend_type": {
      "desc": "Backend type.",
      "label": "Backend type"
    },
    "builtin_data_dir": {
      "desc": "File system directory where the database is located.\n\nBy default, it is equal to `node.data_dir`.",
      "label": "Database location"
    },
    "builtin_layout": {
      "desc": "Storage layout is a method of arranging messages from various topics and clients on disc.\n\nDepending on the type of workload and the topic structure, different types of strategies for storing the data can be employed to maximize efficiency of reading messages from the durable storage.",
      "label": "Storage layout"
    },
    "builtin_local": {
      "desc": "Builtin storage backend utilizing embedded RocksDB key-value store.\nThis backend doesn't support clustering.",
      "label": "Builtin backend"
    },
    "builtin_n_shards": {
      "desc": "The built-in durable storage partitions data into shards.\nThis configuration parameter defines the number of shards.\nPlease note that it takes effect only during the initialization of the durable storage database.\nChanging this configuration parameter after the database has been already created won't take any effect.",
      "label": "Number of shards"
    },
    "builtin_raft": {
      "desc": "Builtin storage backend utilizing embedded RocksDB key-value store.",
      "label": "Builtin backend with Raft replication"
    },
    "builtin_raft_n_sites": {
      "desc": "Number of storage sites that need to share responsibility over the set of storage shards.\nIn this context, sites are EMQX nodes with message durability enabled.\nPlease note that it takes effect only during the initialization of the durable storage database.\nDuring this phase at least that many sites should come online to distribute shards between them, otherwise message storage will be unavailable until then.\nAfter the initialization is complete, sites may be offline, which will affect availability depending on the number of offline sites and replication factor.",
      "label": "Initial number of sites"
    },
    "builtin_raft_replication_factor": {
      "desc": "Number of identical replicas each shard should have.\nIncreasing this number improves durability and availability at the expense of greater resource consumption.\nQuorum of replicas is needed to be healthy for the replication to work, hence an odd number of replicas is a good pick in general.\nPlease note that it takes effect only during the initialization of the durable storage database.\nChanging this configuration parameter after the database has been already created won't take any effect.",
      "label": "Replication factor"
    },
    "builtin_write_buffer": {
      "desc": "Configuration related to the buffering of messages sent from the local node to the shard leader.\n\nEMQX accumulates PUBLISH messages from the local clients in a write buffer before committing them to the durable storage.\nThis helps to hide network latency between EMQX nodes and improves write throughput.",
      "label": "Local write buffer"
    },
    "builtin_write_buffer_flush_interval": {
      "desc": "Maximum linger time for the buffered messages.\nLocal write buffer will be flushed _at least_ as often as `flush_interval`.\n\nLarger values of `flush_interval` may lead to higher throughput and better overall performance, but may increase end-to-end latency.",
      "label": "Flush interval"
    },
    "builtin_write_buffer_max_items": {
      "desc": "This configuration parameter defines maximum number of messages stored in the local write buffer.",
      "label": "Max items"
    },
    "layout_builtin_reference": {
      "desc": "A simplistic layout type that stores all messages from all topics in chronological order in a single stream.\n\nNot recommended for production use.",
      "label": "Reference layout"
    },
    "layout_builtin_reference_type": {
      "desc": "Reference layout type.",
      "label": "Layout type"
    },
    "layout_builtin_wildcard_optimized": {
      "desc": "_Wildcard-optimized_ layout is designed to maximize the throughput of wildcard subscriptions covering large numbers of topics.\n\nFor example, it can handle scenarios where a very large number of clients publish data to the topics containing their client ID, such as: `sensor/%device-version%/%clientid%/temperature`, `sensor/%device-version%/%clientid%/pressure`, etc.\nThis layout will automatically group such topics into a single stream, so a client subscribing to a topic filter containing wildcards (such as `sensor/+/+/temperature`) will be able to consume messages published by all devices as a single batch.\n\nThis layout is efficient for non-wildcard subscriptions as well.",
      "label": "Wildcard-optimized storage layout"
    },
    "layout_builtin_wildcard_optimized_type": {
      "desc": "Wildcard-optimized layout type.",
      "label": "Layout type"
    },
    "messages": {
      "desc": "Configuration related to the durable storage of MQTT messages.",
      "label": "MQTT message storage"
    },
    "wildcard_optimized_epoch_bits": {
      "desc": "Wildcard-optimized layout partitions messages recorded at different times into \"epochs\".\nReading messages from a single epoch can be done very efficiently, so larger epochs improve the throughput of subscribers, but may increase end-to-end latency.\n\nTime span covered by each epoch grows exponentially with the value of `epoch_bits`:\n\n- `epoch_bits = 1`: epoch time = 2 microseconds\n- `epoch_bits = 2`: 4 microseconds\n...\n- `epoch_bits = 20`: ~1s\n...",
      "label": "Epoch bits"
    }
  },
  "emqx_ds_shared_sub_api": {
    "durable_queue_delete": {
      "desc": "Delete a durable queue.",
      "label": "Delete Durable Queue"
    },
    "durable_queue_get": {
      "desc": "Get the information of a durable queue.",
      "label": "Durable Queue"
    },
    "durable_queues_get": {
      "desc": "Get the list of durable queues.",
      "label": "Durable Queues"
    },
    "durable_queues_put": {
      "desc": "Create a durable queue.",
      "label": "Create Durable Queue"
    },
    "param_queue_id": {
      "desc": "The ID of the durable queue.",
      "label": "Queue ID"
    }
  },
  "emqx_ds_shared_sub_schema": {
    "enable": {
      "desc": "Enable the shared subscription feature.",
      "label": "Enable Shared Subscription"
    },
    "leader_drop_timeout_interval_ms": {
      "desc": "The interval in milliseconds for the leader to drop non-responsive sessions.",
      "label": "Leader Drop Timeout Interval"
    },
    "leader_renew_lease_interval_ms": {
      "desc": "The interval in milliseconds for the leader to renew the lease.",
      "label": "Leader Renew Lease Interval"
    },
    "leader_renew_streams_interval_ms": {
      "desc": "The interval in milliseconds for the leader to renew the streams.",
      "label": "Leader Renew Streams Interval"
    },
    "leader_session_not_replaying_timeout_ms": {
      "desc": "The timeout in milliseconds for the leader to wait for the session leave intermediate states.",
      "label": "Leader Session Not Replaying Timeout"
    },
    "leader_session_update_timeout_ms": {
      "desc": "The timeout in milliseconds for the leader to wait for the session to update the stream state.\nIf the session does not update the stream state within this time, the leader will drop the session.",
      "label": "Leader Session Update Timeout"
    },
    "session_find_leader_timeout_ms": {
      "desc": "The timeout in milliseconds for the session to find a leader.\nIf the session cannot find a leader within this time, the session will retry.",
      "label": "Session Find Leader Timeout"
    },
    "session_min_update_stream_state_interval_ms": {
      "desc": "The minimum interval in milliseconds for the session to update the stream state.\nIf session has no updates for the stream state within this time, the session will\nsend empty updates.",
      "label": "Session Min Update Stream State Interval"
    },
    "session_renew_lease_timeout_ms": {
      "desc": "The timeout in milliseconds for the session to wait for the leader to renew the lease.\nIf the leader does not renew the lease within this time, the session will consider\nthe leader as lost and try to find a new leader.",
      "label": "Session Renew Lease Timeout"
    }
  },
  "emqx_eviction_agent_api": {
    "node_eviction_status_get": {
      "desc": "Get the node eviction status",
      "label": "Node Eviction Status"
    }
  },
  "emqx_exhook_api": {
    "add_server": {
      "desc": "Add a server",
      "label": "Add a server"
    },
    "delete_server": {
      "desc": "Delete the server",
      "label": "Delete the server"
    },
    "get_detail": {
      "desc": "Get the detail information of Exhook server",
      "label": "Get server details"
    },
    "get_hooks": {
      "desc": "Get the hooks information of server",
      "label": "Get server hooks information"
    },
    "hook_metrics": {
      "desc": "Metrics information of this hook in the current node",
      "label": "Hook metrics"
    },
    "hook_name": {
      "desc": "The hook's name",
      "label": "Hook name"
    },
    "hook_params": {
      "desc": "The parameters used when the hook is registered",
      "label": "Hook parameters"
    },
    "list_all_servers": {
      "desc": "List all servers",
      "label": "List servers"
    },
    "metric_failed": {
      "desc": "The number of times the hook execution failed",
      "label": "Failed executions count"
    },
    "metric_max_rate": {
      "desc": "Maximum call rate of hooks",
      "label": "Max hook call rate"
    },
    "metric_rate": {
      "desc": "The call rate of hooks",
      "label": "Hook call rate"
    },
    "metric_succeed": {
      "desc": "The number of times the hooks execution successful",
      "label": "Successful executions count"
    },
    "metrics": {
      "desc": "Metrics information",
      "label": "Metrics information"
    },
    "move_api": {
      "desc": "Move the server.\nNOTE: The position should be \"front | rear | before:{name} | after:{name}",
      "label": "Change order of execution for registered Exhook server"
    },
    "move_position": {
      "desc": "The target position to be moved",
      "label": "Target position"
    },
    "node": {
      "desc": "Node name",
      "label": "Node name"
    },
    "node_hook_metrics": {
      "desc": "Metrics information of this hook in all nodes",
      "label": "Node-wise hook metrics"
    },
    "node_metrics": {
      "desc": "Metrics information of this server in all nodes",
      "label": "Node-wise server metrics"
    },
    "node_status": {
      "desc": "status of this server in all nodes",
      "label": "Node-wise server status"
    },
    "server_metrics": {
      "desc": "Metrics information of this server in the current node",
      "label": "Server metrics"
    },
    "server_name": {
      "desc": "The Exhook server name",
      "label": "Server name"
    },
    "status": {
      "desc": "The status of Exhook server.<br/>\nconnected: connection succeeded<br/>\nconnecting: connection failed, reconnecting<br/>\ndisconnected: failed to connect and didn't reconnect<br/>\ndisabled: this server is disabled<br/>\nerror: failed to view the status of this server",
      "label": "Server status"
    },
    "update_server": {
      "desc": "Update the server",
      "label": "Update the server"
    }
  },
  "emqx_exhook_schema": {
    "auto_reconnect": {
      "desc": "Whether to automatically reconnect (initialize) the gRPC server.\nWhen gRPC is not available, Exhook tries to request the gRPC service at that interval and reinitialize the list of mounted hooks."
    },
    "enable": {
      "desc": "Enable this Exhook server"
    },
    "failed_action": {
      "desc": "The value that is returned when the request to the gRPC server fails for any reason"
    },
    "keepalive": {
      "desc": "Enables/disables periodic transmission on a connected socket when no other data is exchanged.\nIf the other end does not respond, the connection is considered broken and an error message is sent to the controlling process."
    },
    "name": {
      "desc": "Name of the exhook server"
    },
    "nodelay": {
      "desc": "If true, option TCP_NODELAY is turned on for the socket,\nwhich means that also small amounts of data are sent immediately"
    },
    "pool_size": {
      "desc": "The process pool size for gRPC client"
    },
    "recbuf": {
      "desc": "The minimum size of receive buffer to use for the socket"
    },
    "request_timeout": {
      "desc": "The timeout of request gRPC server"
    },
    "servers": {
      "desc": "List of exhook servers"
    },
    "sndbuf": {
      "desc": "The minimum size of send buffer to use for the socket"
    },
    "socket_options": {
      "desc": "Connection socket options"
    },
    "url": {
      "desc": "URL of the gRPC server"
    }
  },
  "emqx_exproto_schema": {
    "exproto": {
      "desc": "The Extension Protocol configuration"
    },
    "exproto_grpc_handler_address": {
      "desc": "gRPC server address."
    },
    "exproto_grpc_handler_service_name": {
      "desc": "The service name to handle the connection events.\nIn the initial version, we expected to use streams to improve the efficiency\nof requests in `ConnectionHandler`. But unfortunately, events between different\nstreams are out of order. It causes the `OnSocketCreated` event to may arrive\nlater than `OnReceivedBytes`.\nSo we added the `ConnectionUnaryHandler` service since v5.0.25 and forced\nthe use of Unary in it to avoid ordering problems."
    },
    "exproto_grpc_handler_ssl": {
      "desc": "SSL configuration for the gRPC client."
    },
    "exproto_grpc_server_bind": {
      "desc": "Listening address and port for the gRPC server."
    },
    "exproto_grpc_server_ssl": {
      "desc": "SSL configuration for the gRPC server."
    },
    "exproto_handler": {
      "desc": "Configurations for request to <code>ConnectionHandler</code> service"
    },
    "exproto_server": {
      "desc": "Configurations for starting the <code>ConnectionAdapter</code> service"
    }
  },
  "emqx_ft_api": {
    "file_list": {
      "desc": "List all uploaded files."
    },
    "file_list_transfer": {
      "desc": "List a file uploaded during specified transfer, identified by client id and file id."
    },
    "file_transfer_get_config": {
      "desc": "Show current File Transfer configuration."
    },
    "file_transfer_update_config": {
      "desc": "Replace File Transfer configuration."
    }
  },
  "emqx_ft_schema": {
    "assemble_timeout": {
      "desc": "Timeout for assembling and exporting file segments into a final file.<br/>\nAfter reaching the timeout (e.g. due to system is overloaded), the PUBACK message for `fin` will contain error code (0x80)"
    },
    "backend_enable": {
      "desc": "Whether to enable this backend."
    },
    "enable": {
      "desc": "Enable the File Transfer feature.<br/>\nEnabling File Transfer implies reserving special MQTT topics in order to serve the protocol.<br/>\nThis toggle also affects the availability of the File Transfer REST API and\nstorage-dependent background activities (e.g. garbage collection)."
    },
    "init_timeout": {
      "desc": "Timeout for EMQX to initialize the file transfer.<br/>\nAfter reaching the timeout (e.g. due to system is overloaded), the PUBACK message for `init` will contain error code (0x80)."
    },
    "local_storage": {
      "desc": "Local file system backend to store uploaded fragments and temporary data."
    },
    "local_storage_exporter": {
      "desc": "Exporter to the local file system."
    },
    "local_storage_exporter_backend": {
      "desc": "Exporter for the local file system storage backend.<br/>\nExporter defines where and how fully transferred and assembled files are stored."
    },
    "local_storage_exporter_root": {
      "desc": "Directory where the uploaded files are kept."
    },
    "local_storage_segments": {
      "desc": "Settings for local segments storage, which include uploaded transfer fragments and temporary data."
    },
    "local_storage_segments_gc": {
      "desc": "Garbage collection settings for the intermediate and temporary files in the local file system."
    },
    "local_storage_segments_root": {
      "desc": "File system path to keep uploaded fragments and temporary data."
    },
    "s3_exporter": {
      "desc": "Exporter to the S3 API compatible object storage."
    },
    "storage_backend": {
      "desc": "Storage settings for file transfer."
    },
    "storage_gc_interval": {
      "desc": "Interval of periodic garbage collection."
    },
    "storage_gc_max_segments_ttl": {
      "desc": "Maximum TTL of a segment kept in the local file system.<br/>\nThis is a hard limit: no segment will outlive this TTL, even if some file transfer specifies a\nTTL more than that."
    },
    "storage_gc_min_segments_ttl": {
      "desc": "Minimum TTL of a segment kept in the local file system.<br/>\nThis is a hard limit: no segment will be garbage collected before reaching this TTL,\neven if some file transfer specifies a TTL less than that."
    },
    "store_segment_timeout": {
      "desc": "Timeout for storing a file segment.<br/>\nAfter reaching the timeout (e.g. due to system overloaded), the PUBACK message will contain error code (0x80)."
    }
  },
  "emqx_ft_storage_exporter_fs_api": {
    "file_get": {
      "desc": "Get a file by its id."
    }
  },
  "emqx_gateway_api": {
    "delete_gateway": {
      "desc": "Unload the specified gateway"
    },
    "enable_gateway": {
      "desc": "Enable a gateway by confs."
    },
    "gateway_created_at": {
      "desc": "The Gateway created datetime"
    },
    "gateway_current_connections": {
      "desc": "The Gateway current connected connections/clients"
    },
    "gateway_enable_in_path": {
      "desc": "Whether to enable this gateway"
    },
    "gateway_listener_id": {
      "desc": "Listener ID"
    },
    "gateway_listener_name": {
      "desc": "Listener Name"
    },
    "gateway_listener_running": {
      "desc": "Listener Running status"
    },
    "gateway_listener_type": {
      "desc": "Listener Type"
    },
    "gateway_listeners": {
      "desc": "The Gateway listeners overview"
    },
    "gateway_max_connections": {
      "desc": "The maximum number of concurrent connections allowed by the gateway."
    },
    "gateway_name": {
      "desc": "Gateway Name"
    },
    "gateway_name_in_qs": {
      "desc": "Gateway Name"
    },
    "gateway_node_status": {
      "desc": "The status of the gateway on each node in the cluster"
    },
    "gateway_started_at": {
      "desc": "The Gateway started datetime"
    },
    "gateway_status": {
      "desc": "Gateway status"
    },
    "gateway_status_in_qs": {
      "desc": "Filter gateways by status.<br/>\nIt is enum with `running`, `stopped`, `unloaded`"
    },
    "gateway_stopped_at": {
      "desc": "The Gateway stopped datetime"
    },
    "get_gateway": {
      "desc": "Get the gateway configurations"
    },
    "list_gateway": {
      "desc": "This API returns an overview info for the specified or all gateways.\nincluding current running status, number of connections, listener status, etc."
    },
    "node": {
      "desc": "Node Name"
    },
    "update_gateway": {
      "desc": "Update the gateway basic configurations and running status.<br/>\nNote: The Authentication and Listener configurations should be updated by other special APIs."
    }
  },
  "emqx_gateway_api_authn": {
    "add_authn": {
      "desc": "Enables the authenticator for client authentication for the specified gateway. <br/>\nWhen the authenticator is not configured or turned off, all client connections are assumed to be allowed. <br/>\nNote: Only one authenticator is allowed to be enabled at a time in the gateway, rather than allowing multiple authenticators to be configured to form an authentication chain as in MQTT."
    },
    "add_user": {
      "desc": "Add user for the authenticator (only supports built_in_database)."
    },
    "delete_authn": {
      "desc": "Delete the authenticator of the specified gateway."
    },
    "delete_user": {
      "desc": "Delete the user for the gateway authenticator (only supports built_in_database)"
    },
    "get_authn": {
      "desc": "Gets the configuration of the specified gateway authenticator.<br/>\nReturns 404 when gateway or authentication is not enabled."
    },
    "get_user": {
      "desc": "Get user info from the gateway authenticator (only supports built_in_database)"
    },
    "import_users": {
      "desc": "Import users into the gateway authenticator (only supports built_in_database)"
    },
    "is_superuser": {
      "desc": "Is superuser"
    },
    "like_user_id": {
      "desc": "Fuzzy search using user ID (username or clientid), only supports search by substring."
    },
    "list_users": {
      "desc": "Get the users for the authenticator (only supported by <code>built_in_database</code>)."
    },
    "update_authn": {
      "desc": "Update the configuration of the specified gateway authenticator, or disable the authenticator."
    },
    "update_user": {
      "desc": "Update the user info for the gateway authenticator (only supports built_in_database)"
    },
    "user_id": {
      "desc": "User ID"
    }
  },
  "emqx_gateway_api_clients": {
    "add_subscription": {
      "desc": "Create a subscription membership"
    },
    "awaiting_rel_cnt": {
      "desc": "Number of awaiting acknowledge packet"
    },
    "awaiting_rel_max": {
      "desc": "Maximum allowed number of awaiting PUBREC packet"
    },
    "clean_start": {
      "desc": "Indicate whether the client is using a brand new session"
    },
    "clientid": {
      "desc": "Client ID"
    },
    "connected": {
      "desc": "Whether the client is connected"
    },
    "connected_at": {
      "desc": "Client connection time"
    },
    "created_at": {
      "desc": "Session creation time"
    },
    "delete_subscription": {
      "desc": "Delete a subscriptions membership"
    },
    "disconnected_at": {
      "desc": "Client offline time, This field is only valid and returned when connected is false"
    },
    "endpoint_name": {
      "desc": "The LwM2M client endpoint name"
    },
    "expiry_interval": {
      "desc": "Session expiration interval, with the unit of second"
    },
    "get_client": {
      "desc": "Get the gateway client information"
    },
    "heap_size": {
      "desc": "Process heap size with the unit of byte"
    },
    "inflight_cnt": {
      "desc": "Current length of inflight"
    },
    "inflight_max": {
      "desc": "Maximum length of inflight"
    },
    "ip_address": {
      "desc": "Client's IP address"
    },
    "is_bridge": {
      "desc": "Indicates whether the client is connected via bridge"
    },
    "keepalive": {
      "desc": "Keepalive time, with the unit of second"
    },
    "kick_client": {
      "desc": "Kick out the gateway client"
    },
    "lifetime": {
      "desc": "LwM2M Life time"
    },
    "list_clients": {
      "desc": "Get the gateway client list"
    },
    "list_subscriptions": {
      "desc": "Get the gateway client subscriptions"
    },
    "mailbox_len": {
      "desc": "Process mailbox size"
    },
    "mountpoint": {
      "desc": "Topic mountpoint"
    },
    "mqueue_dropped": {
      "desc": "Number of messages dropped by the message queue due to exceeding the length"
    },
    "mqueue_len": {
      "desc": "Current length of message queue"
    },
    "mqueue_max": {
      "desc": "Maximum length of message queue"
    },
    "nl": {
      "desc": "No Local option, enum: 0, 1"
    },
    "node": {
      "desc": "Name of the node to which the client is connected"
    },
    "param_clean_start": {
      "desc": "Match the client's clean start flag"
    },
    "param_clientid": {
      "desc": "Match the client's ID"
    },
    "param_conn_state": {
      "desc": "Match the client's connection state"
    },
    "param_endpoint_name": {
      "desc": "Match the lwm2m client's endpoint name"
    },
    "param_gte_connected_at": {
      "desc": "Match the client socket connected datetime greater than a certain value"
    },
    "param_gte_created_at": {
      "desc": "Match the session created datetime greater than a certain value"
    },
    "param_gte_lifetime": {
      "desc": "Match the lwm2m client registered lifetime greater than a certain value"
    },
    "param_ip_address": {
      "desc": "Match the client's ip address"
    },
    "param_like_clientid": {
      "desc": "Use sub-string to match client's ID"
    },
    "param_like_endpoint_name": {
      "desc": "Use sub-string to match lwm2m client's endpoint name"
    },
    "param_like_username": {
      "desc": "Use sub-string to match client's username"
    },
    "param_lte_connected_at": {
      "desc": "Match the client socket connected datatime less than a certain value"
    },
    "param_lte_created_at": {
      "desc": "Match the session created datetime less than a certain value"
    },
    "param_lte_lifetime": {
      "desc": "Match the lwm2m client registered lifetime less than a certain value"
    },
    "param_node": {
      "desc": "Match the client's node name"
    },
    "param_proto_ver": {
      "desc": "Match the client's protocol version"
    },
    "param_username": {
      "desc": "Match the client's Username"
    },
    "port": {
      "desc": "Client's port"
    },
    "proto_name": {
      "desc": "Client protocol name"
    },
    "proto_ver": {
      "desc": "Protocol version used by the client"
    },
    "qos": {
      "desc": "QoS level, enum: 0, 1, 2"
    },
    "rap": {
      "desc": "Retain as Published option, enum: 0, 1"
    },
    "recv_cnt": {
      "desc": "Number of socket packets received"
    },
    "recv_msg": {
      "desc": "Number of message packets received"
    },
    "recv_oct": {
      "desc": "Number of bytes received"
    },
    "recv_pkt": {
      "desc": "Number of protocol packets received"
    },
    "reductions": {
      "desc": "Erlang reduction"
    },
    "rh": {
      "desc": "Retain Handling option, enum: 0, 1, 2"
    },
    "send_cnt": {
      "desc": "Number of socket packets sent"
    },
    "send_msg": {
      "desc": "Number of message packets sent"
    },
    "send_oct": {
      "desc": "Number of bytes sent"
    },
    "send_pkt": {
      "desc": "Number of protocol packets sent"
    },
    "sub_props": {
      "desc": "Subscription properties"
    },
    "subid": {
      "desc": "Only stomp protocol, a unique identity for the subscription. range: 1-65535."
    },
    "subscriptions_cnt": {
      "desc": "Number of subscriptions established by this client"
    },
    "subscriptions_max": {
      "desc": "Maximum number of subscriptions allowed by this client"
    },
    "topic": {
      "desc": "Topic Filter/Name"
    },
    "username": {
      "desc": "Username of client when connecting"
    }
  },
  "emqx_gateway_api_listeners": {
    "add_listener": {
      "desc": "Create the gateway listener.<br/>\nNote: For listener types not supported by a gateway, this API returns `400: BAD_REQUEST`."
    },
    "add_listener_authn": {
      "desc": "Enable authenticator for specified listener for client authentication.<br/>\nWhen authenticator is enabled for a listener, all clients connecting to that listener will use that authenticator for authentication."
    },
    "add_user": {
      "desc": "Add user for the authenticator (only supports built_in_database)"
    },
    "current_connections": {
      "desc": "Current Connections"
    },
    "delete_listener": {
      "desc": "Delete the gateway listener. All connected clients under the deleted listener will be disconnected."
    },
    "delete_listener_authn": {
      "desc": "Remove authenticator for the listener."
    },
    "delete_user": {
      "desc": "Delete the user for the gateway authenticator (only supports built_in_database)"
    },
    "get_listener": {
      "desc": "Get the gateway listener configs"
    },
    "get_listener_authn": {
      "desc": "Get the listener's authenticator configs."
    },
    "get_user": {
      "desc": "Get user info from the gateway authenticator (only supports built_in_database)"
    },
    "import_users": {
      "desc": "Import users into the gateway authenticator (only supports built_in_database)"
    },
    "list_listeners": {
      "desc": "Gets a list of gateway listeners. This interface returns all the configs of the listener (including the authenticator on that listener), as well as the status of that listener running in the cluster."
    },
    "list_users": {
      "desc": "Get the users for the authenticator (only supported by <code>built_in_database</code>)"
    },
    "listener_id": {
      "desc": "Listener ID"
    },
    "listener_node_status": {
      "desc": "listener status of each node in the cluster"
    },
    "listener_status": {
      "desc": "listener status"
    },
    "node": {
      "desc": "Node Name"
    },
    "update_listener": {
      "desc": "Update the gateway listener. The listener being updated performs a restart and all clients connected to that listener will be disconnected."
    },
    "update_listener_authn": {
      "desc": "Update authenticator configs for the listener, or disable/enable it."
    },
    "update_user": {
      "desc": "Update the user info for the gateway authenticator (only supports built_in_database)"
    }
  },
  "emqx_gateway_schema": {
    "dtls_listener_acceptors": {
      "desc": "Size of the acceptor pool."
    },
    "dtls_listener_dtls_opts": {
      "desc": "DTLS socket options"
    },
    "fields_ws_opts_allow_origin_absence": {
      "desc": "If <code>false</code> and <code>check_origin_enable</code> is\n <code>true</code>, the server will reject requests that don't have <code>origin</code>\n HTTP header.",
      "label": "Allow origin absence"
    },
    "fields_ws_opts_check_origin_enable": {
      "desc": "If <code>true</code>, <code>origin</code> HTTP header will be\n validated against the list of allowed origins configured in <code>check_origins</code>\n parameter.",
      "label": "Check origin"
    },
    "fields_ws_opts_check_origins": {
      "desc": "List of allowed origins.<br/>See <code>check_origin_enable</code>.",
      "label": "Allowed origins"
    },
    "fields_ws_opts_compress": {
      "desc": "If <code>true</code>, compress WebSocket messages using <code>zlib</code>.<br/>\nThe configuration items under <code>deflate_opts</code> belong to the compression-related parameter configuration.",
      "label": "Ws compress"
    },
    "fields_ws_opts_fail_if_no_subprotocol": {
      "desc": "If <code>true</code>, the server will return an error when\n the client does not carry the <code>Sec-WebSocket-Protocol</code> field.\n <br/>Note: WeChat applet needs to disable this verification.",
      "label": "Fail if no subprotocol"
    },
    "fields_ws_opts_idle_timeout": {
      "desc": "The timeout for waiting for the WebSocket upgrade request. After the timeout, the connection will be closed.",
      "label": "WebSocket Upgrade Timeout"
    },
    "fields_ws_opts_max_frame_size": {
      "desc": "The maximum length of a single MQTT packet.",
      "label": "Max frame size"
    },
    "fields_ws_opts_path": {
      "desc": "WebSocket's MQTT protocol path. So the address of EMQX Broker's WebSocket is:\n<code>ws://{ip}:{port}/mqtt</code>",
      "label": "WS MQTT Path"
    },
    "fields_ws_opts_piggyback": {
      "desc": "Whether a WebSocket message is allowed to contain multiple MQTT packets.",
      "label": "MQTT Piggyback"
    },
    "fields_ws_opts_proxy_address_header": {
      "desc": "HTTP header used to pass information about the client IP address.\nRelevant when the EMQX cluster is deployed behind a load-balancer.",
      "label": "Proxy address header"
    },
    "fields_ws_opts_proxy_port_header": {
      "desc": "HTTP header used to pass information about the client port. Relevant when the EMQX cluster is deployed behind a load-balancer.",
      "label": "Proxy port header"
    },
    "fields_ws_opts_supported_subprotocols": {
      "desc": "Comma-separated list of supported subprotocols.",
      "label": "Supported subprotocols"
    },
    "gateway_common_authentication": {
      "desc": "Default authentication configs for all the gateway listeners. For per-listener overrides see <code>authentication</code>\n in listener configs"
    },
    "gateway_common_clientinfo_override": {
      "desc": "ClientInfo override."
    },
    "gateway_common_clientinfo_override_clientid": {
      "desc": "Template for overriding clientid."
    },
    "gateway_common_clientinfo_override_password": {
      "desc": "Template for overriding password."
    },
    "gateway_common_clientinfo_override_username": {
      "desc": "Template for overriding username."
    },
    "gateway_common_enable": {
      "desc": "Whether to enable this gateway"
    },
    "gateway_common_enable_stats": {
      "desc": "Whether to enable client process statistic"
    },
    "gateway_common_idle_timeout": {
      "desc": "The idle time of the client connection process. It has two purposes:\n  1. A newly created client process that does not receive any client requests after that time will be closed directly.\n  2. A running client process that does not receive any client requests after this time will go into hibernation to save resources."
    },
    "gateway_common_listener_access_rules": {
      "desc": "An access rule list consisting of string rules to restrict or allow access from some addresses.\nThe rules that appear earlier in the list are matched first.\nThe format is `allow | deny <address> | <CIDR> | all`.\n\nFor example:\n\n`[\\\"deny 192.168.1.1\\\", \\\"allow 192.168.1.0/24\\\", \\\"deny, all\\\"]`"
    },
    "gateway_common_listener_bind": {
      "desc": "The IP address and port that the listener will bind."
    },
    "gateway_common_listener_enable": {
      "desc": "Enable the listener."
    },
    "gateway_common_listener_enable_authn": {
      "desc": "Set <code>true</code> (default) to enable client authentication on this listener.\nWhen set to <code>false</code> clients will be allowed to connect without authentication."
    },
    "gateway_common_listener_max_conn_rate": {
      "desc": "Maximum connections per second."
    },
    "gateway_common_listener_max_connections": {
      "desc": "The maximum number of concurrent connections allowed by the listener."
    },
    "gateway_mountpoint": {
      "desc": "When publishing or subscribing, prefix all topics with a mountpoint string.\nThe prefixed string will be removed from the topic name when the message is delivered to the subscriber.\nThe mountpoint is a way that users can use to implement isolation of message routing between different listeners.\nFor example if a client A subscribes to `t` with `listeners.tcp.\\<name>.mountpoint` set to `some_tenant`,\nthen the client actually subscribes to the topic `some_tenant/t`.\nSimilarly, if another client B (connected to the same listener as the client A) sends a message to topic `t`,\nthe message is routed to all the clients subscribed `some_tenant/t`,\nso client A will receive the message, with topic name `t`. Set to `\"\"` to disable the feature.\nSupported placeholders in mountpoint string:<br/>\n  - <code>${clientid}</code>: clientid<br/>\n  - <code>${username}</code>: username<br/>\n  - <code>${endpoint_name}</code>: endpoint name"
    },
    "listener_name_to_settings_map": {
      "desc": "A map from listener names to listener settings."
    },
    "ssl_listener_options": {
      "desc": "SSL Socket options."
    },
    "tcp_listener_acceptors": {
      "desc": "Size of the acceptor pool."
    },
    "tcp_listener_proxy_protocol": {
      "desc": "If a reverse proxy is deployed for EMQX, and the PROXY protocol is enabled at the proxy to pass the client's real IP,\nthis option needs to be turned on so that EMQX can extract the client's real IP from the PROXY protocol header.\nEMQX will automatically detect the version of the PROXY protocol and support V1 and V2.\n\nFor a detailed description of the PROXY protocol, please refer to: https://www.haproxy.com/blog/haproxy/proxy-protocol/"
    },
    "tcp_listener_proxy_protocol_timeout": {
      "desc": "Timeout for proxy protocol.\nEMQX will close the TCP connection if proxy protocol packet is not received within the timeout."
    },
    "tcp_listener_tcp_opts": {
      "desc": "Setting the TCP socket options."
    },
    "tcp_listeners": {
      "desc": "Settings for the TCP listeners."
    },
    "tcp_udp_listeners": {
      "desc": "Settings for the listeners."
    },
    "udp_health_check": {
      "desc": "Some Cloud platform use a `request-reply` mechanism to check whether a UDP port is healthy, here can configure this pair."
    },
    "udp_health_check_reply": {
      "desc": "The content to reply."
    },
    "udp_health_check_request": {
      "desc": "The content of the request."
    },
    "udp_listener_active_n": {
      "desc": "Specify the {active, N} option for the socket.\nSee: https://erlang.org/doc/man/inet.html#setopts-2"
    },
    "udp_listener_buffer": {
      "desc": "Size of the user-space buffer for the socket."
    },
    "udp_listener_recbuf": {
      "desc": "Size of the kernel-space receive buffer for the socket."
    },
    "udp_listener_reuseaddr": {
      "desc": "Allow local reuse of port numbers."
    },
    "udp_listener_sndbuf": {
      "desc": "Size of the kernel-space send buffer for the socket."
    },
    "udp_listener_udp_opts": {
      "desc": "Settings for the UDP sockets."
    },
    "udp_listeners": {
      "desc": "Settings for the UDP listeners."
    }
  },
  "emqx_gbt32960_schema": {
    "max_retry_times": {
      "desc": "Re-send max times"
    },
    "message_queue_len": {
      "desc": "Max message queue length"
    },
    "retry_interval": {
      "desc": "Re-send time interval"
    }
  },
  "emqx_gcp_device_api": {
    "blocked": {
      "desc": "Blocked",
      "label": "If device is blocked from communicating to GCP IoT Core"
    },
    "config": {
      "desc": "Configuration",
      "label": "Device configuration"
    },
    "created_at": {
      "desc": "Time when GCP device was imported",
      "label": "Creation time"
    },
    "deviceid": {
      "desc": "Device identifier",
      "label": "Device identifier"
    },
    "expires_at": {
      "desc": "Public key expiration time",
      "label": "Expiration time"
    },
    "gcp_device": {
      "desc": "Configuration of authenticator using GCP Device as authentication data source."
    },
    "gcp_device_delete": {
      "desc": "Remove a device imported from GCP IoT Core",
      "label": "Remove GCP device"
    },
    "gcp_device_get": {
      "desc": "Get a device imported from GCP IoT Core",
      "label": "Get GCP device"
    },
    "gcp_device_put": {
      "desc": "Update a device imported from GCP IoT Core",
      "label": "Update GCP device"
    },
    "gcp_device_response404": {
      "desc": "The GCP device was not found"
    },
    "gcp_devices_get": {
      "desc": "List all devices imported from GCP IoT Core",
      "label": "List all GCP devices"
    },
    "gcp_devices_post": {
      "desc": "Import authentication and config data for devices from GCP IoT Core",
      "label": "Import GCP devices"
    },
    "imported_counter": {
      "desc": "Number of successfully imported GCP devices"
    },
    "imported_counter_errors": {
      "desc": "Number of GCP devices not imported due to some error"
    },
    "key": {
      "desc": "Public key",
      "label": "Public key"
    },
    "key_type": {
      "desc": "Public key type",
      "label": "Public key type"
    },
    "keys": {
      "desc": "Public keys associated to GCP device",
      "label": "Public keys"
    },
    "location": {
      "desc": "Cloud region",
      "label": "Region"
    },
    "project": {
      "desc": "Cloud project identifier",
      "label": "Project"
    },
    "registry": {
      "desc": "Device registry identifier",
      "label": "Registry"
    }
  },
  "emqx_jt808_schema": {
    "authentication_url": {
      "desc": "The JT/T 808 device authentication central URL."
    },
    "jt808_allow_anonymous": {
      "desc": "Allow anonymous access to the JT/T 808 Gateway."
    },
    "jt808_auth": {
      "desc": "Authentication settings of the JT/T 808 Gateway."
    },
    "jt808_dn_topic": {
      "desc": "The topic of the JT/T 808 protocol downstream message."
    },
    "jt808_frame_max_length": {
      "desc": "The maximum length of the JT/T 808 frame."
    },
    "jt808_up_topic": {
      "desc": "The topic of the JT/T 808 protocol upstream message."
    },
    "max_retry_times": {
      "desc": "Re-send max times"
    },
    "message_queue_len": {
      "desc": "Max message queue length"
    },
    "registry_url": {
      "desc": "The JT/T 808 device registry central URL."
    },
    "retry_interval": {
      "desc": "Re-send time interval"
    }
  },
  "emqx_ldap": {
    "base_dn": {
      "desc": "The name of the base object entry (or possibly the root) relative to\nwhich the Search is to be performed.",
      "label": "Base DN"
    },
    "bind_password": {
      "desc": "The template for password to bind.",
      "label": "Bind Password"
    },
    "filter": {
      "desc": "The filter that defines the conditions that must be fulfilled in order\nfor the Search to match a given entry.<br>\nThe syntax of the filter follows RFC 4515 and also supports placeholders.",
      "label": "Filter"
    },
    "request_timeout": {
      "desc": "Sets the maximum time in milliseconds that is used for each individual request.",
      "label": "Request Timeout"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe LDAP default port 389 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    }
  },
  "emqx_license_http_api": {
    "desc_license_info_api": {
      "desc": "Get license info",
      "label": "License info"
    },
    "desc_license_key_api": {
      "desc": "Update a license key",
      "label": "Update license"
    },
    "desc_license_setting_api": {
      "desc": "Update license setting",
      "label": "Update license setting"
    }
  },
  "emqx_license_schema": {
    "connection_high_watermark_field": {
      "desc": "High watermark limit above which license connection quota usage alarms are activated",
      "label": "Connection high watermark"
    },
    "connection_low_watermark_field": {
      "desc": "Low watermark limit below which license connection quota usage alarms are deactivated",
      "label": "Connection low watermark"
    },
    "dynamic_max_connections": {
      "desc": "Only applicable for \"Business Critical\" license type. This config sets the current allocation of license for the current cluster.\nThis value cannot exceed the connections limit assigned in the license key.",
      "label": "Dynamic Connections Limit"
    },
    "key_field": {
      "desc": "This configuration parameter is designated for the license key and supports below input formats:\n\n- Direct Key: Enter the secret key directly as a string value.\n- File Path: Specify the path to a file that contains the secret key. Ensure the path starts with <code>file://</code>.\n- \"default\": Use string value <code>\"default\"</code> to apply the default trial license.\n\nNote: An invalid license key or an incorrect file path may prevent EMQX from starting successfully.\nIf a file path is used, EMQX attempts to reload the license key from the file every 2 minutes.\nAny failure in reloading the license file will be recorded as an error level log message,\nand EMQX continues to apply the license loaded previously.",
      "label": "License string"
    },
    "license_root": {
      "desc": "Defines the EMQX Enterprise license.\n\nEMQX Enterprise is initially provided with a default trial license.\nThis license, issued in April 2024, is valid for a period of 5 years.\nIt supports up to 25 concurrent connections, catering to early-stage development and testing needs.\n\nFor deploying EMQX Enterprise in a production environment, a different license is required. You can apply for a production license by visiting https://www.emqx.com/apply-licenses/emqx?version=5",
      "label": "License"
    }
  },
  "emqx_limiter_schema": {
    "bytes_rate": {
      "desc": "Used to limit the number of bytes a single client can send to EMQX per second.\n\nOnce the limit is reached, EMQX will pause reading data from the receive-buffer, thus slowing down or even temporarily hanging the sender.\n\nThe unit of the bytes could be: B, KB, MB, GB.\n\nFor example:\n\n- `500KB/s`: Only 500 kilobytes per second will be received, and the remaining bytes will be delayed.\n- `500MB/10s`: Only 500 megabytes will be received every 10 seconds, and the remaining bytes will be delayed.",
      "label": "Data Publish Rate"
    },
    "max_conn_rate": {
      "desc": "Used to limit the rate at which the current listener accepts connections.\n\nOnce the limit is reached, EMQX will pause fetching connections from the Accept queue, thereby delaying or rejecting new connections.\n\nFor example:\n\n- `1000/s`: Only accepts 1000 connections per second.\n- `1000/10s`: Only accepts 1000 connections every 10 seconds.",
      "label": "Maximum Connection Rate"
    },
    "messages_rate": {
      "desc": "Used to limit the number of messages a single client can send to EMQX per second.\n\nOnce the limit is reached, EMQX will pause reading data from the receive-buffer, thus slowing down or even temporarily hanging the sender.\n\nFor example:\n\n- `500/s`: Only 500 messages will be received per second, and the remaining messages will be delayed.\n- `500/10s`: Only 500 messages will be received every 10 seconds and the remaining messages will be delayed.",
      "label": "Messages Publish Rate"
    }
  },
  "emqx_lwm2m_api": {
    "dataType": {
      "desc": "Data Type"
    },
    "lookup_resource": {
      "desc": "Look up a resource"
    },
    "name": {
      "desc": "Resource Name"
    },
    "observe_resource": {
      "desc": "Observe or Cancel observe a resource"
    },
    "operations": {
      "desc": "Resource Operations"
    },
    "path": {
      "desc": "Resource Path"
    },
    "read_resource": {
      "desc": "Send a read command to a resource"
    },
    "write_resource": {
      "desc": "Send a write command to a resource"
    }
  },
  "emqx_lwm2m_schema": {
    "lwm2m": {
      "desc": "The LwM2M Gateway configuration. This gateway only supports the v1.0.1 protocol."
    },
    "lwm2m_auto_observe": {
      "desc": "Automatically observe the object list of REGISTER packet."
    },
    "lwm2m_lifetime_max": {
      "desc": "Maximum value of lifetime allowed to be set by the LwM2M client."
    },
    "lwm2m_lifetime_min": {
      "desc": "Minimum value of lifetime allowed to be set by the LwM2M client."
    },
    "lwm2m_qmode_time_window": {
      "desc": "The value of the time window during which the network link is considered valid by the LwM2M Gateway in QMode mode.\nFor example, after receiving an update message from a client, any messages within this time window are sent directly to the LwM2M client, and all messages beyond this time window are temporarily stored in memory."
    },
    "lwm2m_translators": {
      "desc": "Topic configuration for LwM2M's gateway publishing and subscription."
    },
    "lwm2m_translators_command": {
      "desc": "The topic for receiving downstream commands.\nFor each new LwM2M client that succeeds in going online, the gateway creates a subscription relationship to receive downstream commands and send it to the LwM2M client"
    },
    "lwm2m_translators_notify": {
      "desc": "The topic for gateway to publish the notify events from LwM2M client.\nAfter succeed observe a resource of LwM2M client, Gateway will send the notify events via this topic, if the client reports any resource changes"
    },
    "lwm2m_translators_register": {
      "desc": "The topic for gateway to publish the register events from LwM2M client."
    },
    "lwm2m_translators_response": {
      "desc": "The topic for gateway to publish the acknowledge events from LwM2M client"
    },
    "lwm2m_translators_update": {
      "desc": "The topic for gateway to publish the update events from LwM2M client"
    },
    "lwm2m_update_msg_publish_condition": {
      "desc": "Policy for publishing UPDATE event message.<br/>\n  - always: send update events as long as the UPDATE request is received.<br/>\n  - contains_object_list: send update events only if the UPDATE request carries any Object List"
    },
    "lwm2m_xml_dir": {
      "desc": "The Directory for LwM2M Resource definition."
    },
    "translator": {
      "desc": "MQTT topic that corresponds to a particular type of event."
    },
    "translator_qos": {
      "desc": "QoS Level"
    },
    "translator_topic": {
      "desc": "Topic Name"
    }
  },
  "emqx_message_transformation_http_api": {
    "append_transformation": {
      "desc": "Append a new transformation to the list of transformations"
    },
    "delete_transformation": {
      "desc": "Delete a transformation"
    },
    "dryrun_transformation": {
      "desc": "Test an input against a transformation"
    },
    "enable_disable_transformation": {
      "desc": "Enable or disable a particular transformation"
    },
    "get_transformation_metrics": {
      "desc": "Get metrics for a particular transformation"
    },
    "list_transformations": {
      "desc": "List transformations"
    },
    "lookup_transformation": {
      "desc": "Lookup a transformation"
    },
    "param_path_enable": {
      "desc": "Enable or disable transformation"
    },
    "param_path_name": {
      "desc": "Transformation name"
    },
    "reorder_transformations": {
      "desc": "Reorder of all transformations"
    },
    "reset_transformation_metrics": {
      "desc": "Reset metrics for a particular transformation"
    },
    "update_transformation": {
      "desc": "Update a transformation"
    }
  },
  "emqx_mgmt_api_alarms": {
    "activate_at": {
      "desc": "Alarm start time, using rfc3339 standard time format."
    },
    "deactivate_at": {
      "desc": "Alarm end time, using rfc3339 standard time format."
    },
    "delete_alarms_api": {
      "desc": "Remove all historical alarms.",
      "label": "Remove all historical alarms."
    },
    "delete_alarms_api_response204": {
      "desc": "Historical alarms have been cleared successfully."
    },
    "details": {
      "desc": "Alarm details, provides more alarm information, mainly for program processing."
    },
    "duration": {
      "desc": "Indicates how long the alarm has been active in milliseconds."
    },
    "get_alarms_qs_activated": {
      "desc": "It is used to specify the alarm type of the query.\nWhen true, it returns the currently activated alarm,\nand when it is false, it returns the historical alarm.\nThe default is false."
    },
    "list_alarms_api": {
      "desc": "List currently activated alarms or historical alarms, determined by query parameters.",
      "label": "List alarms"
    },
    "message": {
      "desc": "Alarm message, which describes the alarm content in a human-readable format."
    },
    "name": {
      "desc": "Alarm name, used to distinguish different alarms."
    },
    "node": {
      "desc": "The name of the node that triggered this alarm."
    }
  },
  "emqx_mgmt_api_api_keys": {
    "api_key_list": {
      "desc": "Return api_key list. This API can only be requested using a bearer token.",
      "label": "Return api_key list"
    },
    "create_new_api_key": {
      "desc": "Create new api_key. This API can only be requested using a bearer token.",
      "label": "Create new api_key"
    },
    "delete_api_key": {
      "desc": "Delete the specific api_key. This API can only be requested using a bearer token.",
      "label": "Delete the specific api_key"
    },
    "format": {
      "desc": "Unique and format by [a-zA-Z0-9-_]",
      "label": "Unique and format by [a-zA-Z0-9-_]"
    },
    "get_api_key": {
      "desc": "Return the specific api_key. This API can only be requested using a bearer token.",
      "label": "Return the specific api_key"
    },
    "role": {
      "desc": "Role for this API"
    },
    "update_api_key": {
      "desc": "Update the specific api_key. This API can only be requested using a bearer token.",
      "label": "Update the specific api_key"
    }
  },
  "emqx_mgmt_api_banned": {
    "as": {
      "desc": "Ban method, which can be exact client ID, client ID regular expression, exact username, username regular expression,\nIP address or an IP address range.",
      "label": "Ban Method"
    },
    "at": {
      "desc": "The start time of the ban, the format is rfc3339, the default is the time when the operation was initiated.",
      "label": "Ban Time"
    },
    "by": {
      "desc": "Initiator of the ban.",
      "label": "Ban Initiator"
    },
    "clear_banned_api": {
      "desc": "Clear all banned data.",
      "label": "Clear"
    },
    "create_banned_api": {
      "desc": "Add a client ID, username or IP address to the blacklist.",
      "label": "Ban client ID, username or IP address"
    },
    "create_banned_api_response400": {
      "desc": "Bad request, possibly due to wrong parameters or the existence of a banned object."
    },
    "delete_banned_api": {
      "desc": "Remove a client ID, username or IP address from the blacklist.",
      "label": "Unban a client ID, username or IP address"
    },
    "delete_banned_api_response404": {
      "desc": "The banned object was not found in the blacklist."
    },
    "list_banned_api": {
      "desc": "List all currently banned client IDs, usernames and IP addresses.",
      "label": "List all banned client IDs"
    },
    "reason": {
      "desc": "Ban reason, record the reason why the current object was banned.",
      "label": "Ban Reason"
    },
    "until": {
      "desc": "The end time of the ban, the format is rfc3339, the default is the time when the operation was initiated + 1 year.",
      "label": "Ban End Time"
    },
    "who": {
      "desc": "Ban object, specific client ID, username or IP address.",
      "label": "Ban Object"
    }
  },
  "emqx_mgmt_api_clients": {
    "clean_authz_cache": {
      "desc": "Clean client authz cache in the cluster.",
      "label": "Clean client authz cache in the cluster."
    },
    "clients_info_from_id": {
      "desc": "Get clients info by client ID",
      "label": "Get clients info by client ID"
    },
    "get_authz_cache": {
      "desc": "Get client authz cache in the cluster.",
      "label": "Get client authz cache in the cluster."
    },
    "get_client_inflight_msgs": {
      "desc": "Get client in-flight messages",
      "label": "Get client in-flight messages"
    },
    "get_client_mqueue_msgs": {
      "desc": "Get client mqueue messages",
      "label": "Get client mqueue messages"
    },
    "get_client_subs": {
      "desc": "Get client subscriptions",
      "label": "Get client subscriptions"
    },
    "get_sessions_count": {
      "desc": "Get the total number of sessions in the cluster.\nBy default, it includes only those sessions that have not expired.\nIf the `broker.session_history_retain` config is set to a duration greater than 0s,\nthis count will also include sessions that expired within the specified retain time.\nBy specifying the `since` parameter, it can return the number of sessions that have expired within the specified time.",
      "label": "Count number of sessions"
    },
    "inflight_msgs_list": {
      "desc": "Client's in-flight messages list.\nMessages are sorted by time at which they were inserted to the In-flight storage (from older to newer messages).",
      "label": "Client's in-flight messages"
    },
    "kick_client_id": {
      "desc": "Kick out client by client ID",
      "label": "Kick out client by client ID"
    },
    "kickout_clients": {
      "desc": "Kick out a batch of client by client IDs",
      "label": "Kick out a batch of client by client IDs"
    },
    "list_clients": {
      "desc": "List clients",
      "label": "List clients"
    },
    "mqueue_msgs_list": {
      "desc": "Client's mqueue messages list.\nMessages are ordered according to their priority and queue (FIFO) order: from higher priority to lower priority.\nBy default, all messages in Mqueue have the same priority of 0.",
      "label": "Client's mqueue messages"
    },
    "msg_from_clientid": {
      "desc": "Message publisher's Client ID"
    },
    "msg_from_username": {
      "desc": "Message publisher's username.",
      "label": "Message Publisher's Username"
    },
    "msg_id": {
      "desc": "Message ID.",
      "label": "Message ID"
    },
    "msg_inserted_at": {
      "desc": "A nanosecond precision Unix epoch timestamp at which a message was inserted to In-flight / Mqueue.",
      "label": "Message Insertion Time"
    },
    "msg_mqueue_priority": {
      "desc": "Message Mqueue Priority.",
      "label": "Message Mqueue Priority"
    },
    "msg_publish_at": {
      "desc": "Message publish time, a millisecond precision Unix epoch timestamp.",
      "label": "Message Publish Time"
    },
    "msg_qos": {
      "desc": "Message QoS.",
      "label": "Message QoS"
    },
    "msg_topic": {
      "desc": "Message topic.",
      "label": "Message Topic"
    },
    "set_keepalive_seconds": {
      "desc": "Set the online client keepalive by seconds",
      "label": "Set the online client keepalive by seconds"
    },
    "subscribe": {
      "desc": "Subscribe",
      "label": "Subscribe"
    },
    "subscribe_g": {
      "desc": "Subscribe bulk",
      "label": "Subscribe bulk"
    },
    "unsubscribe": {
      "desc": "Unsubscribe",
      "label": "Unsubscribe"
    },
    "unsubscribe_g": {
      "desc": "Unsubscribe bulk",
      "label": "Unsubscribe bulk"
    }
  },
  "emqx_mgmt_api_cluster": {
    "force_remove_node": {
      "desc": "Force leave node from cluster",
      "label": "Force leave node from cluster"
    },
    "get_cluster_info": {
      "desc": "Get cluster info",
      "label": "Get cluster info"
    },
    "get_cluster_topology": {
      "desc": "Get RLOG cluster topology: connections between core and replicant nodes.",
      "label": "Get cluster topology"
    },
    "get_invitation_status": {
      "desc": "Get the execution status of all asynchronous invite status per node",
      "label": "Get invitation statuses"
    },
    "invite_node": {
      "desc": "Invite node to cluster",
      "label": "Invite node to cluster"
    },
    "invite_node_async": {
      "desc": "Send a join invitation to a node to join the cluster but do not wait for the join result. Join status can be retrieved with `GET api/<version>/invitation`",
      "label": "Asynchronously invite"
    }
  },
  "emqx_mgmt_api_configs": {
    "get_configs": {
      "desc": "Get all the configurations of the specified keys, including hot and non-hot updatable items.",
      "label": "Get all the configurations."
    },
    "get_global_zone_configs": {
      "desc": "Get the MQTT-related configuration",
      "label": "Get the MQTT-related configuration"
    },
    "get_node_level_limiter_configs": {
      "desc": "Get the node-level limiter configs",
      "label": "Get the node-level limiter configs"
    },
    "node_name": {
      "desc": "Node's name. Will deprecated in 5.2.0.",
      "label": "Node's name (deprecated)."
    },
    "rest_conf_query": {
      "desc": "Reset the config entry specified by the query string parameter `conf_path`.<br/>\n- For a config entry that has default value, this resets it to the default value;\n- For a config entry that has no default value, an error 400 will be returned",
      "label": "Reset the config entry with query"
    },
    "update_configs": {
      "desc": "Update the configurations of the specified keys.",
      "label": "Update Configurations."
    },
    "update_global_zone_configs": {
      "desc": "Update MQTT-related configuration",
      "label": "Update MQTT-related configuration"
    },
    "update_node_level_limiter_configs": {
      "desc": "Update the node-level limiter configs",
      "label": "Update the node-level limiter configs"
    }
  },
  "emqx_mgmt_api_key_schema": {
    "api_key": {
      "desc": "API Key, can be used to request API other than the management API key and the Dashboard user management API",
      "label": "API Key"
    },
    "bootstrap_file": {
      "desc": "The bootstrap file provides API keys for EMQX.\nEMQX will load these keys on startup to authorize API requests.\nIt contains colon-separated values in the format: `api_key:api_secret:role`.\nEach line specifies an API key and its associated secret, and the role of this key.\nThe 'role' part should be the pre-defined access scope group name,\nfor example, `administrator` or `viewer`.\nThe 'role' is introduced in 5.4, to be backward compatible, if it is missing, the key is implicitly granted `administrator` role.",
      "label": "Initialize api_key file."
    }
  },
  "emqx_mgmt_api_listeners": {
    "create_on_all_nodes": {
      "desc": "Create the specified listener on all nodes.",
      "label": "Create listener"
    },
    "delete_on_all_nodes": {
      "desc": "Delete the specified listener on all nodes.",
      "label": "Delete listener"
    },
    "list_by_id": {
      "desc": "List all running node's listeners for the specified id.",
      "label": "List listeners per ID"
    },
    "list_listeners": {
      "desc": "List all running node's listeners for the specified type.",
      "label": "List listeners per type"
    },
    "list_node_live_statuses": {
      "desc": "List all running node's listeners live status. group by listener type",
      "label": "List listeners live status"
    },
    "listener_type": {
      "desc": "Listener type",
      "label": "Listener type"
    },
    "restart_on_all_nodes": {
      "desc": "Restart listeners on all nodes.",
      "label": "Restart listener"
    },
    "start_on_all_nodes": {
      "desc": "Start the listener on all nodes.",
      "label": "Start listener"
    },
    "stop_on_all_nodes": {
      "desc": "Stop the listener on all nodes.",
      "label": "Stop listener"
    },
    "update_lisener": {
      "desc": "Update the specified listener on all nodes.",
      "label": "Update listener"
    }
  },
  "emqx_mgmt_api_metrics": {
    "emqx_metrics": {
      "desc": "EMQX metrics",
      "label": "EMQX metrics"
    }
  },
  "emqx_mgmt_api_nodes": {
    "get_node_info": {
      "desc": "Get node info",
      "label": "Get node info"
    },
    "get_node_metrics": {
      "desc": "Get node run-time counter metrics. Such as received or sent bytes or messages, the number of succeeded or failed authentications or authorizations, etc.",
      "label": "Get node metrics"
    },
    "get_node_stats": {
      "desc": "Get node run-time stats. Such as the number of topics, connections, etc.",
      "label": "Get node stats"
    },
    "list_nodes": {
      "desc": "List EMQX nodes",
      "label": "List EMQX nodes"
    }
  },
  "emqx_mgmt_api_publish": {
    "error_message": {
      "desc": "Describes the failure reason in detail."
    },
    "message_id": {
      "desc": "A globally unique message ID for correlation/tracing."
    },
    "message_properties": {
      "desc": "The Properties of the PUBLISH message."
    },
    "msg_content_type": {
      "desc": "The Content Type MUST be a UTF-8 Encoded String."
    },
    "msg_correlation_data": {
      "desc": "Identifier of the Correlation Data. The Server MUST send the Correlation Data unaltered to all subscribers receiving the Application Message."
    },
    "msg_message_expiry_interval": {
      "desc": "Identifier of the Message Expiry Interval. If the Message Expiry Interval has passed and the Server has not managed to start onward delivery to a matching subscriber, then it MUST delete the copy of the message for that subscriber."
    },
    "msg_payload_format_indicator": {
      "desc": "0 (0x00) Byte Indicates that the Payload is unspecified bytes, which is equivalent to not sending a Payload Format Indicator.\n1 (0x01) Byte Indicates that the Payload is UTF-8 Encoded Character Data. The UTF-8 data in the Payload MUST be well-formed UTF-8 as defined by the Unicode specification and restated in RFC 3629."
    },
    "msg_response_topic": {
      "desc": "Identifier of the Response Topic.The Response Topic MUST be a UTF-8 Encoded, It MUST NOT contain wildcard characters."
    },
    "msg_user_properties": {
      "desc": "The User-Property key-value pairs. Note: in case there are duplicated keys, only the last one will be used."
    },
    "payload": {
      "desc": "The MQTT message payload."
    },
    "payload_encoding": {
      "desc": "MQTT Payload Encoding, <code>base64</code> or <code>plain</code>. When set to <code>base64</code>, the message is decoded before it is published."
    },
    "publish_api": {
      "desc": "Possible HTTP status response codes are:<br/>\n<code>200</code>: The message is delivered to at least one subscriber;<br/>\n<code>202</code>: No matched subscribers;<br/>\n<code>400</code>: Message is invalid. for example bad topic name, or QoS is out of range;<br/>\n<code>503</code>: Failed to deliver the message to subscriber(s)",
      "label": "Publish a message"
    },
    "publish_bulk_api": {
      "desc": "Possible HTTP response status code are:<br/>\n200: All messages are delivered to at least one subscriber;<br/>\n202: At least one message was not delivered to any subscriber;<br/>\n400: At least one message is invalid. For example bad topic name, or QoS is out of range;<br/>\n503: Failed to deliver at least one of the messages;<br/>\n\nIn case there is at lest one invalid message in the batch, the HTTP response body\nis the same as for <code>/publish</code> API.<br/>\nOtherwise the HTTP response body is an array of JSON objects indicating the publish\nresult of each individual message in the batch.",
      "label": "Publish a batch of messages"
    },
    "qos": {
      "desc": "MQTT message QoS"
    },
    "reason_code": {
      "desc": "The MQTT reason code, as the same ones used in PUBACK packet.<br/>\nCurrently supported codes are:<br/>\n\n16(0x10): No matching subscribers;<br/>\n131(0x81): Error happened when dispatching the message. e.g. during EMQX restart;<br/>\n144(0x90): Topic name invalid;<br/>\n151(0x97): Publish rate limited, or message size exceeded limit. The global size limit can be configured with <code>mqtt.max_packet_size</code><br/>\nNOTE: The message size is estimated with the received topic and payload size, meaning the actual size of serialized bytes (when sent to MQTT subscriber)\nmight be slightly over the limit."
    },
    "retain": {
      "desc": "A boolean field to indicate if this message should be retained."
    },
    "topic_name": {
      "desc": "Topic Name"
    }
  },
  "emqx_mgmt_api_stats": {
    "emqx_stats": {
      "desc": "EMQX stats",
      "label": "EMQX stats"
    }
  },
  "emqx_mgmt_api_status": {
    "get_status_api": {
      "desc": "Serves as a health check for the node.\nReturns response to describe the status of the node and the application.\n\nThis endpoint requires no authentication.\n\nReturns status code 200 if the EMQX application is up and running, 503 otherwise.\nThis API was introduced in v5.0.10.\nThe GET `/status` endpoint (without the `/api/...` prefix) is also an alias to this endpoint and works in the same way.\nThis alias has been available since v5.0.0.\n\nStarting from v5.0.25 or e5.0.4, you can also use 'format' parameter to get JSON format information.",
      "label": "Service health check"
    },
    "get_status_api_format": {
      "desc": "Specify the response format, 'text' (default) to return the HTTP body in free text,\nor 'json' to return the HTTP body with a JSON object."
    },
    "get_status_response200": {
      "desc": "If 'format' parameter is 'json', then it returns a JSON like below:<br/>\n{\n  \"rel_vsn\": \"v5.0.23\",\n  \"node_name\": \"emqx@127.0.0.1\",\n  \"broker_status\": \"started\",\n  \"app_status\": \"running\"\n}\n<br/>\nOtherwise it returns free text strings as below:<br/>\nNode emqx@127.0.0.1 is started\nemqx is running"
    },
    "get_status_response503": {
      "desc": "When EMQX application is temporary not running or being restarted, it may return 'emqx is not_running'.\nIf the 'format' parameter is provided 'json', then the 'app_status' field in the JSON object will be 'not_running'."
    }
  },
  "emqx_mgmt_api_subscriptions": {
    "list_subs": {
      "desc": "List subscriptions",
      "label": "List subscriptions"
    }
  },
  "emqx_mgmt_api_topics": {
    "topic_info_by_name": {
      "desc": "Lookup topic info by name",
      "label": "Lookup topic info by name"
    },
    "topic_list": {
      "desc": "Topics list",
      "label": "Topics list"
    }
  },
  "emqx_mgmt_api_trace": {
    "clear_all": {
      "desc": "Clear all traces",
      "label": "Clear all traces"
    },
    "client_ip_addess": {
      "desc": "Specify the client's IP address if the trace type is 'ip_address'.",
      "label": "Client IP Address"
    },
    "create_new": {
      "desc": "Create new trace",
      "label": "Create new trace"
    },
    "current_trace_offset": {
      "desc": "Offset from the current trace position.",
      "label": "Offset from the current trace position."
    },
    "delete_trace": {
      "desc": "Delete specified trace",
      "label": "Delete specified trace"
    },
    "download_log_by_name": {
      "desc": "Download trace log by name",
      "label": "Download trace log by name"
    },
    "file_mtime": {
      "desc": "The last time this file is modified.",
      "label": "file mtime"
    },
    "file_size": {
      "desc": "file size",
      "label": "file size"
    },
    "filter_type": {
      "desc": "Filter type",
      "label": "Filter type"
    },
    "get_trace_file_metadata": {
      "desc": "get trace log file's metadata, such as size, last update time",
      "label": "get trace log file's metadata"
    },
    "list_all": {
      "desc": "List all trace",
      "label": "List all trace"
    },
    "max_response_bytes": {
      "desc": "Maximum number of bytes to send in response",
      "label": "Maximum response bytes"
    },
    "mqtt_clientid": {
      "desc": "Specify the MQTT clientid if the trace 'type' is 'clientid'.",
      "label": "MQTT clientid"
    },
    "node_name": {
      "desc": "Node name",
      "label": "Node name"
    },
    "ruleid": {
      "desc": "Specify the Rule ID if the trace type is 'ruleid'.",
      "label": "Rule ID"
    },
    "stop_trace": {
      "desc": "Stop trace by name",
      "label": "Stop trace by name"
    },
    "support_wildcard": {
      "desc": "Specify the topic or topic filter if the trace 'type' is 'topic'.",
      "label": "MQTT Topic"
    },
    "time_format": {
      "desc": "rfc3339 timestamp or epoch second",
      "label": "rfc3339 timestamp or epoch second"
    },
    "trace_log_formatter": {
      "desc": "The formatter that will be used to format the trace log entries. Set this to text to format the log entries as plain text (default). Set it to json to format each log entry as a JSON object.",
      "label": "Trace Log Entry Formatter"
    },
    "trace_log_size": {
      "desc": "trace log size",
      "label": "trace log size"
    },
    "trace_name": {
      "desc": "Unique name of the trace. Only ASCII letters in a-z, A-Z, 0-9 and underscore '_' are allowed.",
      "label": "Unique name of the trace"
    },
    "trace_status": {
      "desc": "trace status",
      "label": "trace status"
    },
    "trace_zip_file": {
      "desc": "A trace zip file",
      "label": "A trace zip file"
    },
    "view_trace_log": {
      "desc": "view trace log",
      "label": "view trace log"
    }
  },
  "emqx_modules_schema": {
    "enable": {
      "desc": "Enable this feature"
    },
    "max_delayed_messages": {
      "desc": "Maximum number of delayed messages (0 is no limit)."
    },
    "rewrite": {
      "desc": "The topic rewriting function of EMQX supports rewriting topic A to topic B when the client subscribes to topics, publishes messages, and cancels subscriptions according to user-configured rules.\nEach rewrite rule consists of three parts: subject filter, regular expression, and target expression.\nUnder the premise that the subject rewriting function is enabled, when EMQX receives a subject-based MQTT message such as a `PUBLISH` message,\nit will use the subject of the message to sequentially match the subject filter part of the rule in the configuration file. If the match is successful,\nthe regular expression is used to extract the information in the subject, and then replaced with the target expression to form a new subject.\nVariables in the format of `$N` can be used in the target expression to match the elements extracted from the regular expression.\nThe value of `$N` is the Nth element extracted from the regular expression. For example, `$1` is the regular expression. The first element extracted by the expression.\nIt should be noted that EMQX uses reverse order to read the rewrite rules in the configuration file.\nWhen a topic can match the topic filter of multiple topic rewrite rules at the same time, EMQX will only use the first rule it matches. Rewrite.\nIf the regular expression in this rule does not match the subject of the MQTT message, the rewriting will fail, and no other rules will be attempted for rewriting.\nTherefore, users need to carefully design MQTT message topics and topic rewriting rules when using them.",
      "label": "Topic Rewrite"
    },
    "tr_action": {
      "desc": "Topic rewriting takes effect on the type of operation:\n  - `subscribe`: Rewrite topic when client do subscribe.\n  - `publish`: Rewrite topic when client do publish.\n  - `all`: Both",
      "label": "Action"
    },
    "tr_dest_topic": {
      "desc": "Destination topic.",
      "label": "Destination Topic"
    },
    "tr_re": {
      "desc": "Regular expressions"
    },
    "tr_source_topic": {
      "desc": "Source topic, specified by the client.",
      "label": "Source Topic"
    }
  },
  "emqx_mongodb": {
    "auth_source": {
      "desc": "Database name associated with the user's credentials.",
      "label": "Auth Source"
    },
    "connect_timeout": {
      "desc": "The duration to attempt a connection before timing out.",
      "label": "Connect Timeout"
    },
    "desc_rs": {
      "desc": "Settings for replica set.",
      "label": "Setting Replica Set"
    },
    "desc_sharded": {
      "desc": "Settings for sharded cluster.",
      "label": "Setting Sharded Cluster"
    },
    "desc_single": {
      "desc": "Settings for a single MongoDB instance.",
      "label": "Setting Single MongoDB"
    },
    "desc_topology": {
      "desc": "Topology of MongoDB.",
      "label": "Setting Topology"
    },
    "heartbeat_period": {
      "desc": "Controls when the driver checks the state of the MongoDB deployment. Specify the interval between checks, counted from the end of the previous check until the beginning of the next one. If the number of connections is increased (which will happen, for example, if you increase the pool size), you may need to increase this period as well to avoid creating too many log entries in the MongoDB log file.",
      "label": "Heartbeat period"
    },
    "local_threshold": {
      "desc": "The size of the latency window for selecting among multiple suitable MongoDB instances.",
      "label": "Local Threshold"
    },
    "max_overflow": {
      "desc": "The maximum number of additional workers that can be created when all workers in the pool are busy. This helps to manage temporary spikes in workload by allowing more concurrent connections to the MongoDB server.",
      "label": "Max Overflow Workers"
    },
    "min_heartbeat_period": {
      "desc": "Controls the minimum amount of time to wait between heartbeats.",
      "label": "Minimum Heartbeat Period"
    },
    "overflow_check_period": {
      "desc": "Period for checking if there are more workers than configured (\"overflow\").",
      "label": "Overflow Check Period"
    },
    "overflow_ttl": {
      "desc": "Period of time before workers that exceed the configured pool size (\"overflow\") to be terminated.",
      "label": "Overflow TTL"
    },
    "r_mode": {
      "desc": "Read mode.",
      "label": "Read Mode"
    },
    "replica_set_name": {
      "desc": "Name of the replica set.",
      "label": "Replica Set Name"
    },
    "rs_mongo_type": {
      "desc": "Replica set. Must be set to 'rs' when MongoDB server is running in 'replica set' mode.",
      "label": "Replica set"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe MongoDB default port 27017 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "server_selection_timeout": {
      "desc": "Specifies how long to block for server selection before throwing an exception.",
      "label": "Server Selection Timeout"
    },
    "servers": {
      "desc": "A Node list for Cluster to connect to. The nodes should be separated with commas, such as: `Node[,Node].`\nFor each Node should be: The IPv4 or IPv6 address or the hostname to connect to.\nA host entry has the following form: `Host[:Port]`.\nThe MongoDB default port 27017 is used if `[:Port]` is not specified.",
      "label": "Servers"
    },
    "sharded_mongo_type": {
      "desc": "Sharded cluster. Must be set to 'sharded' when MongoDB server is running in 'sharded' mode.",
      "label": "Sharded cluster"
    },
    "single_mongo_type": {
      "desc": "Standalone instance. Must be set to 'single' when MongoDB server is running in standalone mode.",
      "label": "Standalone instance"
    },
    "socket_timeout": {
      "desc": "The duration to attempt to send or to receive on a socket before the attempt times out.",
      "label": "Socket Timeout"
    },
    "srv_record": {
      "desc": "Use DNS SRV record.",
      "label": "Srv Record"
    },
    "use_legacy_protocol": {
      "desc": "Whether to use MongoDB's legacy protocol for communicating with the database.  The default is to attempt to automatically determine if the newer protocol is supported.",
      "label": "Use legacy protocol"
    },
    "w_mode": {
      "desc": "Write mode.",
      "label": "Write Mode"
    },
    "wait_queue_timeout": {
      "desc": "The maximum duration that a worker can wait for a connection to become available.",
      "label": "Wait Queue Timeout"
    }
  },
  "emqx_mqttsn_schema": {
    "mqttsn": {
      "desc": "The MQTT-SN Gateway configuration.\nThis gateway only supports the v1.2 protocol"
    },
    "mqttsn_broadcast": {
      "desc": "Whether to periodically broadcast ADVERTISE messages"
    },
    "mqttsn_enable_qos3": {
      "desc": "Allows connectionless clients to publish messages with a Qos of -1.\nThis feature is defined for very simple client implementations which do not support any other features except this one. There is no connection setup nor tear down, no registration nor subscription. The client just sends its 'PUBLISH' messages to a GW"
    },
    "mqttsn_gateway_id": {
      "desc": "MQTT-SN Gateway ID.\nWhen the <code>broadcast</code> option is enabled, the gateway will broadcast ADVERTISE message with this value"
    },
    "mqttsn_predefined": {
      "desc": "The pre-defined topic IDs and topic names.\nA 'pre-defined' topic ID is a topic ID whose mapping to a topic name is known in advance by both the client's application and the gateway"
    },
    "mqttsn_predefined_id": {
      "desc": "Topic ID. Range: 1-65535"
    },
    "mqttsn_predefined_topic": {
      "desc": "Topic Name"
    },
    "mqttsn_subs_resume": {
      "desc": "Whether to initiate all subscribed topic name registration messages to the client after the Session has been taken over by a new channel"
    }
  },
  "emqx_mysql": {
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe MySQL default port 3306 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    }
  },
  "emqx_node_rebalance_api": {
    "abs_conn_threshold": {
      "desc": "Maximum desired difference between the number of connections on the node and the average number of connections on the recipient nodes. Difference lower than this is the goal of the rebalance process.",
      "label": "Absolute connection threshold"
    },
    "abs_sess_threshold": {
      "desc": "Maximum desired difference between the number of sessions on the node and the average number of sessions on the recipient nodes. Difference lower than this is the goal of the evacuation process.",
      "label": "Absolute session threshold"
    },
    "cluster_purge_start": {
      "desc": "Start purge process",
      "label": "Start purge"
    },
    "cluster_purge_stop": {
      "desc": "Stop purge process",
      "label": "Stop purge"
    },
    "conn_evict_rate": {
      "desc": "The rate of evicting connections, in connections per second",
      "label": "Connection eviction rate"
    },
    "coordinator_status_donor_conn_avg": {
      "desc": "Average number of connections per donor node",
      "label": "Donor connections average"
    },
    "coordinator_status_donor_sess_avg": {
      "desc": "Average number of sessions per donor node",
      "label": "Donor sessions average"
    },
    "coordinator_status_donors": {
      "desc": "List of nodes from which connections/sessions are being evacuated",
      "label": "Donors"
    },
    "coordinator_status_node": {
      "desc": "The node that is coordinating the evacuation/rebalance process",
      "label": "Coordinator node"
    },
    "empty_response": {
      "desc": "The response is empty",
      "label": "Empty response"
    },
    "evacuation_status_node": {
      "desc": "The node that is being evacuated",
      "label": "Evacuated node"
    },
    "global_status_evacuations": {
      "desc": "List of nodes that are being evacuated",
      "label": "Evacuations"
    },
    "global_status_rebalances": {
      "desc": "List of nodes that coordinate a rebalance",
      "label": "Rebalances"
    },
    "load_rebalance_availability_check": {
      "desc": "Check if the node is being evacuated or rebalanced",
      "label": "Availability check"
    },
    "load_rebalance_evacuation_start": {
      "desc": "Start evacuation process",
      "label": "Start evacuation"
    },
    "load_rebalance_evacuation_stop": {
      "desc": "Stop evacuation process",
      "label": "Stop evacuation"
    },
    "load_rebalance_global_status": {
      "desc": "Get status of all rebalance/evacuation processes across the cluster",
      "label": "Get global rebalance status"
    },
    "load_rebalance_start": {
      "desc": "Start rebalance process",
      "label": "Start rebalance"
    },
    "load_rebalance_status": {
      "desc": "Get rebalance status of the current node",
      "label": "Get rebalance status"
    },
    "load_rebalance_stop": {
      "desc": "Stop rebalance process",
      "label": "Stop rebalance"
    },
    "local_status_connection_eviction_rate": {
      "desc": "The rate of evicting connections, in connections per second",
      "label": "Connection eviction rate"
    },
    "local_status_connection_goal": {
      "desc": "The number of connections that the node should have after the rebalance/evacuation process",
      "label": "Connection goal"
    },
    "local_status_coordinator_node": {
      "desc": "The node that is coordinating rebalance process",
      "label": "Coordinator node"
    },
    "local_status_disconnected_session_goal": {
      "desc": "The number of disconnected sessions that the node should have after the rebalance process",
      "label": "Disconnected session goal"
    },
    "local_status_enabled": {
      "desc": "Whether the node is being evacuated",
      "label": "Local evacuation status"
    },
    "local_status_process": {
      "desc": "The type of the task that is being performed on the node: 'evacuation' or 'rebalance'",
      "label": "Task Type"
    },
    "local_status_purge_rate": {
      "desc": "The rate of purging sessions, in sessions per second",
      "label": "Session purge rate"
    },
    "local_status_recipients": {
      "desc": "List of nodes to which connections/sessions are being evacuated during rebalance",
      "label": "Recipients"
    },
    "local_status_session_eviction_rate": {
      "desc": "The rate of evicting sessions, in sessions per second",
      "label": "Session eviction rate"
    },
    "local_status_session_goal": {
      "desc": "The number of sessions that the node should have after the evacuation process",
      "label": "Session goal"
    },
    "local_status_session_recipients": {
      "desc": "List of nodes to which sessions are being evacuated",
      "label": "Session recipients"
    },
    "local_status_state": {
      "desc": "The state of the process that is being performed on the node",
      "label": "Rebalance/evacuation current state"
    },
    "local_status_stats": {
      "desc": "Statistics of the evacuation/rebalance process",
      "label": "Statistics"
    },
    "migrate_to": {
      "desc": "Nodes to migrate sessions to",
      "label": "Migrate to"
    },
    "param_node": {
      "desc": "Node name",
      "label": "Node name"
    },
    "rebalance_nodes": {
      "desc": "Nodes to participate in rebalance",
      "label": "Rebalance nodes"
    },
    "redirect_to": {
      "desc": "Server reference to redirect clients to (MQTTv5 Server redirection)",
      "label": "Redirect to"
    },
    "rel_conn_threshold": {
      "desc": "Maximum desired fraction between the number of connections on the node and the average number of connections on the recipient nodes. Fraction lower than this is the goal of the rebalance process.",
      "label": "Relative connection threshold"
    },
    "rel_sess_threshold": {
      "desc": "Maximum desired fraction between the number of sessions on the node and the average number of sessions on the recipient nodes. Fraction lower than this is the goal of the evacuation process",
      "label": "Relative session threshold"
    },
    "sess_evict_rate": {
      "desc": "The rate of evicting sessions, in sessions per second",
      "label": "Session eviction rate"
    },
    "status_stats_current_connected": {
      "desc": "Current number of connections on the node",
      "label": "Current connections"
    },
    "status_stats_current_disconnected_sessions": {
      "desc": "Current number of disconnected sessions on the node",
      "label": "Current disconnected sessions"
    },
    "status_stats_current_sessions": {
      "desc": "Current number of sessions on the node",
      "label": "Current sessions"
    },
    "status_stats_initial_connected": {
      "desc": "The number of connections on the node before the evacuation/rebalance process",
      "label": "Initial connected"
    },
    "status_stats_initial_sessions": {
      "desc": "The number of sessions on the node before the evacuation/rebalance process",
      "label": "Initial sessions"
    },
    "wait_health_check": {
      "desc": "Time to wait before starting the rebalance/evacuation process, in seconds",
      "label": "Wait health check"
    },
    "wait_takeover": {
      "desc": "Time to wait before starting session evacuation process, in seconds",
      "label": "Wait takeover"
    }
  },
  "emqx_ocpp_schema": {
    "default_heartbeat_interval": {
      "desc": "The default Heartbeat time interval"
    },
    "dnstream_max_mqueue_len": {
      "desc": "The maximum message queue length for download stream message delivery."
    },
    "dnstream_topic": {
      "desc": "Download stream topic to receive request/control messages from third-party system.\nThis value is a wildcard topic name that subscribed by every connected Charge Point."
    },
    "heartbeat_checking_times_backoff": {
      "desc": "The backoff for heartbeat checking times"
    },
    "json_schema_dir": {
      "desc": "JSON Schema directory for OCPP message definitions.\nDefault: ${application}/priv/schemas"
    },
    "json_schema_id_prefix": {
      "desc": "The ID prefix for the OCPP message schemas."
    },
    "message_format_checking": {
      "desc": "Whether to enable message format legality checking.\nEMQX checks the message format of the upload stream and download stream against the\nformat defined in json-schema.\nWhen the check fails, emqx will reply with a corresponding answer message.\n\nThe checking strategy can be one of the following values:\n- <code>all</code>: check all messages\n- <code>upstream_only</code>: check upload stream messages only\n- <code>dnstream_only</code>: check download stream messages only\n- <code>disable</code>: don't check any messages"
    },
    "upstream_error_topic": {
      "desc": "The topic for Upload stream error topic."
    },
    "upstream_reply_topic": {
      "desc": "The topic for Upload stream Reply messages."
    },
    "upstream_topic": {
      "desc": "The topic for Upload stream Call Request messages."
    },
    "upstream_topic_override_mapping": {
      "desc": "Upload stream topic override mapping by Message Name."
    },
    "ws": {
      "desc": "Websocket listener."
    },
    "wss": {
      "desc": "Websocket over TLS listener."
    }
  },
  "emqx_oracle": {
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>A host entry has the following form: `Host[:Port]`.<br/>The Oracle Database default port 1521 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "service_name": {
      "desc": "Service Name for Oracle Database.",
      "label": "Oracle Database Service Name"
    },
    "sid": {
      "desc": "Sid for Oracle Database.",
      "label": "Oracle Database Sid"
    }
  },
  "emqx_otel_schema": {
    "enable": {
      "desc": "Enable or disable Open Telemetry signal.",
      "label": "Enable."
    },
    "exporter_endpoint": {
      "desc": "The target URL to which the exporter is going to send Open Telemetry signal data.",
      "label": "Exporter Endpoint"
    },
    "exporter_protocol": {
      "desc": "The transport protocol of Open Telemetry Exporter",
      "label": "Exporter Protocol"
    },
    "exporter_ssl": {
      "desc": "SSL configuration for the Open Telemetry exporter",
      "label": "SSL Options"
    },
    "exporting_timeout": {
      "desc": "The time Open Telemetry signal export can run before it is cancelled.",
      "label": "Exporting Timeout"
    },
    "max_queue_size": {
      "desc": "The maximum queue size. After the size is reached Open Telemetry signals are dropped.",
      "label": "Max Queue Size"
    },
    "opentelemetry": {
      "desc": "Open Telemetry Toolkit configuration",
      "label": "Open Telemetry"
    },
    "otel_exporter": {
      "desc": "Open Telemetry Exporter",
      "label": "Exporter"
    },
    "otel_log_handler_level": {
      "desc": "The log level of the Open Telemetry log handler.",
      "label": "Log Level"
    },
    "otel_logs": {
      "desc": "Open Telemetry Logs configuration. If enabled, EMQX installs a log handler that formats events according to Open Telemetry log data model and\nexports them to the configured Open Telemetry collector or backend.",
      "label": "Open Telemetry Logs"
    },
    "otel_metrics": {
      "desc": "Open Telemetry Metrics configuration.",
      "label": "Open Telemetry Metrics"
    },
    "otel_traces": {
      "desc": "Open Telemetry Traces configuration.",
      "label": "Open Telemetry Traces"
    },
    "scheduled_delay": {
      "desc": "The delay interval between two consecutive exports of Open Telemetry signals.",
      "label": "Scheduled Delay Interval"
    },
    "trace_all": {
      "desc": "If enabled, all published messages are traced, a new trace ID is generated if it can't be extracted from the message.\nOtherwise, only messages published with trace context are traced. Disabled by default.",
      "label": "Trace All"
    },
    "trace_filter": {
      "desc": "Open Telemetry Trace Filter configuration",
      "label": "Trace Filter"
    }
  },
  "emqx_plugins_schema": {
    "check_interval": {
      "desc": "Check interval: check if the status of the plugins in the cluster is consistent, <br/>\nif the results of 3 consecutive checks are not consistent, then alarm."
    },
    "enable": {
      "desc": "Set to 'true' to enable this plugin",
      "label": "Enable"
    },
    "install_dir": {
      "desc": "The installation directory for the external plugins.\nThe plugin beam files and configuration files should reside in\nthe subdirectory named as <code>emqx_foo_bar-0.1.0</code>.\n<br/>\nNOTE: For security reasons, this directory should **NOT** be writable\nby anyone except <code>emqx</code> (or any user which runs EMQX).",
      "label": "Install Directory"
    },
    "name_vsn": {
      "desc": "The `{name}-{version}` of the plugin.<br/>\nIt should match the plugin application name-version as plugin release package name<br/>\nFor example: `my_plugin-0.1.0`.",
      "label": "Name-Version"
    },
    "plugins": {
      "desc": "Manage EMQX plugins.<br/>\nPlugins can be pre-built as a part of EMQX package,\nor installed as a standalone package in a location specified by\n<code>install_dir</code> config key<br/>\nThe standalone-installed plugins are referred to as 'external' plugins.",
      "label": "Plugins"
    },
    "state": {
      "desc": "A per-plugin config to describe the desired state of the plugin.",
      "label": "State"
    },
    "states": {
      "desc": "An array of plugins in the desired states.<br/>\nThe plugins are started in the defined order",
      "label": "States"
    }
  },
  "emqx_postgresql": {
    "config_connector": {
      "desc": "The configuration for the PostgreSQL connector.",
      "label": "PostgreSQL Connector Config"
    },
    "disable_prepared_statements": {
      "desc": "Disables the usage of prepared statements in the connections.\nSome endpoints, like PGBouncer or Supabase in Transaction mode, do not\nsupport session features such as prepared statements.  For such connections,\nthis option should be enabled.",
      "label": "Disable Prepared Statements"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe PostgreSQL default port 5432 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    }
  },
  "emqx_postgresql_connector_schema": {
    "config_connector": {
      "desc": "The configuration for the PostgreSQL connector.",
      "label": "PostgreSQL Connector Config"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe PostgreSQL default port 5432 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    }
  },
  "emqx_prometheus_api": {
    "get_prom_auth_data": {
      "desc": "Get Prometheus Metrics for AuthN, AuthZ and Banned",
      "label": "Prometheus Metrics for Auth"
    },
    "get_prom_conf_info": {
      "desc": "Get Prometheus config info",
      "label": "Get Prometheus config info"
    },
    "get_prom_data": {
      "desc": "Get Prometheus Metrics",
      "label": "Prometheus Metrics"
    },
    "get_prom_data_integration_data": {
      "desc": "Get Prometheus Metrics for Data Integration",
      "label": "Prometheus Metrics for Data Integration"
    },
    "get_prom_message_transformation": {
      "desc": "Get Prometheus Metrics for Message Validation",
      "label": "Prometheus Metrics for Message Validation"
    },
    "get_prom_schema_validation": {
      "desc": "Get Prometheus Metrics for Schema Validation",
      "label": "Prometheus Metrics for Schema Validation"
    },
    "update_prom_conf_info": {
      "desc": "Update Prometheus config",
      "label": "Update Prometheus config"
    }
  },
  "emqx_prometheus_schema": {
    "collectors": {
      "desc": "The internal advanced metrics of the virtual machine are initially disabled\nand are usually only enabled during performance testing.\nEnabling them will increase the CPU load."
    },
    "enable_basic_auth": {
      "desc": "Enable or disable basic authentication for prometheus scrape api, not for Push Gateway"
    },
    "headers": {
      "desc": "An HTTP Headers when pushing to Push Gateway.<br/>\nFor example, <code> { Authorization = \"some-authz-tokens\"}</code>"
    },
    "interval": {
      "desc": "Data reporting interval"
    },
    "job_name": {
      "desc": "Job Name that is pushed to the Push Gateway. Available variables:<br/>\n- ${name}: Name of EMQX node.<br/>\n- ${host}: Host name of EMQX node.<br/>\nFor example, when the EMQX node name is <code>emqx@127.0.0.1</code> then the <code>name</code>\nvariable takes value <code>emqx</code> and the <code>host</code> variable takes value <code>127.0.0.1</code>.\nDefault value is: <code>${name}/instance/${name}~${host}</code>"
    },
    "legacy_deprecated_setting": {
      "desc": "Deprecated since 5.4.0"
    },
    "legacy_enable": {
      "desc": "Deprecated since 5.4.0, use `prometheus.push_gateway.url` instead"
    },
    "legacy_headers": {
      "desc": "Deprecated since 5.4.0, use `prometheus.push_gateway.headers` instead"
    },
    "legacy_interval": {
      "desc": "Deprecated since 5.4.0, use `prometheus.push_gateway.interval` instead"
    },
    "legacy_job_name": {
      "desc": "Deprecated since 5.4.0, use `prometheus.push_gateway.job_name` instead"
    },
    "legacy_mnesia_collector": {
      "desc": "Deprecated since 5.4.0, use `prometheus.collectors.mnesia` instead"
    },
    "legacy_push_gateway_server": {
      "desc": "Deprecated since 5.4.0, use `prometheus.push_gateway.url` instead"
    },
    "legacy_vm_dist_collector": {
      "desc": "Deprecated since 5.4.0, use `prometheus.collectors.vm_dist` instead"
    },
    "legacy_vm_memory_collector": {
      "desc": "Deprecated since 5.4.0, use `prometheus.collectors.vm_memory` instead"
    },
    "legacy_vm_msacc_collector": {
      "desc": "Deprecated since 5.4.0, use `prometheus.collectors.vm_msacc` instead"
    },
    "legacy_vm_statistics_collector": {
      "desc": "Deprecated since 5.4.0, use `prometheus.collectors.vm_statistics` instead"
    },
    "legacy_vm_system_info_collector": {
      "desc": "Deprecated, use `prometheus.collectors.vm_system_info` instead"
    },
    "mnesia_collector": {
      "desc": "Collects Mnesia metrics mainly using <code> mnesia:system_info/1 </code>"
    },
    "prometheus": {
      "desc": "EMQX's Prometheus scraping endpoint is enabled by default without authentication.\nYou can inspect it with a `curl` command like this: `curl -f \"127.0.0.1:18083/api/v5/prometheus/stats\"`",
      "label": "Prometheus"
    },
    "push_gateway": {
      "desc": "Push Gateway is optional, should not be configured if prometheus is to scrape EMQX."
    },
    "push_gateway_enable": {
      "desc": "Enable or disable Pushgateway"
    },
    "push_gateway_url": {
      "desc": "URL of Pushgateway server. Pushgateway is optional, should not be configured if prometheus is to scrape EMQX."
    },
    "recommend_setting": {
      "desc": "Recommended setting"
    },
    "vm_dist_collector": {
      "desc": "Enable or disable VM distribution collector,\ncollects information about the sockets and processes involved in the Erlang distribution mechanism."
    },
    "vm_memory_collector": {
      "desc": "Collects information about memory dynamically allocated by the Erlang emulator using\n<code> erlang:memory/0 </code>."
    },
    "vm_msacc_collector": {
      "desc": "Enable or disable VM microstate accounting metrics collector."
    },
    "vm_statistics_collector": {
      "desc": "Enable or disable VM statistics collector."
    },
    "vm_system_info_collector": {
      "desc": "Enable or disable VM system info collector."
    }
  },
  "emqx_psk_schema": {
    "chunk_size": {
      "desc": "The size of each chunk used to import to the built-in database from PSK file"
    },
    "enable": {
      "desc": "Whether to enable TLS PSK support"
    },
    "init_file": {
      "desc": "If init_file is specified, EMQX will import PSKs from the file into the built-in database at startup for use by the runtime.\nThe file has to be structured line-by-line, each line must be in the format of <code>PSKIdentity:SharedSecret</code>.\nFor example: <code>mydevice1:c2VjcmV0</code>"
    },
    "psk_authentication": {
      "desc": "PSK stands for 'Pre-Shared Keys'.\nThis config to enable TLS-PSK authentication.\n\nImportant! Make sure the SSL listener with only <code>tlsv1.2</code> enabled, and also PSK cipher suites\nconfigured, such as <code>RSA-PSK-AES256-GCM-SHA384</code>.\n\nSee listener SSL options config for more details.\n\nThe IDs and secrets can be provided from a file which is configurable by the <code>init_file</code> field."
    },
    "separator": {
      "desc": "The separator between <code>PSKIdentity</code> and <code>SharedSecret</code> in the PSK file"
    }
  },
  "emqx_redis": {
    "cluster": {
      "desc": "Cluster mode. Must be set to 'cluster' when Redis server is running in clustered mode.",
      "label": "Cluster Mode"
    },
    "database": {
      "desc": "Redis database ID.",
      "label": "Database ID"
    },
    "redis_cluster_connector": {
      "desc": "Redis connector in cluster mode",
      "label": "Redis Cluster Connector"
    },
    "redis_sentinel_connector": {
      "desc": "Redis connector in sentinel mode",
      "label": "Redis Sentinel Connector"
    },
    "redis_single_connector": {
      "desc": "Redis connector in sentinel mode",
      "label": "Redis Single Connector"
    },
    "sentinel": {
      "desc": "Sentinel mode. Must be set to 'sentinel' when Redis server is running in sentinel mode.",
      "label": "Sentinel Mode"
    },
    "sentinel_desc": {
      "desc": "The cluster name in Redis sentinel mode.",
      "label": "Cluster Name"
    },
    "server": {
      "desc": "The IPv4 or IPv6 address or the hostname to connect to.<br/>\nA host entry has the following form: `Host[:Port]`.<br/>\nThe Redis default port 6379 is used if `[:Port]` is not specified.",
      "label": "Server Host"
    },
    "servers": {
      "desc": "A Node list for Cluster to connect to. The nodes should be separated with commas, such as: `Node[,Node].`\nFor each Node should be: The IPv4 or IPv6 address or the hostname to connect to.\nA host entry has the following form: `Host[:Port]`.\nThe Redis default port 6379 is used if `[:Port]` is not specified.",
      "label": "Servers"
    },
    "single": {
      "desc": "Single mode. Must be set to 'single' when Redis server is running in single mode.",
      "label": "Single Mode"
    }
  },
  "emqx_resource_schema": {
    "batch_size": {
      "desc": "Maximum batch count. If equal to 1, there's effectively no batching.",
      "label": "Max batch size"
    },
    "batch_time": {
      "desc": "Maximum waiting interval when accumulating a batch at a low message rates for more efficient resource usage.",
      "label": "Max batch wait time"
    },
    "buffer_seg_bytes": {
      "desc": "Applicable when buffer mode is set to <code>volatile_offload</code>.\nThis value is to specify the size of each on-disk buffer file.",
      "label": "Segment File Bytes"
    },
    "creation_opts": {
      "desc": "Creation options.",
      "label": "Creation Options"
    },
    "enable_batch": {
      "desc": "Batch mode enabled.",
      "label": "Enable batch"
    },
    "enable_queue": {
      "desc": "Enable disk buffer queue (only applicable for egress bridges).\nWhen Enabled, messages will be buffered on disk when the bridge connection is down.\nWhen disabled the messages are buffered in RAM only.",
      "label": "Enable disk buffer queue"
    },
    "health_check_interval": {
      "desc": "Health check interval.",
      "label": "Health Check Interval"
    },
    "inflight_window": {
      "desc": "Query inflight window. When query_mode is set to async, this config has to be set to 1 if messages from the same MQTT client have to be strictly ordered.",
      "label": "Inflight window"
    },
    "max_buffer_bytes": {
      "desc": "Maximum number of bytes to buffer for each buffer worker.",
      "label": "Max buffer queue size"
    },
    "query_mode": {
      "desc": "Query mode. Optional 'sync/async', default 'async'.",
      "label": "Query mode"
    },
    "request_ttl": {
      "desc": "Starting from the moment when the request enters the buffer, if the request remains in the buffer for the specified time or is sent but does not receive a response or acknowledgement in time, the request is considered expired.",
      "label": "Request TTL"
    },
    "resource_opts": {
      "desc": "Resource options.",
      "label": "Resource Options"
    },
    "resume_interval": {
      "desc": "The interval at which the buffer worker attempts to resend failed requests in the inflight window.",
      "label": "Resume Interval"
    },
    "start_after_created": {
      "desc": "Whether start the resource right after created.",
      "label": "Start After Created"
    },
    "start_timeout": {
      "desc": "Time interval to wait for an auto-started resource to become healthy before responding resource creation requests.",
      "label": "Start Timeout"
    },
    "worker_pool_size": {
      "desc": "The number of buffer workers. Only applicable for egress type bridges.\nFor bridges only have ingress direction data flow, it can be set to 0 otherwise must be greater than 0.",
      "label": "Buffer Pool Size"
    }
  },
  "emqx_retainer_api": {
    "config_content": {
      "desc": "The config content"
    },
    "config_not_found": {
      "desc": "Config not found."
    },
    "delete_matching_api": {
      "desc": "Delete matching messages.",
      "label": "Delete matching messages"
    },
    "delete_messages": {
      "desc": "Delete all retained messages",
      "label": "Delete Retained Messages"
    },
    "from_clientid": {
      "desc": "The clientid of publisher."
    },
    "from_username": {
      "desc": "The username of publisher."
    },
    "get_config_api": {
      "desc": "View config",
      "label": "View config"
    },
    "list_retained_api": {
      "desc": "List retained messages.",
      "label": "List retained messages."
    },
    "lookup_api": {
      "desc": "Lookup a message by a topic without wildcards.",
      "label": "Lookup a message"
    },
    "message_detail": {
      "desc": "Details of the message."
    },
    "message_not_exist": {
      "desc": "Viewed message doesn't exist."
    },
    "msgid": {
      "desc": "Message ID."
    },
    "payload": {
      "desc": "Payload."
    },
    "publish_at": {
      "desc": "Message publish time, RFC 3339 format."
    },
    "qos": {
      "desc": "QoS."
    },
    "query_match_topic": {
      "desc": "Topic filter, supports wildcards, omit this to match all messages."
    },
    "retained_list": {
      "desc": "Retained messages list."
    },
    "topic": {
      "desc": "Topic."
    },
    "unsupported_backend": {
      "desc": "Unsupported backend."
    },
    "update_config_failed": {
      "desc": "Update config failed"
    },
    "update_config_success": {
      "desc": "Update configs successfully."
    },
    "update_retainer_api": {
      "desc": "Update retainer config.",
      "label": "Update retainer config"
    }
  },
  "emqx_retainer_schema": {
    "backend": {
      "desc": "Settings for the database storing the retained messages."
    },
    "batch_deliver_limiter": {
      "desc": "The rate limiter name for retained messages' delivery.\nLimiter helps to avoid delivering too many messages to the client at once, which may cause the client to block or crash, or drop messages due to exceeding the size of the message queue.\nThe names of the available rate limiters are taken from the existing rate limiters under `limiter.batch`.\nIf this field is empty, limiter is not used."
    },
    "batch_deliver_number": {
      "desc": "The number of retained messages can be delivered per batch."
    },
    "batch_read_number": {
      "desc": "Size of the batch when reading messages from storage. 0 means no limit."
    },
    "delivery_rate": {
      "desc": "The maximum rate of delivering retained messages"
    },
    "enable": {
      "desc": "Enable retainer feature"
    },
    "flow_control": {
      "desc": "Flow control."
    },
    "max_payload_size": {
      "desc": "The maximum size of retained messages allowed to be stored. EMQX will refuse to store retained messages larger than this size and output an Error log with the keyword 'retain_failed_for_payload_size_exceeded_limit'.\n\n0 means unlimited retained message size."
    },
    "max_retained_messages": {
      "desc": "Maximum number of retained messages. 0 means no limit."
    },
    "mnesia_config_storage_type": {
      "desc": "Specifies whether the messages are stored in RAM or persisted on disc."
    },
    "mnesia_config_type": {
      "desc": "Backend type."
    },
    "mnesia_enable": {
      "desc": "Enable built-in Mnesia backend."
    },
    "msg_clear_interval": {
      "desc": "The time interval for checking and clearing expired retained messages. This can prevent expired retained messages from being stored for a long time.\n\nIf `msg_clear_interval` is set to 0, that is, expired retained messages are not actively checked regularly, EMQX will only check and delete expired retained messages when preparing for delivery."
    },
    "msg_expiry_interval": {
      "desc": "Expired retained messages will not be delivered again, and a setting of 0 means that retained messages will never expire.\n\nHowever, if the `Message-Expiry-Interval` property is specified in the MQTT message, the value of that property prevails."
    },
    "stop_publish_clear_msg": {
      "desc": "When the retained flag of the `PUBLISH` message is set and Payload is empty,\nwhether to continue to publish the message.\nSee:\nhttp://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718038"
    }
  },
  "emqx_rewrite_api": {
    "list_topic_rewrite_api": {
      "desc": "List all rewrite rules",
      "label": "List all rewrite rules"
    },
    "update_topic_rewrite_api": {
      "desc": "Update all rewrite rules",
      "label": "Update all rewrite rules"
    },
    "update_topic_rewrite_api_response400": {
      "desc": "Bad request",
      "label": "Bad request"
    },
    "update_topic_rewrite_api_response413": {
      "desc": "Rules count exceed max limit",
      "label": "Rules count exceed limit"
    }
  },
  "emqx_rule_api_schema": {
    "event_action": {
      "desc": "Publish or Subscribe",
      "label": "Publish or Subscribe"
    },
    "event_authz_source": {
      "desc": "Cache, Plugs or Default",
      "label": "Auth Source"
    },
    "event_clean_start": {
      "desc": "Clean Start",
      "label": "Clean Start"
    },
    "event_clientid": {
      "desc": "The Client ID",
      "label": "Client ID"
    },
    "event_connected_at": {
      "desc": "The Time that this Client is Connected",
      "label": "Connected Time"
    },
    "event_ctx_authn_reason_code": {
      "desc": "The reason code"
    },
    "event_ctx_connack_reason_code": {
      "desc": "The reason code",
      "label": "Reason Code"
    },
    "event_ctx_disconnected_da": {
      "desc": "The Time that this Client is Disconnected",
      "label": "Disconnected Time"
    },
    "event_ctx_disconnected_reason": {
      "desc": "The Reason for Disconnect",
      "label": "Disconnect Reason"
    },
    "event_ctx_dropped": {
      "desc": "The Reason for Dropping",
      "label": "Dropped Reason"
    },
    "event_dup": {
      "desc": "The DUP flag of the MQTT message",
      "label": "DUP Flag"
    },
    "event_event_type": {
      "desc": "Event Type",
      "label": "Event Type"
    },
    "event_expiry_interval": {
      "desc": "Expiry Interval",
      "label": "Expiry Interval"
    },
    "event_from_clientid": {
      "desc": "The Client ID",
      "label": "Client ID"
    },
    "event_from_username": {
      "desc": "The User Name",
      "label": "Username"
    },
    "event_id": {
      "desc": "Message ID",
      "label": "Message ID"
    },
    "event_is_anonymous": {
      "desc": "True if this user is anonymous."
    },
    "event_is_bridge": {
      "desc": "Is Bridge",
      "label": "Is Bridge"
    },
    "event_is_superuser": {
      "desc": "True if this is a super user."
    },
    "event_keepalive": {
      "desc": "KeepAlive",
      "label": "KeepAlive"
    },
    "event_mountpoint": {
      "desc": "The Mountpoint",
      "label": "Mountpoint"
    },
    "event_payload": {
      "desc": "The Message Payload",
      "label": "Message Payload"
    },
    "event_peerhost": {
      "desc": "The IP Address of the Peer Client",
      "label": "Peer IP Address"
    },
    "event_peername": {
      "desc": "The IP Address and Port of the Peer Client",
      "label": "IP Address And Port"
    },
    "event_proto_name": {
      "desc": "Protocol Name",
      "label": "Protocol Name"
    },
    "event_proto_ver": {
      "desc": "Protocol Version",
      "label": "Protocol Version"
    },
    "event_publish_received_at": {
      "desc": "The Time that this Message is Received",
      "label": "Message Received Time"
    },
    "event_qos": {
      "desc": "The Message QoS",
      "label": "Message QoS"
    },
    "event_result": {
      "desc": "Allow or Deny",
      "label": "Auth Result"
    },
    "event_retain": {
      "desc": "If is a retain message",
      "label": "Retain Message"
    },
    "event_server": {
      "desc": "The IP address (or hostname) and port of the MQTT broker, in IP:Port format",
      "label": "Server IP And Port"
    },
    "event_sockname": {
      "desc": "The IP Address and Port of the Local Listener",
      "label": "IP Address And Port"
    },
    "event_topic": {
      "desc": "Message Topic",
      "label": "Message Topic"
    },
    "event_transformation": {
      "desc": "Transformation",
      "label": "Transformation"
    },
    "event_username": {
      "desc": "Username",
      "label": "Username"
    },
    "event_validation": {
      "desc": "Validation",
      "label": "Validation"
    },
    "metrics_actions_failed": {
      "desc": "How many times the rule failed to call the actions.",
      "label": "Failed Action"
    },
    "metrics_actions_failed_out_of_service": {
      "desc": "How many times the rule has failed to call actions due to the action is out of service. For example, a bridge is disabled or stopped.",
      "label": "Fail Action"
    },
    "metrics_actions_failed_unknown": {
      "desc": "The number of action failures that have occurred due to unanticipated reasons. For more information on these errors, please refer to the EMQX log file.",
      "label": "Unknown Failures"
    },
    "metrics_actions_success": {
      "desc": "How many times the rule successided to call the actions.",
      "label": "Success Action"
    },
    "metrics_actions_total": {
      "desc": "How many times the actions are called by the rule. This value may several times of 'matched', depending on the number of the actions of the rule.",
      "label": "Action Total"
    },
    "metrics_sql_failed": {
      "desc": "How many times the SQL statement has failed",
      "label": "SQL Failed"
    },
    "metrics_sql_failed_exception": {
      "desc": "How many times the SQL is failed due to exceptions. This may because of a crash when calling a SQL function, or trying to do arithmetic operation on undefined variables",
      "label": "SQL Exception"
    },
    "metrics_sql_failed_unknown": {
      "desc": "How many times the SQL is failed due to an unknown error.",
      "label": "SQL Unknown Error"
    },
    "metrics_sql_matched": {
      "desc": "How many times the FROM clause of the SQL is matched.",
      "label": "Matched"
    },
    "metrics_sql_matched_rate": {
      "desc": "The rate of matched, times/second",
      "label": ""
    },
    "metrics_sql_matched_rate_last5m": {
      "desc": "The average rate of matched in last 5 minutes, times/second",
      "label": "Average Matched Rate"
    },
    "metrics_sql_matched_rate_max": {
      "desc": "The max rate of matched, times/second",
      "label": "Max Matched Rate"
    },
    "metrics_sql_passed": {
      "desc": "How many times the SQL is passed",
      "label": "SQL Passed"
    },
    "node_node": {
      "desc": "The node name",
      "label": "Node Name"
    },
    "ri_created_at": {
      "desc": "The created time of the rule",
      "label": "Rule Create Time"
    },
    "ri_from": {
      "desc": "The topics of the rule",
      "label": "Topics of Rule"
    },
    "ri_metrics": {
      "desc": "The metrics of the rule",
      "label": "Rule Metrics"
    },
    "ri_node_metrics": {
      "desc": "The metrics of the rule for each node",
      "label": "Each Node Rule Metrics"
    },
    "root_rule_creation": {
      "desc": "Schema for creating rules",
      "label": "Create Schema"
    },
    "root_rule_engine": {
      "desc": "Rule engine configurations. This API can be used to change EMQX rule engine settings. But not for the rules. To list, create, or update rules, call the '/rules' API instead.",
      "label": "Rule engine configuration"
    },
    "root_rule_events": {
      "desc": "Schema for rule events",
      "label": "Rule Events Schema"
    },
    "root_rule_info": {
      "desc": "Schema for rule info",
      "label": "Info Schema"
    },
    "root_rule_test": {
      "desc": "Schema for testing rules",
      "label": "Rule Test Schema"
    },
    "rs_columns": {
      "desc": "The columns",
      "label": "Column"
    },
    "rs_description": {
      "desc": "The description",
      "label": "Description"
    },
    "rs_event": {
      "desc": "The event topics",
      "label": "Event Topics"
    },
    "rs_sql_example": {
      "desc": "The sql_example",
      "label": "SQL Example"
    },
    "rs_test_columns": {
      "desc": "The test columns",
      "label": "Test Columns"
    },
    "rs_title": {
      "desc": "The title",
      "label": "Title"
    },
    "rule_id": {
      "desc": "The ID of the rule",
      "label": "Rule ID"
    },
    "stop_action_after_template_render": {
      "desc": "Set this to true if the action should be stopped after its template has been rendered (default is true).",
      "label": "Stop Action After Template Rendering"
    },
    "test_context": {
      "desc": "The context of the event for testing",
      "label": "Event Conetxt"
    },
    "test_sql": {
      "desc": "The SQL of the rule for testing",
      "label": "Test SQL"
    }
  },
  "emqx_rule_engine_api": {
    "api1": {
      "desc": "List all rules",
      "label": "List All Rules"
    },
    "api10": {
      "desc": "Update rule engine configuration.",
      "label": "Update configuration"
    },
    "api11": {
      "desc": "Apply a rule with the given message and environment",
      "label": "Apply Rule"
    },
    "api1_enable": {
      "desc": "Filter enable/disable rules"
    },
    "api1_from": {
      "desc": "Filter rules by from(topic), exact match"
    },
    "api1_like_description": {
      "desc": "Filter rules by description, Substring matching"
    },
    "api1_like_from": {
      "desc": "Filter rules by from(topic), Substring matching"
    },
    "api1_like_id": {
      "desc": "Filter rules by id, Substring matching"
    },
    "api1_match_from": {
      "desc": "Filter rules by from(topic), Mqtt topic matching"
    },
    "api1_qs_action": {
      "desc": "Filters rules that contain any of the given action id(s).  When used in conjunction with source id filtering, the rules must contain sources *and* actions that match some of the criteria."
    },
    "api1_qs_source": {
      "desc": "Filters rules that contain any of the given source id(s).  When used in conjunction with action id filtering, the rules must contain sources *and* actions that match some of the criteria."
    },
    "api1_resp": {
      "desc": "List of rules",
      "label": "List Rules"
    },
    "api2": {
      "desc": "Create a new rule using given Id",
      "label": "Create Rule By ID"
    },
    "api3": {
      "desc": "List all events can be used in rules",
      "label": "List All Events Can Be Used In Rule"
    },
    "api4": {
      "desc": "Get a rule by given Id",
      "label": "Get Rule"
    },
    "api4_1": {
      "desc": "Get a rule's metrics by given Id",
      "label": "Get Metric"
    },
    "api5": {
      "desc": "Update a rule by given Id to all nodes in the cluster",
      "label": "Update Cluster Rule"
    },
    "api6": {
      "desc": "Delete a rule by given Id from all nodes in the cluster",
      "label": "Delete Cluster Rule"
    },
    "api7": {
      "desc": "Reset a rule metrics",
      "label": "Reset Rule Metrics"
    },
    "api8": {
      "desc": "Test a rule",
      "label": "Test Rule"
    },
    "api9": {
      "desc": "Get rule engine configuration.",
      "label": "Get configuration"
    }
  },
  "emqx_rule_engine_schema": {
    "console_function": {
      "desc": "Print the actions to the console",
      "label": "Console Function"
    },
    "desc_builtin_action_console": {
      "desc": "Configuration for a built-in action.",
      "label": "Action Console Configuration"
    },
    "desc_builtin_action_republish": {
      "desc": "Configuration for a built-in action.",
      "label": "Republish Configuration"
    },
    "desc_republish_args": {
      "desc": "The arguments of the built-in 'republish' action.One can use variables in the args.\nThe variables are selected by the rule. For example, if the rule SQL is defined as following:\n<code>\n    SELECT clientid, qos, payload FROM \"t/1\"\n</code>\nThen there are 3 variables available: <code>clientid</code>, <code>qos</code> and\n<code>payload</code>. And if we've set the args to:\n<code>\n    {\n        topic = \"t/${clientid}\"\n        qos = \"${qos}\"\n        payload = \"msg: ${payload}\"\n    }\n</code>\nWhen the rule is triggered by an MQTT message with payload = `hello`, qos = 1,\nclientid = `Steve`, the rule will republish a new MQTT message to topic `t/Steve`,\npayload = `msg: hello`, and `qos = 1`.",
      "label": "Republish Args"
    },
    "desc_rule_engine": {
      "desc": "Configuration for the EMQX Rule Engine.",
      "label": "Rule Engine Configuration"
    },
    "desc_rules": {
      "desc": "Configuration for a rule.",
      "label": "Rule Configuration"
    },
    "desc_user_provided_function": {
      "desc": "Configuration for a built-in action.",
      "label": "User Provid Function Configuration"
    },
    "republish_args_direct_dispatch": {
      "desc": "Enable direct dispatch to subscribers without initiating a new message publish event.\nWhen set to `true`, this prevents the recursive processing of a message by the same action\nand is used when the output message does not require further processing.\n\nHowever, enabling this feature has several limitations:\n\n- The output message from this action is not retained.\n- It does not trigger other rules that operate based on the output topic of this action.\n- It does not activate rules that select from the `$events/message_publish`.\n- It does not trigger plugins that use the `'message.publish'` hook.\n- Topic metrics are not collected for the output message of this action.\n- Message schema validation is not applied (feature of EMQX Enterprise).\n- Message transformation processes are not applied (feature of EMQX Enterprise).",
      "label": "Direct Dispatch"
    },
    "republish_args_mqtt_properties": {
      "desc": "From which variable should the MQTT Publish Properties of the message be taken.\nPlaceholders like <code>${.payload.content_type}</code> may be used.",
      "label": "MQTT Properties"
    },
    "republish_args_payload": {
      "desc": "The payload of the message to be re-published.\nTemplate with variables is allowed, see description of the 'republish_args'.\nDefaults to ${payload}. If variable ${payload} is not found from the selected result\nof the rule, then the string \"undefined\" is used.",
      "label": "Message Payload"
    },
    "republish_args_qos": {
      "desc": "The qos of the message to be re-published.\nTemplate with variables is allowed, see description of the 'republish_args'.\nDefaults to ${qos}. If variable ${qos} is not found from the selected result of the rule,\n0 is used.",
      "label": "Message QoS"
    },
    "republish_args_retain": {
      "desc": "The 'retain' flag of the message to be re-published.\nTemplate with variables is allowed, see description of the 'republish_args'.\nDefaults to ${retain}. If variable ${retain} is not found from the selected result\nof the rule, false is used.",
      "label": "Retain Flag"
    },
    "republish_args_topic": {
      "desc": "The target topic of message to be re-published.\nTemplate with variables is allowed, see description of the 'republish_args'.",
      "label": "Target Topic"
    },
    "republish_args_user_properties": {
      "desc": "From which variable should the MQTT message's User-Property pairs be taken from.\nThe value must be a map.\nYou may configure it to <code>${pub_props.'User-Property'}</code> or\nuse <code>SELECT *,pub_props.'User-Property' as user_properties</code>\nto forward the original user properties to the republished message.\nYou may also call <code>map_put</code> function like\n<code>map_put('my-prop-name', 'my-prop-value', user_properties) as user_properties</code>\nto inject user properties.\nNOTE: MQTT spec allows duplicated user property names, but EMQX Rule-Engine does not.",
      "label": "User Properties"
    },
    "republish_function": {
      "desc": "Republish the message as a new MQTT message",
      "label": "Republish Function"
    },
    "rule_engine_ignore_sys_message": {
      "desc": "When set to 'true' (default), rule-engine will ignore messages published to $SYS topics.",
      "label": "Ignore Sys Message"
    },
    "rule_engine_jq_function_default_timeout": {
      "desc": "Default timeout for the `jq` rule engine function",
      "label": "Rule engine jq function default timeout"
    },
    "rule_engine_jq_implementation_module": {
      "desc": "The implementation module for the jq rule engine function. The two options are jq_nif and jq_port. With the jq_nif option an Erlang NIF library is used while with the jq_port option an implementation based on Erlang port programs is used. The jq_nif option (the default option) is the fastest implementation of the two but jq_port is safer as the jq programs will not execute in the same process as the Erlang VM.",
      "label": "JQ Implementation Module"
    },
    "rule_engine_rules": {
      "desc": "The rules",
      "label": "Rules"
    },
    "rules_actions": {
      "desc": "A list of actions of the rule.\nAn action can be a string that refers to the channel ID of an EMQX bridge, or an object\nthat refers to a function.\nThere a some built-in functions like \"republish\" and \"console\", and we also support user\nprovided functions in the format: \"{module}:{function}\".\nThe actions in the list are executed sequentially.\nThis means that if one of the action is executing slowly, all the following actions will not\nbe executed until it returns.\nIf one of the action crashed, all other actions come after it will still be executed, in the\noriginal order.\nIf there's any error when running an action, there will be an error message, and the 'failure'\ncounter of the function action or the bridge channel will increase.",
      "label": "Rule Action List"
    },
    "rules_description": {
      "desc": "The description of the rule",
      "label": "Rule Description"
    },
    "rules_enable": {
      "desc": "Enable or disable the rule",
      "label": "Enable Or Disable Rule"
    },
    "rules_metadata": {
      "desc": "Rule metadata, do not change manually",
      "label": "Rule metadata"
    },
    "rules_name": {
      "desc": "The name of the rule",
      "label": "Rule Name"
    },
    "rules_sql": {
      "desc": "SQL query to transform the messages.\nExample: <code>SELECT * FROM \"test/topic\" WHERE payload.x = 1</code>",
      "label": "Rule SQL"
    },
    "user_provided_function_args": {
      "desc": "The args will be passed as the 3rd argument to module:function/3,\ncheckout the function <code>console</code> and <code>republish</code> in the source file:\n<code>apps/emqx_rule_engine/src/emqx_rule_actions.erl</code> as an example.",
      "label": "User Provided Function Args"
    },
    "user_provided_function_function": {
      "desc": "The user provided function. Should be in the format: '{module}:{function}'.\nWhere {module} is the Erlang callback module and {function} is the Erlang function.\n\nTo write your own function, checkout the function <code>console</code> and\n<code>republish</code> in the source file:\n<code>apps/emqx_rule_engine/src/emqx_rule_actions.erl</code> as an example.",
      "label": "User Provided Function"
    }
  },
  "emqx_s3_schema": {
    "access_key_id": {
      "desc": "The access key ID of the S3 bucket."
    },
    "acl": {
      "desc": "The ACL to use for the uploaded objects."
    },
    "bucket": {
      "desc": "The name of the S3 bucket.",
      "label": "Bucket"
    },
    "host": {
      "desc": "The host of the S3 endpoint."
    },
    "ipv6_probe": {
      "desc": "Whether to probe for IPv6 support."
    },
    "key": {
      "desc": "Key of the S3 object.",
      "label": "Object Key"
    },
    "max_part_size": {
      "desc": "The maximum part size for multipart uploads.<br/>\nS3 uploader won't try to upload parts larger than this size."
    },
    "min_part_size": {
      "desc": "The minimum part size for multipart uploads.<br/>\nUploaded data will be accumulated in memory until this size is reached."
    },
    "port": {
      "desc": "The port of the S3 endpoint."
    },
    "secret_access_key": {
      "desc": "The secret access key of the S3 bucket."
    },
    "transport_options": {
      "desc": "Options for the HTTP transport layer used by the S3 client."
    },
    "upload_headers": {
      "desc": "HTTP headers to include in the S3 object upload request.<br/>\nUseful to specify content type, content encoding, etc. of the S3 object.",
      "label": "S3 object HTTP headers"
    },
    "url_expire_time": {
      "desc": "The time in seconds for which the signed URLs to the S3 objects are valid."
    }
  },
  "emqx_schema": {
    "alarm_actions": {
      "desc": "The actions triggered when the alarm is activated.<br/>Currently, the following actions are supported: <code>log</code> and <code>publish</code>.\n<code>log</code> is to write the alarm to log (console or file).\n<code>publish</code> is to publish the alarm as an MQTT message to the system topics:\n<code>$SYS/brokers/emqx@xx.xx.xx.x/alarms/activate</code> and\n<code>$SYS/brokers/emqx@xx.xx.xx.x/alarms/deactivate</code>",
      "label": "Alarm Actions"
    },
    "alarm_size_limit": {
      "desc": "The maximum number of historical alarms that can be stored.\n\nWhen the maximum number is reached, the oldest historical alarms will be deleted to store new historical alarms.",
      "label": "Alarm size limit"
    },
    "alarm_validity_period": {
      "desc": "The validity period of historical alarms. Calculated from the time of activation of the historical alarm instead of the time of cancelation.\n\nIf it exists longer than the validity period, the alarm will be deleted.",
      "label": "Alarm validity period"
    },
    "banned_bootstrap_file": {
      "desc": "The bootstrap file is a CSV file used to batch loading banned data when initializing a single node or cluster, in other words, the import operation is performed only if there is no data in the database.\n\nThe delimiter for this file is `,`.\n\nThe first line of this file must be a header line. All valid headers are listed here:\n- as :: required\n- who :: required\n- by  :: optional\n- reason :: optional\n- at :: optional\n- until :: optional\n\nSee the documentation for details on each field.\n\nEach row in the rest of this file must contain the same number of columns as the header line,\nand column can be omitted then its value will be `undefined`."
    },
    "base_listener_acceptors": {
      "desc": "The size of the listener's receiving pool.",
      "label": "Acceptors Num"
    },
    "base_listener_bind": {
      "desc": "IP address and port for the listening socket.",
      "label": "IP address and port"
    },
    "base_listener_enable_authn": {
      "desc": "Set <code>true</code> (default) to enable client authentication on this listener, the authentication\nprocess goes through the configured authentication chain.\nWhen set to <code>false</code>, any client (with or without username/password) is allowed to connect.\nWhen set to <code>quick_deny_anonymous</code>, it behaves like when set to <code>true</code>, but clients will be\ndenied immediately without going through any authenticators if <code>username</code> is not provided. This is useful to fence off\nanonymous clients early.",
      "label": "Enable authentication"
    },
    "base_listener_limiter": {
      "desc": "Type of the rate limit.",
      "label": "Type of the rate limit."
    },
    "base_listener_max_connections": {
      "desc": "The maximum number of concurrent connections allowed by the listener.",
      "label": "Max connections"
    },
    "base_listener_mountpoint": {
      "desc": "When publishing or subscribing, prefix all topics with a mountpoint string.\nThe prefixed string will be removed from the topic name when the message\nis delivered to the subscriber. The mountpoint is a way that users can use\nto implement isolation of message routing between different listeners.\nFor example if a client A subscribes to `t` with `listeners.tcp.\\<name>.mountpoint`\nset to `some_tenant`, then the client actually subscribes to the topic\n`some_tenant/t`. Similarly, if another client B (connected to the same listener\nas the client A) sends a message to topic `t`, the message is routed\nto all the clients subscribed `some_tenant/t`, so client A will receive the\nmessage, with topic name `t`.<br/>\nSet to `\"\"` to disable the feature.<br/>\n\nVariables in mountpoint string:\n  - <code>${clientid}</code>: clientid\n  - <code>${username}</code>: username",
      "label": "mountpoint"
    },
    "base_listener_zone": {
      "desc": "The configuration zone to which the listener belongs.\nClients connected to this listener will inherit zone-settings created under this zone name.\n\nA zone can override the configs under below root names:\n- `mqtt`\n- `force_shutdown`\n- `force_gc`\n- `flapping_detect`\n- `durable_sessions`",
      "label": "Zone"
    },
    "broker": {
      "desc": "Message broker options."
    },
    "broker_enable_session_registry": {
      "desc": "The Global Session Registry is a cluster-wide mechanism designed to maintain the uniqueness of client IDs within the cluster.\nRecommendations for Use<br/>\n- Default Setting: It is generally advisable to enable. This feature is crucial for session takeover to work properly. For example if a client reconnected to another node in the cluster, the new connection will need to find the old session and take it over.\n- Disabling the Feature: Disabling is an option for scenarios when all sessions expire immediately after client is disconnected (i.e. session expiry interval is zero). This can be relevant in certain specialized use cases.\n\nAdvantages of Disabling<br/>\n- Reduced Memory Usage: Turning off the session registry can lower the overall memory footprint of the system.\n- Improved Performance: Without the overhead of maintaining a global registry, the node can process client connections faster."
    },
    "broker_perf_route_lock_type": {
      "desc": "Performance tuning for subscribing/unsubscribing a wildcard topic.\nChange this parameter only when there are many wildcard topics.\n\nNOTE: when changing from/to `global` lock, it requires all nodes in the cluster to be stopped before the change.\n  - `key`: mnesia transactional updates with per-key locks. Recommended for a single-node setup.\n  - `tab`: mnesia transactional updates with table lock. Recommended for a cluster setup.\n  - `global`: updates are protected with a global lock. Recommended for large clusters."
    },
    "broker_perf_trie_compaction": {
      "desc": "Enable trie path compaction.\nEnabling it significantly improves wildcard topic subscribe rate, if wildcard topics have unique prefixes like: 'sensor/{{id}}/+/', where ID is unique per subscriber.\nTopic match performance (when publishing) may degrade if messages are mostly published to topics with large number of levels.\n\nNOTE: This is a cluster-wide configuration. It requires all nodes to be stopped before changing it."
    },
    "broker_routing_batch_sync_enable_on": {
      "desc": "Use separate process pool to synchronize subscriptions with the global routing table in a batched manner.\nEspecially useful in clusters interconnected through links with non-negligible latency, but might help in other scenarios by ensuring that the broker pool has less chance being overloaded.\nThe selected value determines which nodes in the cluster will have this feature enabled.\n- <code>all</code>: enables it unconditionally on each node,\n- <code>replicant</code>: enables it only on replicants (e.g. those where <code>node.role = replicant</code>),\n- <code>core</code>: enables it only on core nodes,\n- <code>none</code>: disables this altogether."
    },
    "broker_routing_storage_schema": {
      "desc": "Routing storage schema.\nSet <code>v1</code> to use the former schema.\n<code>v2</code> is introduced in 5.2. It enables routing through 2 separate tables, one for topic filter and one for regular topic subscriptions. This schema should increase both subscription and routing performance at the cost of slight increase in memory consumption per subscription.\nNOTE: Schema <code>v2</code> is still experimental.\nNOTE: Full non-rolling cluster restart is needed after altering this option for it to take any effect."
    },
    "broker_session_history_retain": {
      "desc": "The duration to retain the session registration history. Setting this to a value greater than `0s` will increase memory usage and impact peformance.\nThis retained history can be used to monitor how many sessions were registered in the past configured duration.\nNote: This config has no effect if `enable_session_registry` is set to `false`.<br/>\nNote: If the clients are using random client IDs, it's not recommended to enable this feature, at least not for a long retention period.<br/>\nNote: When clustered, the lowest (but greater than `0s`) value among the nodes in the cluster will take effect."
    },
    "broker_session_locking_strategy": {
      "desc": "Session locking strategy in a cluster.\n  - `local`: only lock the session on the current node\n  - `one`: select only one remote node to lock the session\n  - `quorum`: select some nodes to lock the session\n  - `all`: lock the session on all the nodes in the cluster"
    },
    "broker_shared_dispatch_ack_enabled": {
      "desc": "Deprecated.\nThis was designed to avoid dispatching messages to a shared-subscription session which has the client disconnected.\nHowever it's no longer useful because the shared-subscrption messages in a expired session will be redispatched to other sessions in the group."
    },
    "ciphers_schema_common": {
      "desc": "This config holds TLS cipher suite names separated by comma,\nor as an array of strings. e.g.\n<code>\"TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256\"</code> or\n<code>[\"TLS_AES_256_GCM_SHA384\",\"TLS_AES_128_GCM_SHA256\"]</code>.\n<br/>\nCiphers (and their ordering) define the way in which the\nclient and server encrypts information over the network connection.\nSelecting a good cipher suite is critical for the\napplication's data security, confidentiality and performance.\n\nThe names should be in OpenSSL string format (not RFC format).\nAll default values and examples provided by EMQX config\ndocumentation are all in OpenSSL format.<br/>\n\nNOTE: Certain cipher suites are only compatible with\nspecific TLS <code>versions</code> ('tlsv1.1', 'tlsv1.2' or 'tlsv1.3')\nincompatible cipher suites will be silently dropped.\nFor instance, if only 'tlsv1.3' is given in the <code>versions</code>,\nconfiguring cipher suites for other versions will have no effect.\n<br/>\n\nNOTE: PSK ciphers are suppressed by 'tlsv1.3' version config<br/>\nIf PSK cipher suites are intended, 'tlsv1.3' should be disabled from <code>versions</code>.<br/>\nPSK cipher suites: <code>\"RSA-PSK-AES256-GCM-SHA384,RSA-PSK-AES256-CBC-SHA384,\nRSA-PSK-AES128-GCM-SHA256,RSA-PSK-AES128-CBC-SHA256,\nRSA-PSK-AES256-CBC-SHA,RSA-PSK-AES128-CBC-SHA,\nRSA-PSK-DES-CBC3-SHA,RSA-PSK-RC4-SHA\"</code>",
      "label": "TLS cipher suites"
    },
    "ciphers_schema_quic": {
      "desc": "This config holds TLS cipher suite names separated by comma,\nor as an array of strings. e.g.\n<code>\"TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256\"</code> or\n<code>[\"TLS_AES_256_GCM_SHA384\",\"TLS_AES_128_GCM_SHA256\"]</code>.\n<br/>\nCiphers (and their ordering) define the way in which the\nclient and server encrypts information over the network connection.\nSelecting a good cipher suite is critical for the\napplication's data security, confidentiality and performance.\n\nThe names should be in OpenSSL string format (not RFC format).\nAll default values and examples provided by EMQX config\ndocumentation are all in OpenSSL format.<br/>\n\nNOTE: Certain cipher suites are only compatible with\nspecific TLS <code>versions</code> ('tlsv1.1', 'tlsv1.2' or 'tlsv1.3')\nincompatible cipher suites will be silently dropped.\nFor instance, if only 'tlsv1.3' is given in the <code>versions</code>,\nconfiguring cipher suites for other versions will have no effect.\n<br/>\n\nNOTE: PSK ciphers are suppressed by 'tlsv1.3' version config<br/>\nIf PSK cipher suites are intended, 'tlsv1.3' should be disabled from <code>versions</code>.<br/>\nPSK cipher suites: <code>\"RSA-PSK-AES256-GCM-SHA384,RSA-PSK-AES256-CBC-SHA384,\nRSA-PSK-AES128-GCM-SHA256,RSA-PSK-AES128-CBC-SHA256,\nRSA-PSK-AES256-CBC-SHA,RSA-PSK-AES128-CBC-SHA,\nRSA-PSK-DES-CBC3-SHA,RSA-PSK-RC4-SHA\"</code><br/>\n\nNOTE: QUIC listener supports only 'tlsv1.3' ciphers",
      "label": "QUIC TLS cipher suites"
    },
    "client_attrs_init": {
      "desc": "Specify how to initialize client attributes.\nEach client attribute can be initialized as `client_attrs.{NAME}`,\nwhere `{NAME}` is the name of the attribute specified in the config field `set_as_attr`.\nThe initialized client attribute will be stored in the `client_attrs` property with the specified name,\nand can be used as a placeholder in a template for authentication and authorization.\nFor example, use `${client_attrs.alias}` to render an HTTP POST body when `set_as_attr = alias`,\nor render listener config `moutpoint = devices/${client_attrs.alias}/` to initialize a per-client topic namespace.",
      "label": "Client Attributes Initialization"
    },
    "client_attrs_init_expression": {
      "desc": "A one line expression to evaluate a set of predefined string functions (like in the rule engine SQL statements).\nThe expression can be a function call with nested calls as its arguments, or direct variable reference.\nSo far, it does not provide user-defined variable binding (like `var a=1`) or user-defined functions.\nAs an example, to extract the prefix of client ID delimited by a dot: `nth(1, tokens(clientid, '.'))`.\n\nThe variables pre-bound variables are:\n- `cn`: Client's TLS certificate common name.\n- `dn`: Client's TLS certificate distinguished name (the subject).\n- `clientid`: MQTT Client ID.\n- `username`: MQTT Client's username.\n- `user_property.{NAME}`: User properties in the CONNECT packet.\n\nYou can read more about variform expressions in EMQX docs.",
      "label": "Client Attribute Extraction Regular Expression"
    },
    "client_attrs_init_set_as_attr": {
      "desc": "The name of the client attribute extracted from the client data.\nThe extracted attribute will be stored in the `client_attrs` property with this name.",
      "label": "Name The Extracted Attribute"
    },
    "client_ssl_opts_schema_enable": {
      "desc": "Enable TLS.",
      "label": "Enable TLS."
    },
    "client_ssl_opts_schema_server_name_indication": {
      "desc": "Specify the host name to be used in TLS Server Name Indication extension.<br/>\nFor instance, when connecting to \"server.example.net\", the genuine server\nwhich accepts the connection and performs TLS handshake may differ from the\nhost the TLS client initially connects to, e.g. when connecting to an IP address\nor when the host has multiple resolvable DNS records <br/>\nIf not specified, it will default to the host name string which is used\nto establish the connection, unless it is IP address used.<br/>\nThe host name is then also used in the host name verification of the peer\ncertificate.<br/> The special value 'disable' prevents the Server Name\nIndication extension from being sent and disables the hostname\nverification check.",
      "label": "Server Name Indication"
    },
    "common_ssl_opts_schema_cacertfile": {
      "desc": "Trusted PEM format CA certificates bundle file.<br/>\nThe certificates in this file are used to verify the TLS peer's certificates.\nAppend new certificates to the file if new CAs are to be trusted.\nThere is no need to restart EMQX to have the updated file loaded, because\nthe system regularly checks if file has been updated (and reload).<br/>\nNOTE: invalidating (deleting) a certificate from the file will not affect\nalready established connections.",
      "label": "CACertfile"
    },
    "common_ssl_opts_schema_cacerts": {
      "desc": "When enabled, uses the system trusted CA certificates for establishing to TLS connections.",
      "label": "Use System CA Certificates"
    },
    "common_ssl_opts_schema_certfile": {
      "desc": "PEM format certificates chain file.<br/>\nThe certificates in this file should be in reversed order of the certificate\nissue chain. That is, the host's certificate should be placed in the beginning\nof the file, followed by the immediate issuer certificate and so on.\nAlthough the root CA certificate is optional, it should be placed at the end of\nthe file if it is to be added.",
      "label": "Certfile"
    },
    "common_ssl_opts_schema_depth": {
      "desc": "Maximum number of non-self-issued intermediate certificates that can follow the peer certificate in a valid certification path.\nSo, if depth is 0 the PEER must be signed by the trusted ROOT-CA directly;<br/>\nif 1 the path can be PEER, Intermediate-CA, ROOT-CA;<br/>\nif 2 the path can be PEER, Intermediate-CA1, Intermediate-CA2, ROOT-CA.",
      "label": "CACert Depth"
    },
    "common_ssl_opts_schema_hibernate_after": {
      "desc": "Specifies the amount of time that an SSL process will hibernate after being idle, thus reducing its memory footprint.\n\nThe hibernating process will be woken up when a new message arrives.\nHibernating and waking up too often can cause CPU utilization to increase, as they both perform garbage collection on the process.",
      "label": "Hibernate After"
    },
    "common_ssl_opts_schema_keyfile": {
      "desc": "PEM format private key file.",
      "label": "Keyfile"
    },
    "common_ssl_opts_schema_log_level": {
      "desc": "The minimum level of logging allowed for SSL output.\n\nThe default is `notice`, set to a lower `debug` level for more detailed logging that can be used to investigate SSL handshake issues.",
      "label": "SSL Log Level"
    },
    "common_ssl_opts_schema_password": {
      "desc": "String containing the user's password. Only used if the private key file is password-protected.",
      "label": "Keyfile Passphrase"
    },
    "common_ssl_opts_schema_reuse_sessions": {
      "desc": "Enable TLS session reuse.<br/>\nHas no effect when TLS version is configured (or negotiated) to 1.3",
      "label": "TLS Session Reuse"
    },
    "common_ssl_opts_schema_secure_renegotiate": {
      "desc": "Whether to reject TLS renegotiation attempts that are not compliant with [RFC 5746](http://www.ietf.org/rfc/rfc5746.txt).\n\nBy default, `secure_renegotiate` is set to `true`, which forces secure renegotiation.\nIf set to `false`, secure renegotiation will still be used, but will fall back to insecure renegotiation if the peer does not support [RFC 5746](http://www.ietf.org/rfc/rfc5746.txt), which increases the risk of a MitM attack.\n\nHas no effect when TLS version is configured (or negotiated) to 1.3.",
      "label": "SSL Secure Renegotiation"
    },
    "common_ssl_opts_schema_user_lookup_fun": {
      "desc": "EMQX-internal callback that is used to lookup pre-shared key (PSK) identity.<br/>\nHas no effect when TLS version is configured (or negotiated) to 1.3",
      "label": "SSL PSK user lookup fun"
    },
    "common_ssl_opts_schema_verify": {
      "desc": "Enable or disable peer verification.",
      "label": "Verify peer"
    },
    "common_ssl_opts_schema_versions": {
      "desc": "All TLS/DTLS versions to be supported.<br/>\nNOTE: PSK ciphers are suppressed by 'tlsv1.3' version config.<br/>\nIn case PSK cipher suites are intended, make sure to configure\n<code>['tlsv1.2', 'tlsv1.1']</code> here.",
      "label": "SSL versions"
    },
    "conn_congestion_enable_alarm": {
      "desc": "Enable or disable connection congestion alarm.",
      "label": "Enable/disable congestion alarm"
    },
    "conn_congestion_min_alarm_sustain_duration": {
      "desc": "Minimal time before clearing the alarm.<br/>The alarm is cleared only when there's no pending data in<br/>the queue, and at least <code>min_alarm_sustain_duration</code>milliseconds passed since the last time we considered the connection 'congested'.<br/>This is to avoid clearing and raising the alarm again too often.",
      "label": "Sustain duration"
    },
    "crl_cache_capacity": {
      "desc": "The maximum number of CRL URLs that can be held in cache.  If the cache is at full capacity and a new URL must be fetched, then it'll evict the oldest inserted URL in the cache.",
      "label": "CRL Cache Capacity"
    },
    "crl_cache_refresh_http_timeout": {
      "desc": "The timeout for the HTTP request when fetching CRLs.  This is a global setting for all listeners.",
      "label": "CRL Cache Refresh HTTP Timeout"
    },
    "crl_cache_refresh_interval": {
      "desc": "The period to refresh the CRLs from the servers.  This is a global setting for all URLs and listeners.",
      "label": "CRL Cache Refresh Interval"
    },
    "description": {
      "desc": "Descriptive text.",
      "label": "Description"
    },
    "durable_sessions_enable": {
      "desc": "Use durable storage for client sessions persistence.\nIf enabled, sessions configured to outlive client connections, along with their corresponding messages, will be durably stored and survive broker downtime.\n\n:::warning\nThis feature is currently experimental. Please don't enable it in the production environments that contain valuable data.\n:::",
      "label": "Enable session persistence"
    },
    "durable_storage": {
      "desc": "Configuration related to the EMQX durable storages.\n\nEMQX uses durable storages to offload various data, such as MQTT messages, to disc.",
      "label": "Durable storage"
    },
    "fields_authorization_deny_action": {
      "desc": "The action when the authorization check rejects an operation.",
      "label": "Authorization deny action"
    },
    "fields_authorization_no_match": {
      "desc": "Default access control action if the user or client matches no ACL rules,\nor if no such user or client is found by the configurable authorization\nsources such as built_in_database, an HTTP API, or a query against PostgreSQL.\nFind more details in 'authorization.sources' config.",
      "label": "Authorization no match"
    },
    "fields_authz_cache_excludes": {
      "desc": "Exclude caching ACL check results for topics matching the given patterns.",
      "label": "Excludes"
    },
    "fields_cache_enable": {
      "desc": "Enable or disable the authorization cache.",
      "label": "Enable or disable the authorization cache."
    },
    "fields_cache_max_size": {
      "desc": "Maximum number of cached items.",
      "label": "Maximum number of cached items."
    },
    "fields_cache_ttl": {
      "desc": "Time to live for the cached data.",
      "label": "Time to live for the cached data."
    },
    "fields_deflate_opts_client_context_takeover": {
      "desc": "Takeover means the compression state is retained between client messages.",
      "label": "Client context takeover"
    },
    "fields_deflate_opts_client_max_window_bits": {
      "desc": "Specifies the size of the compression context for the client.",
      "label": "Client compression max window size"
    },
    "fields_deflate_opts_level": {
      "desc": "Compression level.",
      "label": "Compression level"
    },
    "fields_deflate_opts_mem_level": {
      "desc": "Specifies the size of the compression state.<br/>\nLower values decrease memory usage per connection.",
      "label": "Size of the compression state"
    },
    "fields_deflate_opts_server_context_takeover": {
      "desc": "Takeover means the compression state is retained between server messages.",
      "label": "Server context takeover"
    },
    "fields_deflate_opts_server_max_window_bits": {
      "desc": "Specifies the size of the compression context for the server.",
      "label": "Server compression max window size"
    },
    "fields_deflate_opts_strategy": {
      "desc": "Specifies the compression strategy.",
      "label": "compression strategy"
    },
    "fields_listener_enabled": {
      "desc": "Enable listener.",
      "label": "Enable listener"
    },
    "fields_listeners_quic": {
      "desc": "QUIC listeners.",
      "label": "QUIC listeners"
    },
    "fields_listeners_ssl": {
      "desc": "SSL listeners.",
      "label": "SSL listeners"
    },
    "fields_listeners_tcp": {
      "desc": "TCP listeners.",
      "label": "TCP listeners"
    },
    "fields_listeners_ws": {
      "desc": "HTTP websocket listeners.",
      "label": "HTTP websocket listeners"
    },
    "fields_listeners_wss": {
      "desc": "HTTPS websocket listeners.",
      "label": "HTTPS websocket listeners"
    },
    "fields_mqtt_quic_listener_certfile": {
      "desc": "Path to the certificate file. Will be deprecated in 5.1, use .ssl_options.certfile instead.",
      "label": "Certificate file"
    },
    "fields_mqtt_quic_listener_conn_flow_control_window": {
      "desc": "Connection-wide flow control window. Default: 16777216",
      "label": "Conn flow control window"
    },
    "fields_mqtt_quic_listener_datagram_receive_enabled": {
      "desc": "Advertise support for QUIC datagram extension. Reserve for the future. Default 0 (FALSE)",
      "label": "Datagram receive enabled"
    },
    "fields_mqtt_quic_listener_disconnect_timeout_ms": {
      "desc": "How long to wait for an ACK before declaring a path dead and disconnecting. Default: 16000",
      "label": "Disconnect timeout ms"
    },
    "fields_mqtt_quic_listener_handshake_idle_timeout": {
      "desc": "How long a handshake can idle before it is discarded.",
      "label": "Handshake Idle Timeout"
    },
    "fields_mqtt_quic_listener_handshake_idle_timeout_ms": {
      "desc": "How long a handshake can idle before it is discarded",
      "label": "Handshake idle timeout ms"
    },
    "fields_mqtt_quic_listener_idle_timeout": {
      "desc": "How long a connection can go idle before it is gracefully shut down. 0 to disable",
      "label": "Idle Timeout"
    },
    "fields_mqtt_quic_listener_idle_timeout_ms": {
      "desc": "How long a connection can go idle before it is gracefully shut down. 0 to disable timeout",
      "label": "Idle timeout ms"
    },
    "fields_mqtt_quic_listener_initial_rtt_ms": {
      "desc": "Initial RTT estimate.",
      "label": "Initial RTT ms"
    },
    "fields_mqtt_quic_listener_initial_window_packets": {
      "desc": "The size (in packets) of the initial congestion window for a connection. Default: 10",
      "label": "Initial window packets"
    },
    "fields_mqtt_quic_listener_keep_alive_interval": {
      "desc": "How often to send PING frames to keep a connection alive. 0 means disabled.",
      "label": "Keep Alive Interval"
    },
    "fields_mqtt_quic_listener_keep_alive_interval_ms": {
      "desc": "How often to send PING frames to keep a connection alive.",
      "label": "Keep alive interval ms"
    },
    "fields_mqtt_quic_listener_keyfile": {
      "desc": "Path to the secret key file. Will be deprecated in 5.1, use .ssl_options.keyfile instead.",
      "label": "Key file"
    },
    "fields_mqtt_quic_listener_load_balancing_mode": {
      "desc": "0: Disabled, 1: SERVER_ID_IP, 2: SERVER_ID_FIXED. default: 0",
      "label": "Load balancing mode"
    },
    "fields_mqtt_quic_listener_max_ack_delay_ms": {
      "desc": "How long to wait after receiving data before sending an ACK. Default: 25",
      "label": "Max ack delay ms"
    },
    "fields_mqtt_quic_listener_max_binding_stateless_operations": {
      "desc": "The maximum number of stateless operations that may be queued on a binding at any one time. Default: 100",
      "label": "Max binding stateless operations"
    },
    "fields_mqtt_quic_listener_max_bytes_per_key": {
      "desc": "Maximum number of bytes to encrypt with a single 1-RTT encryption key before initiating key update. Default: 274877906944",
      "label": "Max bytes per key"
    },
    "fields_mqtt_quic_listener_max_operations_per_drain": {
      "desc": "The maximum number of operations to drain per connection quantum. Default: 16",
      "label": "Max operations per drain"
    },
    "fields_mqtt_quic_listener_max_stateless_operations": {
      "desc": "The maximum number of stateless operations that may be queued on a worker at any one time. Default: 16",
      "label": "Max stateless operations"
    },
    "fields_mqtt_quic_listener_maximum_mtu": {
      "desc": "The maximum MTU supported by a connection. This will be the maximum probed value. Default: 1500",
      "label": "Maximum MTU"
    },
    "fields_mqtt_quic_listener_migration_enabled": {
      "desc": "Enable clients to migrate IP addresses and tuples. Requires a cooperative load-balancer, or no load-balancer. Default: 1 (Enabled)",
      "label": "Migration enabled"
    },
    "fields_mqtt_quic_listener_minimum_mtu": {
      "desc": "The minimum MTU supported by a connection. This will be used as the starting MTU. Default: 1248",
      "label": "Minimum MTU"
    },
    "fields_mqtt_quic_listener_mtu_discovery_missing_probe_count": {
      "desc": "The maximum number of stateless operations that may be queued on a binding at any one time. Default: 3",
      "label": "MTU discovery missing probe count"
    },
    "fields_mqtt_quic_listener_mtu_discovery_search_complete_timeout_us": {
      "desc": "The time in microseconds to wait before reattempting MTU probing if max was not reached. Default: 600000000",
      "label": "MTU discovery search complete timeout us"
    },
    "fields_mqtt_quic_listener_pacing_enabled": {
      "desc": "Pace sending to avoid overfilling buffers on the path. Default: 1 (Enabled)",
      "label": "Pacing enabled"
    },
    "fields_mqtt_quic_listener_peer_bidi_stream_count": {
      "desc": "Number of bidirectional streams to allow the peer to open.",
      "label": "Peer bidi stream count"
    },
    "fields_mqtt_quic_listener_peer_unidi_stream_count": {
      "desc": "Number of unidirectional streams to allow the peer to open.",
      "label": "Peer unidi stream count"
    },
    "fields_mqtt_quic_listener_retry_memory_limit": {
      "desc": "The percentage of available memory usable for handshake connections before stateless retry is used. Calculated as `N/65535`. Default: 65",
      "label": "Retry memory limit"
    },
    "fields_mqtt_quic_listener_send_buffering_enabled": {
      "desc": "Buffer send data instead of holding application buffers until sent data is acknowledged. Default: 1 (Enabled)",
      "label": "Send buffering enabled"
    },
    "fields_mqtt_quic_listener_send_idle_timeout_ms": {
      "desc": "Reset congestion control after being idle for amount of time. Default: 1000",
      "label": "Send idle timeout ms"
    },
    "fields_mqtt_quic_listener_server_resumption_level": {
      "desc": "Controls resumption tickets and/or 0-RTT server support. Default: 0 (No resumption)",
      "label": "Server resumption level"
    },
    "fields_mqtt_quic_listener_ssl_options": {
      "desc": "TLS options for QUIC transport",
      "label": "TLS Options"
    },
    "fields_mqtt_quic_listener_stateless_operation_expiration_ms": {
      "desc": "The time limit between operations for the same endpoint, in milliseconds. Default: 100",
      "label": "Stateless operation expiration ms"
    },
    "fields_mqtt_quic_listener_stream_recv_buffer_default": {
      "desc": "Stream initial buffer size. Default: 4096",
      "label": "Stream recv buffer default"
    },
    "fields_mqtt_quic_listener_stream_recv_window_default": {
      "desc": "Initial stream receive window size. Default: 32678",
      "label": "Stream recv window default"
    },
    "fields_mqtt_quic_listener_tls_server_max_send_buffer": {
      "desc": "How much Server TLS data to buffer. Default: 8192",
      "label": "TLS server max send buffer"
    },
    "fields_rate_limit_conn_bytes_in": {
      "desc": "Limit the rate of receiving packets for a MQTT connection.\nThe rate is counted by bytes of packets per second.",
      "label": "Connection bytes in"
    },
    "fields_rate_limit_conn_messages_in": {
      "desc": "Message limit for the external MQTT connections.",
      "label": "connecting messages in"
    },
    "fields_rate_limit_max_conn_rate": {
      "desc": "Maximum connections per second.",
      "label": "Max connection rate"
    },
    "fields_tcp_opts_active_n": {
      "desc": "Specify the {active, N} option for this Socket.<br/>\nSee: https://erlang.org/doc/man/inet.html#setopts-2",
      "label": "active_n"
    },
    "fields_tcp_opts_backlog": {
      "desc": "TCP backlog defines the maximum length that the queue of\npending connections can grow to.",
      "label": "TCP backlog length"
    },
    "fields_tcp_opts_buffer": {
      "desc": "The size of the user-space buffer used by the driver.",
      "label": "TCP user-space buffer"
    },
    "fields_tcp_opts_high_watermark": {
      "desc": "When EMQX tries to send more data than the OS has allocated for the socket's send buffer, the remaining data will be temporarily stored in Erlang's internal buffer and then sent in the background.\n\nIf the amount of data queued in the internal buffer exceeds `high_watermark`, the corresponding socket will be marked as busy.\n\nThe process sending data to this busy socket will be suspended until the socket is no longer busy, or the suspension time exceeds `send_timeout`.\n\nThe socket will only be unbusy when the data in the internal buffer is below the low watermark.\n\nWhile the process is suspended, the message queue of the process may accumulate, see `max_mailbox_len` for details.",
      "label": "TCP high watermark"
    },
    "fields_tcp_opts_keepalive": {
      "desc": "Enable TCP keepalive for MQTT connections over TCP or SSL.\nThe value is three comma separated numbers in the format of 'Idle,Interval,Probes'\n - Idle: The number of seconds a connection needs to be idle before the server begins to send out keep-alive probes (Linux default 7200).\n - Interval: The number of seconds between TCP keep-alive probes (Linux default 75).\n - Probes: The maximum number of TCP keep-alive probes to send before giving up and killing the connection if no response is obtained from the other end (Linux default 9).\nFor example \"240,30,5\" means: EMQX should start sending TCP keepalive probes after the connection is in idle for 240 seconds, and the probes are sent every 30 seconds until a response is received from the MQTT client, if it misses 5 consecutive responses, EMQX should close the connection.\nDefault: 'none'",
      "label": "TCP keepalive options"
    },
    "fields_tcp_opts_nodelay": {
      "desc": "The TCP_NODELAY flag for the connections.",
      "label": "TCP_NODELAY"
    },
    "fields_tcp_opts_recbuf": {
      "desc": "The TCP receive buffer (OS kernel) for the connections.",
      "label": "TCP receive buffer"
    },
    "fields_tcp_opts_reuseaddr": {
      "desc": "The SO_REUSEADDR flag for the connections.",
      "label": "SO_REUSEADDR"
    },
    "fields_tcp_opts_send_timeout": {
      "desc": "The maximum time a process is suspended for sending data to a busy socket. After the timeout, the TCP connection and the process will be closed.\n\nThe process is unsuspended only when the socket is unbusy, that is, the data accumulated in the Erlang internal buffer drops from the high watermark (specified by `high_watermark`) to the low watermark (default 4 KB).\n\nTherefore, `(high_watermark - 4 KB) / send_timeout` must be a suitable message outflow speed, otherwise the suspended process will never be able to recover before the timeout.",
      "label": "TCP send timeout"
    },
    "fields_tcp_opts_send_timeout_close": {
      "desc": "Close the connection if send timeout.",
      "label": "TCP send timeout close"
    },
    "fields_tcp_opts_sndbuf": {
      "desc": "The TCP send buffer (OS kernel) for the connections.",
      "label": "TCP send buffer"
    },
    "fields_trace_payload_encode": {
      "desc": "Determine the format of the payload format in the trace file.<br/>\n`text`: Text-based protocol or plain text protocol.\n It is recommended when payload is JSON encoded.<br/>\n`hex`: Binary hexadecimal encode. It is recommended when payload is a custom binary protocol.<br/>\n`hidden`: payload is obfuscated as `******`",
      "label": "Payload encode"
    },
    "fields_ws_opts_allow_origin_absence": {
      "desc": "If <code>false</code> and <code>check_origin_enable</code> is\n <code>true</code>, the server will reject requests that don't have <code>origin</code>\n HTTP header.",
      "label": "Allow origin absence"
    },
    "fields_ws_opts_check_origin_enable": {
      "desc": "If <code>true</code>, <code>origin</code> HTTP header will be\n validated against the list of allowed origins configured in <code>check_origins</code>\n parameter.",
      "label": "Check origin"
    },
    "fields_ws_opts_check_origins": {
      "desc": "List of allowed origins.<br/>See <code>check_origin_enable</code>.",
      "label": "Allowed origins"
    },
    "fields_ws_opts_compress": {
      "desc": "If <code>true</code>, compress WebSocket messages using <code>zlib</code>.\n\nThe configuration items under <code>deflate_opts</code> belong to the compression-related parameter configuration.",
      "label": "Ws compress"
    },
    "fields_ws_opts_fail_if_no_subprotocol": {
      "desc": "If <code>true</code>, the server will return an error when\n the client does not carry the <code>Sec-WebSocket-Protocol</code> field.\n <br/>Note: WeChat applet needs to disable this verification.",
      "label": "Fail if no subprotocol"
    },
    "fields_ws_opts_idle_timeout": {
      "desc": "The timeout for waiting for the WebSocket upgrade request. After the timeout, the connection will be closed.",
      "label": "WebSocket Upgrade Timeout"
    },
    "fields_ws_opts_max_frame_size": {
      "desc": "The maximum length of a single MQTT packet.",
      "label": "Max frame size"
    },
    "fields_ws_opts_mqtt_path": {
      "desc": "WebSocket's MQTT protocol path. By default, the full URL for the WebSocket client to connect is:\n`ws://{host}:{port}/mqtt`.\nAppend `/[...]` to the end of the path to make EMQX accept any subpath.\nFor example, specifying `mqtt/[...]` would allow clients to connect at paths like\n`mqtt/org1` or `mqtt/group2`, etc.\n\nNOTE: An unmatched path will cause the client to be rejected immediately at the HTTP layer,\nmeaning it will not be traceable at the MQTT layer.",
      "label": "WS MQTT Path"
    },
    "fields_ws_opts_mqtt_piggyback": {
      "desc": "Whether a WebSocket message is allowed to contain multiple MQTT packets.",
      "label": "MQTT Piggyback"
    },
    "fields_ws_opts_proxy_address_header": {
      "desc": "The HTTP request header that carries the original client's IP address, EMQX will take the leftmost IP in the header as the original client's IP.\n\nThis option is typically used when EMQX is deployed behind a WebSocket proxy.",
      "label": "Proxy address header"
    },
    "fields_ws_opts_proxy_port_header": {
      "desc": "The HTTP request header that carries the original client's source port, EMQX will take the leftmost port in the header as the original client's source port.\n\nThis option is typically used when EMQX is deployed behind a WebSocket proxy.",
      "label": "Proxy port header"
    },
    "fields_ws_opts_supported_subprotocols": {
      "desc": "Comma-separated list of supported subprotocols.",
      "label": "Supported subprotocols"
    },
    "fields_ws_opts_validate_utf8": {
      "desc": "Whether to verify that the payload of `text` and `close` frames is valid UTF-8. Disabling it can save resources and improve performance.",
      "label": "Enable/Disable WebSocket Frame utf8 validation"
    },
    "flapping_detect_ban_time": {
      "desc": "How long the flapping clientid will be banned.",
      "label": "Ban time"
    },
    "flapping_detect_enable": {
      "desc": "Enable flapping connection detection feature.",
      "label": "Enable flapping detection"
    },
    "flapping_detect_max_count": {
      "desc": "The maximum number of disconnects allowed for a MQTT Client in `window_time`",
      "label": "Max count"
    },
    "flapping_detect_window_time": {
      "desc": "The time window for flapping detection.",
      "label": "Window time"
    },
    "force_gc_bytes": {
      "desc": "GC the process after specified number of bytes have passed through.",
      "label": "Process GC bytes"
    },
    "force_gc_count": {
      "desc": "GC the process after this many received messages.",
      "label": "Process GC messages num"
    },
    "force_gc_enable": {
      "desc": "Enable forced garbage collection.",
      "label": "Enable forced garbage collection"
    },
    "force_shutdown_enable": {
      "desc": "Enable `force_shutdown` feature.",
      "label": "Enable `force_shutdown` feature"
    },
    "force_shutdown_max_heap_size": {
      "desc": "The maximum heap size of the process. If the `force_shutdown` is enabled, processes that exceed this limit will automatically exit or be forcibly killed. Messages in the process message queue (mailbox) are also part of the heap. The shutdown of a process can be divided into the following two situations:\n\n- The process actively checks the current heap size during its own operation, and actively exits after finding that it exceeds the limit.\n- The underlying scheduling system checks the current heap size after performing garbage collection for the process, and forcibly kills the process after finding that it exceeds the limit.\n\nNote: The Error logs generated by the above two will be different. The log generated by the former is similar to `...errorContext: connection_shutdown, reason: #{max => 2097152, reason => proc_heap_too_large, value => 2787348}..`,\nand the log generated by the latter is similar to `...Context: maximum heap size reached...`.",
      "label": "Maximum Process Heap Size"
    },
    "force_shutdown_max_mailbox_size": {
      "desc": "EMQX creates at least one lightweight process for each client connection.\n\nEach process has its own message queue (aka mailbox) to hold messages from other processes (e.g. MQTT messages) so that the process can read messages from the message queue (mailbox) at any time.\n\nIf the system is busy or the process hangs due to a busy socket (see `high_watermark`), the message queue can accumulate many messages.\n\nTo avoid excessive memory usage, EMQX will force a process to shut down when the length of its message queue exceeds `max_mailbox_size`.",
      "label": "Maximum mailbox size."
    },
    "mqtt": {
      "desc": "Global MQTT configuration.\nThe configs here work as default values which can be overridden in <code>zone</code> configs"
    },
    "mqtt_await_rel_timeout": {
      "desc": "For client to broker QoS 2 message, the time limit for the broker to wait before the `PUBREL` message is received. The wait is aborted after timed out, meaning the packet ID is freed for new `PUBLISH` requests. Receiving a stale `PUBREL` causes a warning level log. Note, the message is delivered to subscribers before entering the wait for PUBREL.",
      "label": "Max Awaiting PUBREL TIMEOUT"
    },
    "mqtt_exclusive_subscription": {
      "desc": "Whether to enable support for MQTT exclusive subscription.",
      "label": "Exclusive Subscription"
    },
    "mqtt_idle_timeout": {
      "desc": "Configure the duration of time that a connection can remain idle (i.e., without any data transfer) before being:\n  - Automatically disconnected  if no CONNECT package is received from the client yet.\n  - Put into hibernation mode to save resources if some CONNECT packages are already received.\nNote: Please set the parameter with caution as long idle time will lead to resource waste.",
      "label": "Idle Timeout"
    },
    "mqtt_ignore_loop_deliver": {
      "desc": "Whether the messages sent by the MQTT v3.1.1/v3.1.0 client will be looped back to the publisher itself, similar to <code>No Local</code> in MQTT 5.0.",
      "label": "Ignore Loop Deliver"
    },
    "mqtt_keepalive_check_interval": {
      "desc": "The frequency of checking for incoming MQTT packets determines how often the server will check for new MQTT packets.\nIf a certain amount of time passes without any packets being sent from the client, this time will be added up.\nOnce the accumulated time exceeds `keepalive-interval * keepalive-multiplier`, the connection will be terminated.\nThe default is set to 30 seconds, with a minimum value of 1 second and a maximum value of `keepalive-interval / 2`.",
      "label": "Keep Alive Check Interval"
    },
    "mqtt_keepalive_multiplier": {
      "desc": "Keep-Alive Timeout = Keep-Alive interval  Keep-Alive Multiplier.\nThe default value 1.5 is following the MQTT 5.0 specification. This multiplier is adjustable, providing system administrators flexibility for tailoring to their specific needs. For instance, if a client's 10-second Keep-Alive interval PINGREQ gets delayed by an extra 10 seconds, changing the multiplier to 2 lets EMQX tolerate this delay.",
      "label": "Keep Alive Multiplier"
    },
    "mqtt_listener_access_rules": {
      "desc": "An access rule list consisting of string rules to restrict or allow access from some addresses. The rules that appear earlier in the list are matched first.\nThe format is `allow | deny <address> | <CIDR> | all`.\n\nFor example:\n\n`[\\\"deny 192.168.1.1\\\", \\\"allow 192.168.1.0/24\\\", \\\"deny, all\\\"]`",
      "label": "Access rules"
    },
    "mqtt_listener_proxy_protocol": {
      "desc": "Enable the Proxy Protocol V1/2 if the EMQX cluster is deployed behind HAProxy or Nginx.<br/>\nSee: https://www.haproxy.com/blog/haproxy/proxy-protocol/",
      "label": "Proxy protocol"
    },
    "mqtt_listener_proxy_protocol_timeout": {
      "desc": "If a reverse proxy is deployed for EMQX, and the PROXY protocol is enabled at the proxy to pass the client's real IP, this option needs to be turned on so that EMQX can extract the client's real IP from the PROXY protocol header.\n\nEMQX will automatically detect the version of the PROXY protocol and support V1 and V2.\n\nFor a detailed description of the PROXY protocol, please refer to: https://www.haproxy.com/blog/haproxy/proxy-protocol/",
      "label": "Proxy protocol timeout"
    },
    "mqtt_max_awaiting_rel": {
      "desc": "For each publisher session, the maximum number of outstanding QoS 2 messages pending on the client to send PUBREL. After reaching this limit, new QoS 2 PUBLISH requests will be rejected with `147(0x93)` until either PUBREL is received or timed out.",
      "label": "Max Awaiting PUBREL"
    },
    "mqtt_max_clientid_len": {
      "desc": "Maximum allowed length of MQTT Client ID.",
      "label": "Max Client ID Length"
    },
    "mqtt_max_inflight": {
      "desc": "Maximum number of QoS 1 and QoS 2 messages that are allowed to be delivered simultaneously before completing the acknowledgment.",
      "label": "Max Inflight"
    },
    "mqtt_max_mqueue_len": {
      "desc": "Maximum queue length. Enqueued messages when persistent client disconnected, or inflight window is full.",
      "label": "Max Message Queue Length"
    },
    "mqtt_max_packet_size": {
      "desc": "Maximum MQTT packet size allowed. Default: 1 MB, Maximum: 256 MB",
      "label": "Max Packet Size"
    },
    "mqtt_max_qos_allowed": {
      "desc": "Maximum QoS allowed.",
      "label": "Max QoS"
    },
    "mqtt_max_subscriptions": {
      "desc": "Maximum number of subscriptions allowed per client.",
      "label": "Max Subscriptions"
    },
    "mqtt_max_topic_alias": {
      "desc": "Maximum topic alias, 0 means no topic alias supported.",
      "label": "Max Topic Alias"
    },
    "mqtt_max_topic_levels": {
      "desc": "Maximum topic levels allowed.",
      "label": "Max Topic Levels"
    },
    "mqtt_message_expiry_interval": {
      "desc": "The expiry interval of MQTT messages. For MQTT 5.0 clients, this configuration will only take effect when the `Message-Expiry-Interval` property is not set in the message; otherwise, the value of the `Message-Expiry-Interval` property will be used. For MQTT versions older than 5.0, this configuration will always take effect. Please note that setting `message_expiry_interval` greater than `session_expiry_interval` is meaningless, as all messages will be cleared when the session expires.",
      "label": "Message Expiry Interval"
    },
    "mqtt_mqueue_default_priority": {
      "desc": "Default topic priority, which will be used by topics not in <code>Topic Priorities</code> (<code>mqueue_priorities</code>).",
      "label": "Default Topic Priorities"
    },
    "mqtt_mqueue_priorities": {
      "desc": "Topic priority list. Prioritize messages in the message queue by topic. The priority range is `[1, 255]`.\n\nThe larger the value, the higher the priority. Messages with higher priority will be sent first.\n\nTopics not in this list will use the default priority (specified by `mqueue_default_priority`).\n\nBy default, this list is empty, which means all topics have the same priority.\n\nNote: commas and equal signs are not supported in topic names.\n\nFor example, if you want `topic/1` to have a higher priority than `topic/2`, you can configure it like this:\n\n`mqueue_priorities: {\\\"topic/1\\\": 10, \\\"topic/2\\\": 8}`",
      "label": "Topic Priorities"
    },
    "mqtt_mqueue_store_qos0": {
      "desc": "Specifies whether to store QoS 0 messages in the message queue while the connection is down but the session remains.",
      "label": "Store QoS 0 Message"
    },
    "mqtt_peer_cert_as_clientid": {
      "desc": "Use the CN, DN field in the peer certificate or the entire certificate content as Client ID. Only works for the TLS connection.\nSupported configurations are the following:\n- <code>cn</code>: CN field of the certificate\n- <code>dn</code>: DN field of the certificate\n- <code>crt</code>: <code>DER</code> or <code>PEM</code> certificate\n- <code>pem</code>: Convert <code>DER</code> certificate content to <code>PEM</code> format and use as Client ID\n- <code>md5</code>: MD5 value of the <code>DER</code> or <code>PEM</code> certificate",
      "label": "Use Peer Certificate as Client ID"
    },
    "mqtt_peer_cert_as_username": {
      "desc": "Use the CN, DN field in the peer certificate or the entire certificate content as Username. Only works for the TLS connection.\nSupported configurations are the following:\n- <code>cn</code>: CN field of the certificate\n- <code>dn</code>: DN field of the certificate\n- <code>crt</code>: Content of the <code>DER</code> or <code>PEM</code> certificate\n- <code>pem</code>: Convert <code>DER</code> certificate content to <code>PEM</code> format and use as Username\n- <code>md5</code>: MD5 value of the <code>DER</code> or <code>PEM</code> certificate",
      "label": "Use Peer Certificate as Username"
    },
    "mqtt_response_information": {
      "desc": "UTF-8 string, for creating the response topic, for example, if set to <code>reqrsp/</code>, the publisher/subscriber will communicate using the topic prefix <code>reqrsp/</code>.\nTo disable this feature, input <code>\"\"</code> in the text box below. Only applicable to MQTT 5.0 clients.",
      "label": "Response Information"
    },
    "mqtt_retain_available": {
      "desc": "Whether to enable support for MQTT retained message.",
      "label": "Retain Available"
    },
    "mqtt_retry_interval": {
      "desc": "Retry interval for QoS 1/2 message delivering.",
      "label": "Retry Interval"
    },
    "mqtt_server_keepalive": {
      "desc": "The keep alive duration required by EMQX. To use the setting from the client side, choose disabled from the drop-down list. Only applicable to MQTT 5.0 clients.",
      "label": "Server Keep Alive"
    },
    "mqtt_session_expiry_interval": {
      "desc": "Specifies how long the session will expire after the connection is disconnected, only for non-MQTT 5.0 connections.",
      "label": "Session Expiry Interval"
    },
    "mqtt_shared_subscription": {
      "desc": "Whether to enable support for MQTT shared subscription.",
      "label": "Shared Subscription Available"
    },
    "mqtt_shared_subscription_strategy": {
      "desc": "Dispatch strategy for shared subscription.\n - `random`: Randomly select a subscriber for dispatch;\n - `round_robin`: Clients in a shared subscription group will consume messages in turn, and the progress of the loop is recorded independently in each publisher, so two adjacent messages from **different publishers** may be consumed by the same client in the subscription group;\n - `round_robin_per_group`: Clients in a shared subscription group will consume messages in turn, and the progress of the loop is recorded independently in each node, so two adjacent messages from **different nodes** may be consumed by the same client in the subscription group;\n - `local`: Randomly select a subscriber on the current node, if there are no subscribers on the current node, then randomly select within the cluster;\n - `sticky`: Continuously dispatch messages to the initially selected subscriber until their session ends;\n - `hash_clientid`: Hash the publisher's client ID to select a subscriber;\n - `hash_topic`: Hash the publishing topic to select a subscriber."
    },
    "mqtt_strict_mode": {
      "desc": "Whether to parse MQTT messages in strict mode.\nIn strict mode, invalid utf8 strings in for example client ID, topic name, etc. will cause the client to be disconnected.",
      "label": "Strict Mode"
    },
    "mqtt_upgrade_qos": {
      "desc": "Force upgrade of QoS level according to subscription.",
      "label": "Upgrade QoS"
    },
    "mqtt_use_username_as_clientid": {
      "desc": "Whether to use Username as Client ID.\nThis setting takes effect later than `peer_cert_as_username` and `peer_cert_as_clientid`.",
      "label": "Use Username as Client ID"
    },
    "mqtt_wildcard_subscription": {
      "desc": "Whether to enable support for MQTT wildcard subscription.",
      "label": "Wildcard Subscription Available"
    },
    "overload_protection_backoff_delay": {
      "desc": "The maximum duration of delay for background task execution during high load conditions.",
      "label": "Delay Time"
    },
    "overload_protection_backoff_gc": {
      "desc": "When at high load, skip forceful GC.",
      "label": "Skip GC"
    },
    "overload_protection_backoff_hibernation": {
      "desc": "When at high load, skip process hibernation.",
      "label": "Skip hibernation"
    },
    "overload_protection_backoff_new_conn": {
      "desc": "When at high load, close new incoming connections.",
      "label": "Close new connections"
    },
    "overload_protection_enable": {
      "desc": "React on system overload or not.",
      "label": "React on system overload or not"
    },
    "resource_tags": {
      "desc": "Tags to annotate this config entry.",
      "label": "Tags"
    },
    "server_ssl_opts_schema_client_renegotiation": {
      "desc": "In protocols that support client-initiated renegotiation,\nthe cost of resources of such an operation is higher for the server than the client.\nThis can act as a vector for denial of service attacks.\nThe SSL application already takes measures to counter-act such attempts,\nbut client-initiated renegotiation can be strictly disabled by setting this option to false.\nThe default value is true. Note that disabling renegotiation can result in\nlong-lived connections becoming unusable due to limits on\nthe number of messages the underlying cipher suite can encipher.<br/>\nHas no effect when TLS version is configured (or negotiated) to 1.3",
      "label": "SSL client renegotiation"
    },
    "server_ssl_opts_schema_dhfile": {
      "desc": "Path to a file containing PEM-encoded Diffie-Hellman parameters\nto be used by the server if a cipher suite using Diffie-Hellman\nkey exchange is negotiated. If not specified, default parameters\nare used.<br/>\nNOTE: The <code>dhfile</code> option is not supported by TLS 1.3.",
      "label": "SSL dhfile"
    },
    "server_ssl_opts_schema_enable_crl_check": {
      "desc": "Whether to enable CRL verification for this listener.",
      "label": "Enable CRL Check"
    },
    "server_ssl_opts_schema_enable_ocsp_stapling": {
      "desc": "Whether to enable Online Certificate Status Protocol (OCSP) stapling for the listener.  If set to true, requires defining the OCSP responder URL and issuer PEM path.",
      "label": "Enable OCSP Stapling"
    },
    "server_ssl_opts_schema_fail_if_no_peer_cert": {
      "desc": "This option is only effective if `verify` is set to `verify_peer`.\n\nIf set to `true`, EMQX will reject the connection if the client fails to provide a certificate.\n\nIf set to `false`, EMQX will accept clients which don't present a certificate.",
      "label": "SSL fail if no peer cert"
    },
    "server_ssl_opts_schema_gc_after_handshake": {
      "desc": "Memory usage tuning. If enabled, will immediately perform a garbage collection after the TLS/SSL handshake.",
      "label": "Perform GC after handshake"
    },
    "server_ssl_opts_schema_handshake_timeout": {
      "desc": "Maximum time duration allowed for the handshake to complete",
      "label": "Handshake timeout"
    },
    "server_ssl_opts_schema_honor_cipher_order": {
      "desc": "An important security setting. If this setting is enabled, the server will prioritize the cipher suites it prefers most from the list of cipher suites supported by the client, thus ignoring the client's preferences.\n\nThe server's cipher suites are specified by `ciphers`, with preference decreasing from left to right.\n\nIt is often better to use the server's preferences, as it is more likely that the server will be configured correctly.",
      "label": "SSL honor cipher order"
    },
    "server_ssl_opts_schema_ocsp_issuer_pem": {
      "desc": "PEM-encoded certificate of the OCSP issuer for the server certificate.",
      "label": "OCSP Issuer Certificate"
    },
    "server_ssl_opts_schema_ocsp_refresh_http_timeout": {
      "desc": "The timeout for the HTTP request when checking OCSP responses.",
      "label": "OCSP Refresh HTTP Timeout"
    },
    "server_ssl_opts_schema_ocsp_refresh_interval": {
      "desc": "The period to refresh the OCSP response for the server.",
      "label": "OCSP Refresh Interval"
    },
    "server_ssl_opts_schema_ocsp_responder_url": {
      "desc": "URL for the OCSP responder to check the server certificate against.",
      "label": "OCSP Responder URL"
    },
    "session_ds_batch_size": {
      "desc": "This value affects the flow control for the persistent sessions.\nPersistent session queries the durable message storage in batches.\nThis value specifies size of the batch.\n\nNote: larger batches generally improve the throughput and overall performance of the system, but increase RAM usage per client.",
      "label": "Batch size"
    },
    "session_ds_session_gc_batch_size": {
      "desc": "The size of each batch of expired persistent sessions to be garbage collected per iteration.",
      "label": "Session garbage collection batch size"
    },
    "session_ds_session_gc_interval": {
      "desc": "The interval at which session garbage collection is executed for persistent sessions.",
      "label": "Session garbage collection interval"
    },
    "shared_subscription_group_strategy": {
      "desc": "Per group dispatch strategy for shared subscription.\nThis config is a map from shared subscription group name to the strategy\nname. The group name should be of format `[A-Za-z0-9]`. i.e. no\nspecial characters are allowed."
    },
    "shared_subscription_strategy_enum": {
      "desc": "Dispatch strategy for shared subscription.\n - `random`: Randomly select a subscriber for dispatch;\n - `round_robin`: Clients in a shared subscription group will consume messages in turn, and the progress of the loop is recorded independently in each publisher, so two adjacent messages from **different publishers** may be consumed by the same client in the subscription group;\n - `round_robin_per_group`: Clients in a shared subscription group will consume messages in turn, and the progress of the loop is recorded independently in each node, so two adjacent messages from **different nodes** may be consumed by the same client in the subscription group;\n - `local`: Randomly select a subscriber on the current node, if there are no subscribers on the current node, then randomly select within the cluster;\n - `sticky`: Continuously dispatch messages to the initially selected subscriber until their session ends;\n - `hash_clientid`: Hash the publisher's client ID to select a subscriber;\n - `hash_topic`: Hash the publishing topic to select a subscriber."
    },
    "stats_enable": {
      "desc": "Enable/disable statistic data collection.",
      "label": "Enable/disable statistic data collection."
    },
    "sys_event_client_connected": {
      "desc": "Enable to publish client connected event messages"
    },
    "sys_event_client_disconnected": {
      "desc": "Enable to publish client disconnected event messages."
    },
    "sys_event_client_subscribed": {
      "desc": "Enable to publish event message that client subscribed a topic successfully."
    },
    "sys_event_client_unsubscribed": {
      "desc": "Enable to publish event message that client unsubscribed a topic successfully."
    },
    "sys_event_messages": {
      "desc": "Client events messages."
    },
    "sys_heartbeat_interval": {
      "desc": "Time interval for publishing following heartbeat messages:\n  - `$SYS/brokers/<node>/uptime`\n  - `$SYS/brokers/<node>/datetime`"
    },
    "sys_msg_interval": {
      "desc": "Time interval for publishing following system messages:\n  - `$SYS/brokers`\n  - `$SYS/brokers/<node>/version`\n  - `$SYS/brokers/<node>/sysdescr`\n  - `$SYS/brokers/<node>/stats/<name>`\n  - `$SYS/brokers/<node>/metrics/<name>`"
    },
    "sys_topics": {
      "desc": "System topics configuration."
    },
    "sysmon_os_cpu_check_interval": {
      "desc": "The time interval for the periodic CPU check. Disabled on Windows platform.",
      "label": "The time interval for the periodic CPU check."
    },
    "sysmon_os_cpu_high_watermark": {
      "desc": "The threshold, as percentage of system CPU load,\n for how much system cpu can be used before the corresponding alarm is raised. Disabled on Windows platform",
      "label": "CPU high watermark"
    },
    "sysmon_os_cpu_low_watermark": {
      "desc": "The threshold, as percentage of system CPU load,\n for how much system cpu can be used before the corresponding alarm is cleared. Disabled on Windows platform",
      "label": "CPU low watermark"
    },
    "sysmon_os_mem_check_interval": {
      "desc": "The time interval for the periodic memory check. Disabled on Windows platform.",
      "label": "Mem check interval"
    },
    "sysmon_os_procmem_high_watermark": {
      "desc": "The threshold, as percentage of system memory,\n for how much system memory can be allocated by one Erlang process before\n the corresponding alarm is raised. Disabled on Windows platform.",
      "label": "ProcMem high wartermark"
    },
    "sysmon_os_sysmem_high_watermark": {
      "desc": "The threshold, as percentage of system memory,\n for how much system memory can be allocated before the corresponding alarm is raised. Disabled on Windows platform",
      "label": "SysMem high wartermark"
    },
    "sysmon_top_db_hostname": {
      "desc": "Hostname of the PostgreSQL database that collects the data points",
      "label": "DB Hostname"
    },
    "sysmon_top_db_name": {
      "desc": "PostgreSQL database name",
      "label": "DB Name"
    },
    "sysmon_top_db_password": {
      "desc": "EMQX user password in the PostgreSQL database",
      "label": "DB Password"
    },
    "sysmon_top_db_port": {
      "desc": "Port of the PostgreSQL database that collects the data points.",
      "label": "DB Port"
    },
    "sysmon_top_db_username": {
      "desc": "Username of the PostgreSQL database",
      "label": "DB Username"
    },
    "sysmon_top_max_procs": {
      "desc": "Stop collecting data when the number of processes\nin the VM exceeds this value",
      "label": "Max procs"
    },
    "sysmon_top_num_items": {
      "desc": "The number of top processes per monitoring group",
      "label": "Top num items"
    },
    "sysmon_top_sample_interval": {
      "desc": "Specifies how often process top should be collected",
      "label": "Top sample interval"
    },
    "sysmon_vm_busy_dist_port": {
      "desc": "When the RPC connection used to communicate with other nodes in the cluster is overloaded,\nthere will be a <code>busy_dist_port</code> warning log,\nand an MQTT message is published to system topic <code>$SYS/sysmon/busy_dist_port</code>.",
      "label": "Enable Busy Distribution Port monitoring."
    },
    "sysmon_vm_busy_port": {
      "desc": "When a port (e.g. TCP socket) is overloaded, there will be a <code>busy_port</code> warning log,\nand an MQTT message is published to the system topic <code>$SYS/sysmon/busy_port</code>.",
      "label": "Enable Busy Port monitoring."
    },
    "sysmon_vm_large_heap": {
      "desc": "When the heap memory occupied by a process exceeds the size specified by `large_heap`, the system will write a warning level `large_heap` log, and an MQTT message will be published to the system topic `$SYS/sysmon/large_heap`.",
      "label": "Enable Large Heap monitoring."
    },
    "sysmon_vm_long_gc": {
      "desc": "When an Erlang process spends long time to perform garbage collection, a warning level <code>long_gc</code> log is emitted,\nand an MQTT message is published to the system topic <code>$SYS/sysmon/long_gc</code>.",
      "label": "Enable Long GC monitoring."
    },
    "sysmon_vm_long_schedule": {
      "desc": "When the Erlang VM detect a task scheduled for too long, a warning level 'long_schedule' log is emitted,\nand an MQTT message is published to the system topic <code>$SYS/sysmon/long_schedule</code>.",
      "label": "Enable Long Schedule monitoring."
    },
    "sysmon_vm_process_check_interval": {
      "desc": "The time interval for the periodic process count limit check, used together with `process_high_watermark` and `process_low_watermark`.",
      "label": "Process limit check interval"
    },
    "sysmon_vm_process_high_watermark": {
      "desc": "The threshold, as percentage of processes, for how many\n processes can simultaneously exist at the local node before the corresponding\n alarm is raised.",
      "label": "Process high watermark"
    },
    "sysmon_vm_process_low_watermark": {
      "desc": "The threshold, as percentage of processes, for how many\n processes can simultaneously exist at the local node before the corresponding\n alarm is cleared.",
      "label": "Process low watermark"
    },
    "zones": {
      "desc": "A zone is a set of configs grouped by the zone <code>name</code>.\nFor flexible configuration mapping, the <code>name</code> can be set to a listener's <code>zone</code> config.\nNOTE: A built-in zone named <code>default</code> is auto created and can not be deleted."
    }
  },
  "emqx_schema_registry_http_api": {
    "desc_param_path_schema_name": {
      "desc": "The schema name",
      "label": "Schema name"
    },
    "desc_schema_registry_api_delete": {
      "desc": "Delete a schema",
      "label": "Delete schema"
    },
    "desc_schema_registry_api_get": {
      "desc": "Get a schema by its name",
      "label": "Get schema"
    },
    "desc_schema_registry_api_list": {
      "desc": "List all registered schemas",
      "label": "List schemas"
    },
    "desc_schema_registry_api_post": {
      "desc": "Register a new schema",
      "label": "Register schema"
    },
    "desc_schema_registry_api_put": {
      "desc": "Update an existing schema",
      "label": "Update schema"
    }
  },
  "emqx_schema_registry_schema": {
    "avro_type": {
      "desc": "[Apache Avro](https://avro.apache.org/) serialization format.",
      "label": "Apache Avro"
    },
    "json_type": {
      "desc": "Supports JSON Schema\n[Draft 03](http://tools.ietf.org/html/draft-zyp-json-schema-03)\n[Draft 04](http://tools.ietf.org/html/draft-zyp-json-schema-04) and\n[Draft 06](https://datatracker.ietf.org/doc/html/draft-wright-json-schema-00).",
      "label": "JSON Schema"
    },
    "protobuf_type": {
      "desc": "[Protocol Buffers](https://protobuf.dev/) serialization format.",
      "label": "Protocol Buffers"
    },
    "schema_description": {
      "desc": "A description for this schema.",
      "label": "Schema description"
    },
    "schema_name": {
      "desc": "A name for the schema that will serve as its identifier.",
      "label": "Schema name"
    },
    "schema_registry_root": {
      "desc": "Schema registry configurations.",
      "label": "Schema registry"
    },
    "schema_registry_schemas": {
      "desc": "Registered schemas.",
      "label": "Registered schemas"
    },
    "schema_source": {
      "desc": "Source text for the schema.",
      "label": "Schema source"
    },
    "schema_type_avro": {
      "desc": "Must be `avro` for Avro schema.",
      "label": "Avro Schema"
    },
    "schema_type_json": {
      "desc": "Must be `json` for JSON schema.",
      "label": "JSON Schema"
    },
    "schema_type_protobuf": {
      "desc": "Must be `protobuf` for protobuf schema.",
      "label": "Protobuf Schema"
    }
  },
  "emqx_schema_validation_http_api": {
    "append_validation": {
      "desc": "Append a new validation to the list of validations"
    },
    "delete_validation": {
      "desc": "Delete a validation"
    },
    "enable_disable_validation": {
      "desc": "Enable or disable a particular validation"
    },
    "get_validation_metrics": {
      "desc": "Get metrics for a particular validation"
    },
    "list_validations": {
      "desc": "List validations"
    },
    "lookup_validation": {
      "desc": "Lookup a validation"
    },
    "param_path_enable": {
      "desc": "Enable or disable validation"
    },
    "param_path_name": {
      "desc": "Validation name"
    },
    "reorder_validations": {
      "desc": "Reorder of all validations"
    },
    "reset_validation_metrics": {
      "desc": "Reset metrics for a particular validation"
    },
    "update_validation": {
      "desc": "Update a validation"
    }
  },
  "emqx_schema_validation_schema": {
    "check_avro_schema": {
      "desc": "Schema name to use during check.",
      "label": "Schema name"
    },
    "check_avro_type": {
      "desc": "Avro schema check",
      "label": "Avro schema check"
    },
    "check_json_schema": {
      "desc": "Schema name to use during check.",
      "label": "Schema name"
    },
    "check_json_type": {
      "desc": "JSON schema check",
      "label": "JSON schema check"
    },
    "check_protobuf_message_type": {
      "desc": "Message name to use during check.",
      "label": "Message name"
    },
    "check_protobuf_schema": {
      "desc": "Schema name to use during check.",
      "label": "Schema name"
    },
    "check_protobuf_type": {
      "desc": "Protobuf schema check",
      "label": "Protobuf schema check"
    },
    "check_sql_schema": {
      "desc": "Schema name to use during check.",
      "label": "Schema name"
    },
    "check_sql_type": {
      "desc": "Use rule-engine's SQL to validate the message. SQL here is the same as in rule-engine,\n  just with the different that the `FROM` clause must be omitted.\n  A SQL statement which yields any value is considered successfully validated, otherwise failed.\n  For example <code>SELECT payload.foo + payload.bar as sum WHERE sum > 0</code>\n  validates that the sum of field `foo` and `bar` is a positive value.",
      "label": "SQL schema check"
    },
    "checks": {
      "desc": "Checks that will be performed during validation.  They are evaluated in the same order as defined.",
      "label": "Checks"
    },
    "failure_action": {
      "desc": "How to proceed if the validation fails.\n\n  <code>drop</code>: The offending message is simply dropped without further processing.\n  <code>disconnect</code>: The message is not published, and the publishing client is disconnected.\n  <code>ignore</code>: Only the failure is logged and traced.  No other action is taken.",
      "label": "Failure action"
    },
    "log_failure_at": {
      "desc": "Log level at which failures will be logged.",
      "label": "Failure log level"
    },
    "name": {
      "desc": "Name"
    },
    "strategy": {
      "desc": "Strategy"
    },
    "topics": {
      "desc": "A single topic filter or list of topic filters that this validation should validate.",
      "label": "Topic filter(s)"
    }
  },
  "emqx_slow_subs_api": {
    "clear_records_api": {
      "desc": "Clear current data and re count slow topic",
      "label": "Clear current data and re count slow topic"
    },
    "clientid": {
      "desc": "Message clientid"
    },
    "get_records_api": {
      "desc": "View slow topics statistics record data",
      "label": "View slow topics statistics record data"
    },
    "get_setting_api": {
      "desc": "View slow subs settings",
      "label": "View slow subs settings"
    },
    "last_update_time": {
      "desc": "The timestamp of last update"
    },
    "node": {
      "desc": "Message node name"
    },
    "timespan": {
      "desc": "Timespan for message transmission"
    },
    "topic": {
      "desc": "Message topic"
    },
    "update_setting_api": {
      "desc": "Update slow subs settings",
      "label": "Update slow subs settings"
    }
  },
  "emqx_slow_subs_schema": {
    "enable": {
      "desc": "Enable Slow Subscriptions"
    },
    "expire_interval": {
      "desc": "The expiration time of the slow subscription record, if the record is not updated within the expiration time, then the record will be deleted."
    },
    "stats_type": {
      "desc": "Message latency calculation method:\n\n- `whole`: The time from when the message arrives at the EMQX (the EMQX gets the message from the receive-buffer) until the message completes delivery.\n- `internal`: The time from when the message arrives at the EMQX (the EMQX gets the message from the receive-buffer) to when the message begins to be delivered (the EMQX attempts to write the message to the send-buffer).\n- `response`: The time from the start of message delivery to the completion.\n\nNote: The completion delivery time refers to the time when QoS 1 and 2 messages complete the MQTT message response process, i.e., the time when QoS 1 message receives the PUBACK packet and QoS 2 message receives the PUBCOMP packet.\nSince there is no response packet for QoS 0 message, the completion delivery time of the QoS 0 message will be replaced by the time when the message starts to be delivered. Therefore, when using the `response` method to calculate the latency, the latency of a QoS 0 message will always be equal to 0."
    },
    "threshold": {
      "desc": "The Client ID and topic of the consumer whose message latency is greater than this threshold will be recorded in the slow subscription list."
    },
    "top_k_num": {
      "desc": "The maximum number of slow-subscription records, up to a maximum of 1000."
    }
  },
  "emqx_stomp_schema": {
    "stomp": {
      "desc": "The Stomp Gateway configuration.\nThis gateway supports v1.2/1.1/1.0"
    },
    "stomp_frame_max_body_length": {
      "desc": "Maximum number of bytes of Body allowed per Stomp packet"
    },
    "stomp_frame_max_headers": {
      "desc": "The maximum number of Header"
    },
    "stomp_frame_max_headers_length": {
      "desc": "The maximum string length of the Header Value"
    }
  },
  "emqx_telemetry_api": {
    "active_modules": {
      "desc": "Get active modules"
    },
    "active_plugins": {
      "desc": "Get active plugins"
    },
    "emqx_version": {
      "desc": "Get emqx version"
    },
    "enable": {
      "desc": "Enable telemetry"
    },
    "get_telemetry_data_api": {
      "desc": "Get telemetry data",
      "label": "Get telemetry data"
    },
    "get_telemetry_status_api": {
      "desc": "Get telemetry status",
      "label": "Get telemetry status"
    },
    "license": {
      "desc": "Get license information"
    },
    "messages_received": {
      "desc": "Get number of messages received"
    },
    "messages_sent": {
      "desc": "Get number of messages sent"
    },
    "nodes_uuid": {
      "desc": "Get nodes UUID"
    },
    "num_clients": {
      "desc": "Get number of clients"
    },
    "os_name": {
      "desc": "Get OS name"
    },
    "os_version": {
      "desc": "Get OS version"
    },
    "otp_version": {
      "desc": "Get Erlang OTP version"
    },
    "up_time": {
      "desc": "Get uptime"
    },
    "update_telemetry_status_api": {
      "desc": "Enable or disable telemetry",
      "label": "Enable or disable telemetry"
    },
    "uuid": {
      "desc": "Get UUID"
    }
  },
  "emqx_telemetry_schema": {
    "enable": {
      "desc": "Set to `false` disable telemetry data report"
    },
    "telemetry_root_doc": {
      "desc": "Whether to enable telemetry to allow EMQX to collect relevant usage information and share it with EMQ for the purpose of enhancing your product experience, and in no case will EMQX collect personal information about you, such as your MAC address, IP address, content of messages sent.\n\nSee https://docs.emqx.com/en/emqx/latest/telemetry/telemetry.html for more details."
    }
  },
  "emqx_topic_metrics_api": {
    "action": {
      "desc": "Action. Only support reset",
      "label": "Action"
    },
    "create_time": {
      "desc": "Create time",
      "label": "Create time"
    },
    "delete_topic_metrics_data_api": {
      "desc": "Delete topic metrics",
      "label": "Delete topic metrics"
    },
    "gat_topic_metrics_data_api": {
      "desc": "Get topic metrics",
      "label": "Get topic metrics"
    },
    "get_topic_metrics_api": {
      "desc": "List topic metrics",
      "label": "List topic metrics"
    },
    "message_dropped_count": {
      "desc": "Dropped messages count",
      "label": "Dropped messages count"
    },
    "message_dropped_rate": {
      "desc": "Dropped messages rate",
      "label": "Dropped messages rate"
    },
    "message_in_count": {
      "desc": "In messages count",
      "label": "In messages count"
    },
    "message_in_rate": {
      "desc": "In messages rate",
      "label": "In messages rate"
    },
    "message_out_count": {
      "desc": "Out messages count",
      "label": "Out messages count"
    },
    "message_out_rate": {
      "desc": "Out messages rate",
      "label": "Out messages rate"
    },
    "message_qos0_in_count": {
      "desc": "QoS0 in messages count",
      "label": "QoS0 in messages count"
    },
    "message_qos0_in_rate": {
      "desc": "QoS0 in messages rate",
      "label": "QoS0 in messages rate"
    },
    "message_qos0_out_count": {
      "desc": "QoS0 out messages count",
      "label": "QoS0 out messages count"
    },
    "message_qos0_out_rate": {
      "desc": "QoS0 out messages rate",
      "label": "QoS0 out messages rate"
    },
    "message_qos1_in_count": {
      "desc": "QoS1 in messages count",
      "label": "QoS1 in messages count"
    },
    "message_qos1_in_rate": {
      "desc": "QoS1 in messages rate",
      "label": "QoS1 in messages rate"
    },
    "message_qos1_out_count": {
      "desc": "QoS1 out messages count",
      "label": "QoS1 out messages count"
    },
    "message_qos1_out_rate": {
      "desc": "QoS1 out messages rate",
      "label": "QoS1 out messages rate"
    },
    "message_qos2_in_count": {
      "desc": "QoS2 in messages count",
      "label": "QoS2 in messages count"
    },
    "message_qos2_in_rate": {
      "desc": "QoS2 in messages rate",
      "label": "QoS2 in messages rate"
    },
    "message_qos2_out_count": {
      "desc": "QoS2 out messages count",
      "label": "QoS2 out messages count"
    },
    "message_qos2_out_rate": {
      "desc": "QoS2 out messages rate",
      "label": "QoS2 out messages rate"
    },
    "metrics": {
      "desc": "Metrics",
      "label": "Metrics"
    },
    "post_topic_metrics_api": {
      "desc": "Create topic metrics",
      "label": "Create topic metrics"
    },
    "reset_time": {
      "desc": "Reset time. In rfc3339. Nullable if never reset",
      "label": "Reset time"
    },
    "reset_topic_desc": {
      "desc": "Topic Name. If this parameter is not present,all created topic metrics will be reset.",
      "label": "Topic Name"
    },
    "reset_topic_metrics_api": {
      "desc": "Reset telemetry status",
      "label": "Reset telemetry status"
    },
    "topic": {
      "desc": "Topic",
      "label": "Topic"
    },
    "topic_in_body": {
      "desc": "Raw topic string",
      "label": "Raw topic string"
    },
    "topic_in_path": {
      "desc": "Topic string. Notice: Topic string in url path must be encoded",
      "label": "Topic string"
    },
    "topic_metrics_api_response400": {
      "desc": "Bad request. Already exists or bad topic name",
      "label": "Bad request"
    },
    "topic_metrics_api_response404": {
      "desc": "Not Found. Topic metrics not found",
      "label": "Not Found"
    },
    "topic_metrics_api_response409": {
      "desc": "Conflict. Topic metrics exceeded max limit 512",
      "label": "Conflict"
    }
  }
}
